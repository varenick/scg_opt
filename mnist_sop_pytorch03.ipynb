{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.0.post4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as distr\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 8)\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cuda_wrapper(tensor, use_cuda=USE_CUDA):\n",
    "    if use_cuda:\n",
    "        return tensor.cuda()\n",
    "    else:\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "kwargs = {}\n",
    "batch_size = 24\n",
    "test_batch_size = 24\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './data', train=True, download=False,\n",
    "        transform=transforms.Compose(\n",
    "            #[transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            [transforms.ToTensor()]\n",
    "        )\n",
    "    ), batch_size=batch_size, shuffle=True, **kwargs\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        './data', train=False, \n",
    "        transform=transforms.Compose(\n",
    "            #[transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            [transforms.ToTensor()]\n",
    "        )\n",
    "    ), batch_size=test_batch_size, shuffle=True, **kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SigmoidBeliefNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=None, num_blocks=1, hidden_dim=200, nonlinear_blocks=False):\n",
    "        super(SigmoidBeliefNetwork, self).__init__()\n",
    "        \n",
    "        if output_dim is None:\n",
    "            output_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_blocks = num_blocks\n",
    "        \n",
    "        layer_input_dim = input_dim\n",
    "        layer_output_dim = hidden_dim\n",
    "            \n",
    "        self.dense_layers = nn.ModuleList()\n",
    "        self.nonlinearities = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_blocks):\n",
    "            self.dense_layers.append(nn.ModuleList())\n",
    "            self.nonlinearities.append(nn.ModuleList())\n",
    "            if nonlinear_blocks:\n",
    "                for _ in range(3):\n",
    "                    self.dense_layers[-1].append(nn.Linear(layer_input_dim, layer_output_dim))\n",
    "                    layer_input_dim = layer_output_dim\n",
    "                    layer_output_dim = hidden_dim\n",
    "                for _ in range(2):\n",
    "                    self.nonlinearities[-1].append(nn.Tanh())\n",
    "                self.nonlinearities[-1].append(nn.Sigmoid())\n",
    "            else:\n",
    "                self.dense_layers[-1].append(nn.Linear(layer_input_dim, layer_output_dim))\n",
    "                layer_input_dim = layer_output_dim\n",
    "                layer_output_dim = hidden_dim\n",
    "                self.nonlinearities[-1].append(nn.Sigmoid())\n",
    "                    \n",
    "        self.output_layer = nn.Linear(layer_input_dim, output_dim)\n",
    "        \n",
    "        self.eps = 1.0e-6\n",
    "        \n",
    "    def _soft_forward(self, X, sigmoid_temp, start_block_idx):\n",
    "        soft_output = X\n",
    "        for i in range(start_block_idx, self.num_blocks):\n",
    "            for dense_layer, nonlinearity in zip(self.dense_layers[i], self.nonlinearities[i]):\n",
    "                soft_output = nonlinearity(dense_layer(soft_output))\n",
    "            prob = torch.clamp(soft_output, min=self.eps, max=1.-self.eps)\n",
    "            \n",
    "            u = autograd.Variable(\n",
    "                cuda_wrapper(torch.Tensor(prob.size()).uniform_()), requires_grad=False\n",
    "            )\n",
    "\n",
    "            z = torch.log(prob * u + self.eps) - torch.log((1 - prob) * (1 - u) + self.eps)\n",
    "            soft_output = torch.sigmoid(z / sigmoid_temp)\n",
    "            \n",
    "        return self.output_layer(soft_output)\n",
    "            \n",
    "    def forward(self, X, sigmoid_temp=1.0):\n",
    "        self.sample_log_probs = []\n",
    "        final_soft_outputs = []\n",
    "        final_cond_soft_outputs = []\n",
    "\n",
    "        hard_output = X\n",
    "        for i in range(self.num_blocks):\n",
    "            for dense_layer, nonlinearity in zip(self.dense_layers[i], self.nonlinearities[i]):\n",
    "                hard_output = nonlinearity(dense_layer(hard_output))\n",
    "            prob = torch.clamp(hard_output, min=self.eps, max=1.-self.eps)\n",
    "            \n",
    "            u = autograd.Variable(\n",
    "                cuda_wrapper(torch.Tensor(prob.size()).uniform_()), requires_grad=False\n",
    "            )\n",
    "            v = autograd.Variable(\n",
    "                cuda_wrapper(torch.Tensor(prob.size()).uniform_()), requires_grad=False\n",
    "            )\n",
    "\n",
    "            z = torch.log(prob * u + self.eps) - torch.log((1 - prob) * (1 - u) + self.eps)\n",
    "            b = (z > 0)\n",
    "            v = v * (1 - prob) * (1 - b.float()) + (v * prob + (1 - prob)) * b.float() \n",
    "            z_cond = torch.log(prob * v + self.eps) - torch.log((1 - prob) * (1 - v) + self.eps)\n",
    "\n",
    "            self.sample_log_probs.append(distr.Bernoulli(prob).log_prob(b))\n",
    "            \n",
    "            hard_output = b.float()\n",
    "            soft_output = torch.sigmoid(z / sigmoid_temp)\n",
    "            cond_soft_output = torch.sigmoid(z_cond / sigmoid_temp)\n",
    "            \n",
    "            final_soft_outputs.append(self._soft_forward(soft_output, sigmoid_temp, start_block_idx=i+1))\n",
    "            final_cond_soft_outputs.append(self._soft_forward(cond_soft_output, sigmoid_temp, start_block_idx=i+1))\n",
    "        \n",
    "        final_hard_output = self.output_layer(hard_output)\n",
    "        return final_hard_output, final_soft_outputs, final_cond_soft_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = train_loader.dataset.train_data.size()\n",
    "input_dim = input_dim[1] * input_dim[2] // 2\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rebar_0.1\n",
      "Epoch 1 of 200\n",
      "loss: 115.72\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9994, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 2 of 200\n",
      "loss: 109.08\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0002, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 3 of 200\n",
      "loss: 109.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0002\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 4 of 200\n",
      "loss: 109.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 32.0s\n",
      "\n",
      "Epoch 5 of 200\n",
      "loss: 109.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 31.3s\n",
      "\n",
      "Epoch 6 of 200\n",
      "loss: 109.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 31.7s\n",
      "\n",
      "Epoch 7 of 200\n",
      "loss: 108.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 30.9s\n",
      "\n",
      "Epoch 8 of 200\n",
      "loss: 108.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 30.9s\n",
      "\n",
      "Epoch 9 of 200\n",
      "loss: 108.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 32.8s\n",
      "\n",
      "Epoch 10 of 200\n",
      "loss: 108.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 29.9s\n",
      "\n",
      "Epoch 11 of 200\n",
      "loss: 108.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 12 of 200\n",
      "loss: 108.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 13 of 200\n",
      "loss: 108.98\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 14 of 200\n",
      "loss: 108.98\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 15 of 200\n",
      "loss: 108.98\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9998, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 16 of 200\n",
      "loss: 108.98\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9998, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 17 of 200\n",
      "loss: 106.47\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0010, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0009, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0010, eta_b: 1.0002\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 18 of 200\n",
      "loss: 98.68\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0016, eta_b: 1.0002\n",
      "layer 2:\n",
      "eta_w: 1.0013, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0005, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 19 of 200\n",
      "loss: 93.76\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0027, eta_b: 1.0005\n",
      "layer 2:\n",
      "eta_w: 1.0019, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0007, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 20 of 200\n",
      "loss: 89.33\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0027, eta_b: 1.0008\n",
      "layer 2:\n",
      "eta_w: 1.0020, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0008, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 21 of 200\n",
      "loss: 85.43\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0029, eta_b: 1.0012\n",
      "layer 2:\n",
      "eta_w: 1.0024, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0009, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 22 of 200\n",
      "loss: 82.10\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0031, eta_b: 1.0017\n",
      "layer 2:\n",
      "eta_w: 1.0029, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0010, eta_b: 1.0002\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 23 of 200\n",
      "loss: 79.70\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0035, eta_b: 1.0023\n",
      "layer 2:\n",
      "eta_w: 1.0033, eta_b: 1.0003\n",
      "layer 3:\n",
      "eta_w: 1.0012, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 24 of 200\n",
      "loss: 77.92\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0041, eta_b: 1.0027\n",
      "layer 2:\n",
      "eta_w: 1.0037, eta_b: 1.0006\n",
      "layer 3:\n",
      "eta_w: 1.0013, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 25 of 200\n",
      "loss: 76.51\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0039, eta_b: 1.0032\n",
      "layer 2:\n",
      "eta_w: 1.0033, eta_b: 1.0009\n",
      "layer 3:\n",
      "eta_w: 1.0014, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 26 of 200\n",
      "loss: 75.36\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0041, eta_b: 1.0035\n",
      "layer 2:\n",
      "eta_w: 1.0036, eta_b: 1.0012\n",
      "layer 3:\n",
      "eta_w: 1.0013, eta_b: 1.0002\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 27 of 200\n",
      "loss: 74.42\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0049, eta_b: 1.0038\n",
      "layer 2:\n",
      "eta_w: 1.0038, eta_b: 1.0015\n",
      "layer 3:\n",
      "eta_w: 1.0013, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 28 of 200\n",
      "loss: 73.57\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0046, eta_b: 1.0039\n",
      "layer 2:\n",
      "eta_w: 1.0035, eta_b: 1.0017\n",
      "layer 3:\n",
      "eta_w: 1.0013, eta_b: 1.0002\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 29 of 200\n",
      "loss: 72.84\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0042, eta_b: 1.0040\n",
      "layer 2:\n",
      "eta_w: 1.0033, eta_b: 1.0019\n",
      "layer 3:\n",
      "eta_w: 1.0014, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 30 of 200\n",
      "loss: 72.19\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0042, eta_b: 1.0040\n",
      "layer 2:\n",
      "eta_w: 1.0036, eta_b: 1.0019\n",
      "layer 3:\n",
      "eta_w: 1.0014, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 31 of 200\n",
      "loss: 71.61\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0040, eta_b: 1.0041\n",
      "layer 2:\n",
      "eta_w: 1.0039, eta_b: 1.0020\n",
      "layer 3:\n",
      "eta_w: 1.0014, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 32 of 200\n",
      "loss: 71.11\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0041, eta_b: 1.0042\n",
      "layer 2:\n",
      "eta_w: 1.0039, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0013, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 33 of 200\n",
      "loss: 70.64\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0035, eta_b: 1.0040\n",
      "layer 2:\n",
      "eta_w: 1.0034, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0012, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 34 of 200\n",
      "loss: 70.24\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0034, eta_b: 1.0040\n",
      "layer 2:\n",
      "eta_w: 1.0035, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0014, eta_b: 1.0002\n",
      "elapsed time: 34.3s\n",
      "\n",
      "Epoch 35 of 200\n",
      "loss: 69.85\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0032, eta_b: 1.0038\n",
      "layer 2:\n",
      "eta_w: 1.0031, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0012, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 36 of 200\n",
      "loss: 69.51\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0036, eta_b: 1.0036\n",
      "layer 2:\n",
      "eta_w: 1.0033, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0014, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 37 of 200\n",
      "loss: 69.17\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0032, eta_b: 1.0035\n",
      "layer 2:\n",
      "eta_w: 1.0031, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0012, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 38 of 200\n",
      "loss: 68.87\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0030, eta_b: 1.0034\n",
      "layer 2:\n",
      "eta_w: 1.0025, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0010, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 39 of 200\n",
      "loss: 68.60\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0028, eta_b: 1.0032\n",
      "layer 2:\n",
      "eta_w: 1.0027, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0011, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 40 of 200\n",
      "loss: 68.31\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0024, eta_b: 1.0031\n",
      "layer 2:\n",
      "eta_w: 1.0028, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0010, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 41 of 200\n",
      "loss: 68.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0023, eta_b: 1.0029\n",
      "layer 2:\n",
      "eta_w: 1.0027, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0009, eta_b: 1.0002\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 42 of 200\n",
      "loss: 67.84\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0028, eta_b: 1.0029\n",
      "layer 2:\n",
      "eta_w: 1.0032, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0010, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 43 of 200\n",
      "loss: 67.60\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0026, eta_b: 1.0030\n",
      "layer 2:\n",
      "eta_w: 1.0027, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0009, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 44 of 200\n",
      "loss: 67.38\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0019, eta_b: 1.0028\n",
      "layer 2:\n",
      "eta_w: 1.0027, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0008, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 45 of 200\n",
      "loss: 67.18\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0024, eta_b: 1.0028\n",
      "layer 2:\n",
      "eta_w: 1.0028, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0009, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 46 of 200\n",
      "loss: 66.98\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0021, eta_b: 1.0027\n",
      "layer 2:\n",
      "eta_w: 1.0026, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0007, eta_b: 1.0002\n",
      "elapsed time: 34.0s\n",
      "\n",
      "Epoch 47 of 200\n",
      "loss: 66.79\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0023, eta_b: 1.0026\n",
      "layer 2:\n",
      "eta_w: 1.0024, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0007, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 48 of 200\n",
      "loss: 66.61\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0023, eta_b: 1.0024\n",
      "layer 2:\n",
      "eta_w: 1.0023, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0006, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 49 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 66.43\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0021, eta_b: 1.0022\n",
      "layer 2:\n",
      "eta_w: 1.0020, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0005, eta_b: 1.0002\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 50 of 200\n",
      "loss: 66.25\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0014, eta_b: 1.0021\n",
      "layer 2:\n",
      "eta_w: 1.0019, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0005, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 51 of 200\n",
      "loss: 66.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0007, eta_b: 1.0019\n",
      "layer 2:\n",
      "eta_w: 1.0018, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0005, eta_b: 1.0002\n",
      "elapsed time: 35.3s\n",
      "\n",
      "Epoch 52 of 200\n",
      "loss: 65.91\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0014, eta_b: 1.0017\n",
      "layer 2:\n",
      "eta_w: 1.0018, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0003, eta_b: 1.0002\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 53 of 200\n",
      "loss: 65.74\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0004, eta_b: 1.0015\n",
      "layer 2:\n",
      "eta_w: 1.0016, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0002, eta_b: 1.0002\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 54 of 200\n",
      "loss: 65.58\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0009, eta_b: 1.0013\n",
      "layer 2:\n",
      "eta_w: 1.0012, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0002\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 55 of 200\n",
      "loss: 65.44\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0005, eta_b: 1.0011\n",
      "layer 2:\n",
      "eta_w: 1.0013, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0002, eta_b: 1.0002\n",
      "elapsed time: 35.3s\n",
      "\n",
      "Epoch 56 of 200\n",
      "loss: 65.31\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9993, eta_b: 1.0009\n",
      "layer 2:\n",
      "eta_w: 1.0012, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0001, eta_b: 1.0002\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 57 of 200\n",
      "loss: 65.18\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9998, eta_b: 1.0008\n",
      "layer 2:\n",
      "eta_w: 1.0013, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 58 of 200\n",
      "loss: 65.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0005, eta_b: 1.0008\n",
      "layer 2:\n",
      "eta_w: 1.0016, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 1.0001, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 59 of 200\n",
      "loss: 64.95\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0009\n",
      "layer 2:\n",
      "eta_w: 1.0011, eta_b: 1.0021\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 35.4s\n",
      "\n",
      "Epoch 60 of 200\n",
      "loss: 64.83\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9999, eta_b: 1.0007\n",
      "layer 2:\n",
      "eta_w: 1.0008, eta_b: 1.0020\n",
      "layer 3:\n",
      "eta_w: 0.9999, eta_b: 1.0002\n",
      "elapsed time: 35.7s\n",
      "\n",
      "Epoch 61 of 200\n",
      "loss: 64.71\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0006, eta_b: 1.0006\n",
      "layer 2:\n",
      "eta_w: 1.0006, eta_b: 1.0019\n",
      "layer 3:\n",
      "eta_w: 0.9998, eta_b: 1.0002\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 62 of 200\n",
      "loss: 64.60\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0003, eta_b: 1.0005\n",
      "layer 2:\n",
      "eta_w: 1.0009, eta_b: 1.0018\n",
      "layer 3:\n",
      "eta_w: 0.9998, eta_b: 1.0002\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 63 of 200\n",
      "loss: 64.48\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9999, eta_b: 1.0003\n",
      "layer 2:\n",
      "eta_w: 1.0007, eta_b: 1.0017\n",
      "layer 3:\n",
      "eta_w: 0.9997, eta_b: 1.0002\n",
      "elapsed time: 34.0s\n",
      "\n",
      "Epoch 64 of 200\n",
      "loss: 64.39\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9996, eta_b: 1.0003\n",
      "layer 2:\n",
      "eta_w: 1.0005, eta_b: 1.0016\n",
      "layer 3:\n",
      "eta_w: 0.9995, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 65 of 200\n",
      "loss: 64.27\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9991, eta_b: 1.0002\n",
      "layer 2:\n",
      "eta_w: 1.0004, eta_b: 1.0016\n",
      "layer 3:\n",
      "eta_w: 0.9996, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 66 of 200\n",
      "loss: 64.17\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9987, eta_b: 1.0001\n",
      "layer 2:\n",
      "eta_w: 1.0003, eta_b: 1.0015\n",
      "layer 3:\n",
      "eta_w: 0.9994, eta_b: 1.0002\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 67 of 200\n",
      "loss: 64.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9991, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 0.9999, eta_b: 1.0013\n",
      "layer 3:\n",
      "eta_w: 0.9992, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 68 of 200\n",
      "loss: 63.96\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9986, eta_b: 0.9998\n",
      "layer 2:\n",
      "eta_w: 1.0001, eta_b: 1.0012\n",
      "layer 3:\n",
      "eta_w: 0.9992, eta_b: 1.0002\n",
      "elapsed time: 36.1s\n",
      "\n",
      "Epoch 69 of 200\n",
      "loss: 63.87\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9993, eta_b: 0.9997\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0011\n",
      "layer 3:\n",
      "eta_w: 0.9991, eta_b: 1.0002\n",
      "elapsed time: 36.3s\n",
      "\n",
      "Epoch 70 of 200\n",
      "loss: 63.79\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9988, eta_b: 0.9995\n",
      "layer 2:\n",
      "eta_w: 1.0004, eta_b: 1.0010\n",
      "layer 3:\n",
      "eta_w: 0.9992, eta_b: 1.0002\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 71 of 200\n",
      "loss: 63.69\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9980, eta_b: 0.9994\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0009\n",
      "layer 3:\n",
      "eta_w: 0.9990, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 72 of 200\n",
      "loss: 63.61\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9985, eta_b: 0.9991\n",
      "layer 2:\n",
      "eta_w: 0.9996, eta_b: 1.0008\n",
      "layer 3:\n",
      "eta_w: 0.9989, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 73 of 200\n",
      "loss: 63.51\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9986, eta_b: 0.9989\n",
      "layer 2:\n",
      "eta_w: 0.9994, eta_b: 1.0006\n",
      "layer 3:\n",
      "eta_w: 0.9989, eta_b: 1.0002\n",
      "elapsed time: 36.3s\n",
      "\n",
      "Epoch 74 of 200\n",
      "loss: 63.43\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9984, eta_b: 0.9986\n",
      "layer 2:\n",
      "eta_w: 0.9993, eta_b: 1.0003\n",
      "layer 3:\n",
      "eta_w: 0.9987, eta_b: 1.0002\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 75 of 200\n",
      "loss: 63.34\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9986, eta_b: 0.9986\n",
      "layer 2:\n",
      "eta_w: 0.9994, eta_b: 1.0003\n",
      "layer 3:\n",
      "eta_w: 0.9987, eta_b: 1.0002\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 76 of 200\n",
      "loss: 63.27\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9990, eta_b: 0.9985\n",
      "layer 2:\n",
      "eta_w: 0.9991, eta_b: 1.0002\n",
      "layer 3:\n",
      "eta_w: 0.9986, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 77 of 200\n",
      "loss: 63.18\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9987, eta_b: 0.9984\n",
      "layer 2:\n",
      "eta_w: 0.9990, eta_b: 1.0001\n",
      "layer 3:\n",
      "eta_w: 0.9985, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 78 of 200\n",
      "loss: 63.11\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9985, eta_b: 0.9983\n",
      "layer 2:\n",
      "eta_w: 0.9987, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 0.9985, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 79 of 200\n",
      "loss: 63.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9995, eta_b: 0.9982\n",
      "layer 2:\n",
      "eta_w: 0.9991, eta_b: 0.9998\n",
      "layer 3:\n",
      "eta_w: 0.9986, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 80 of 200\n",
      "loss: 62.97\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9989, eta_b: 0.9982\n",
      "layer 2:\n",
      "eta_w: 0.9991, eta_b: 0.9997\n",
      "layer 3:\n",
      "eta_w: 0.9985, eta_b: 1.0002\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 81 of 200\n",
      "loss: 62.88\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9986, eta_b: 0.9982\n",
      "layer 2:\n",
      "eta_w: 0.9991, eta_b: 0.9995\n",
      "layer 3:\n",
      "eta_w: 0.9985, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 82 of 200\n",
      "loss: 62.82\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9985, eta_b: 0.9980\n",
      "layer 2:\n",
      "eta_w: 0.9993, eta_b: 0.9994\n",
      "layer 3:\n",
      "eta_w: 0.9984, eta_b: 1.0002\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 83 of 200\n",
      "loss: 62.74\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9976, eta_b: 0.9979\n",
      "layer 2:\n",
      "eta_w: 0.9988, eta_b: 0.9992\n",
      "layer 3:\n",
      "eta_w: 0.9984, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 84 of 200\n",
      "loss: 62.67\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9975, eta_b: 0.9976\n",
      "layer 2:\n",
      "eta_w: 0.9986, eta_b: 0.9991\n",
      "layer 3:\n",
      "eta_w: 0.9983, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 85 of 200\n",
      "loss: 62.60\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9974, eta_b: 0.9974\n",
      "layer 2:\n",
      "eta_w: 0.9984, eta_b: 0.9989\n",
      "layer 3:\n",
      "eta_w: 0.9982, eta_b: 1.0002\n",
      "elapsed time: 34.2s\n",
      "\n",
      "Epoch 86 of 200\n",
      "loss: 62.53\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9974, eta_b: 0.9974\n",
      "layer 2:\n",
      "eta_w: 0.9983, eta_b: 0.9988\n",
      "layer 3:\n",
      "eta_w: 0.9982, eta_b: 1.0002\n",
      "elapsed time: 34.3s\n",
      "\n",
      "Epoch 87 of 200\n",
      "loss: 62.48\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9978, eta_b: 0.9975\n",
      "layer 2:\n",
      "eta_w: 0.9984, eta_b: 0.9987\n",
      "layer 3:\n",
      "eta_w: 0.9981, eta_b: 1.0002\n",
      "elapsed time: 34.3s\n",
      "\n",
      "Epoch 88 of 200\n",
      "loss: 62.40\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9970, eta_b: 0.9975\n",
      "layer 2:\n",
      "eta_w: 0.9980, eta_b: 0.9987\n",
      "layer 3:\n",
      "eta_w: 0.9979, eta_b: 1.0002\n",
      "elapsed time: 35.6s\n",
      "\n",
      "Epoch 89 of 200\n",
      "loss: 62.33\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9967, eta_b: 0.9974\n",
      "layer 2:\n",
      "eta_w: 0.9980, eta_b: 0.9986\n",
      "layer 3:\n",
      "eta_w: 0.9980, eta_b: 1.0002\n",
      "elapsed time: 35.8s\n",
      "\n",
      "Epoch 90 of 200\n",
      "loss: 62.27\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9972, eta_b: 0.9973\n",
      "layer 2:\n",
      "eta_w: 0.9979, eta_b: 0.9986\n",
      "layer 3:\n",
      "eta_w: 0.9979, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 91 of 200\n",
      "loss: 62.19\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9962, eta_b: 0.9973\n",
      "layer 2:\n",
      "eta_w: 0.9976, eta_b: 0.9985\n",
      "layer 3:\n",
      "eta_w: 0.9979, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 92 of 200\n",
      "loss: 62.13\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9966, eta_b: 0.9972\n",
      "layer 2:\n",
      "eta_w: 0.9976, eta_b: 0.9984\n",
      "layer 3:\n",
      "eta_w: 0.9978, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 93 of 200\n",
      "loss: 62.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9965, eta_b: 0.9971\n",
      "layer 2:\n",
      "eta_w: 0.9975, eta_b: 0.9983\n",
      "layer 3:\n",
      "eta_w: 0.9977, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 94 of 200\n",
      "loss: 62.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9961, eta_b: 0.9970\n",
      "layer 2:\n",
      "eta_w: 0.9976, eta_b: 0.9982\n",
      "layer 3:\n",
      "eta_w: 0.9978, eta_b: 1.0002\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 95 of 200\n",
      "loss: 61.94\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9960, eta_b: 0.9967\n",
      "layer 2:\n",
      "eta_w: 0.9977, eta_b: 0.9980\n",
      "layer 3:\n",
      "eta_w: 0.9976, eta_b: 1.0002\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 96 of 200\n",
      "loss: 61.88\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9958, eta_b: 0.9964\n",
      "layer 2:\n",
      "eta_w: 0.9975, eta_b: 0.9979\n",
      "layer 3:\n",
      "eta_w: 0.9975, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 97 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 61.83\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9958, eta_b: 0.9963\n",
      "layer 2:\n",
      "eta_w: 0.9978, eta_b: 0.9978\n",
      "layer 3:\n",
      "eta_w: 0.9977, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 98 of 200\n",
      "loss: 61.78\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9951, eta_b: 0.9962\n",
      "layer 2:\n",
      "eta_w: 0.9976, eta_b: 0.9977\n",
      "layer 3:\n",
      "eta_w: 0.9975, eta_b: 1.0002\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 99 of 200\n",
      "loss: 61.73\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9951, eta_b: 0.9960\n",
      "layer 2:\n",
      "eta_w: 0.9976, eta_b: 0.9976\n",
      "layer 3:\n",
      "eta_w: 0.9976, eta_b: 1.0002\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 100 of 200\n",
      "loss: 61.68\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9953, eta_b: 0.9960\n",
      "layer 2:\n",
      "eta_w: 0.9979, eta_b: 0.9976\n",
      "layer 3:\n",
      "eta_w: 0.9975, eta_b: 1.0002\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 101 of 200\n",
      "loss: 61.63\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9944, eta_b: 0.9960\n",
      "layer 2:\n",
      "eta_w: 0.9974, eta_b: 0.9975\n",
      "layer 3:\n",
      "eta_w: 0.9974, eta_b: 1.0002\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 102 of 200\n",
      "loss: 61.57\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9954, eta_b: 0.9961\n",
      "layer 2:\n",
      "eta_w: 0.9971, eta_b: 0.9974\n",
      "layer 3:\n",
      "eta_w: 0.9974, eta_b: 1.0002\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 103 of 200\n",
      "loss: 61.51\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9945, eta_b: 0.9960\n",
      "layer 2:\n",
      "eta_w: 0.9971, eta_b: 0.9974\n",
      "layer 3:\n",
      "eta_w: 0.9973, eta_b: 1.0002\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 104 of 200\n",
      "loss: 61.45\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9950, eta_b: 0.9958\n",
      "layer 2:\n",
      "eta_w: 0.9967, eta_b: 0.9973\n",
      "layer 3:\n",
      "eta_w: 0.9971, eta_b: 1.0002\n",
      "elapsed time: 36.7s\n",
      "\n",
      "Epoch 105 of 200\n",
      "loss: 61.39\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9946, eta_b: 0.9956\n",
      "layer 2:\n",
      "eta_w: 0.9965, eta_b: 0.9971\n",
      "layer 3:\n",
      "eta_w: 0.9971, eta_b: 1.0002\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 106 of 200\n",
      "loss: 61.34\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9942, eta_b: 0.9954\n",
      "layer 2:\n",
      "eta_w: 0.9963, eta_b: 0.9970\n",
      "layer 3:\n",
      "eta_w: 0.9969, eta_b: 1.0002\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 107 of 200\n",
      "loss: 61.30\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9946, eta_b: 0.9954\n",
      "layer 2:\n",
      "eta_w: 0.9961, eta_b: 0.9969\n",
      "layer 3:\n",
      "eta_w: 0.9970, eta_b: 1.0002\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 108 of 200\n",
      "loss: 61.25\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9953, eta_b: 0.9953\n",
      "layer 2:\n",
      "eta_w: 0.9961, eta_b: 0.9969\n",
      "layer 3:\n",
      "eta_w: 0.9969, eta_b: 1.0002\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 109 of 200\n",
      "loss: 61.20\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9945, eta_b: 0.9952\n",
      "layer 2:\n",
      "eta_w: 0.9960, eta_b: 0.9968\n",
      "layer 3:\n",
      "eta_w: 0.9968, eta_b: 1.0002\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 110 of 200\n",
      "loss: 61.14\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9949, eta_b: 0.9951\n",
      "layer 2:\n",
      "eta_w: 0.9960, eta_b: 0.9968\n",
      "layer 3:\n",
      "eta_w: 0.9968, eta_b: 1.0002\n",
      "elapsed time: 35.6s\n",
      "\n",
      "Epoch 111 of 200\n",
      "loss: 61.09\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9938, eta_b: 0.9951\n",
      "layer 2:\n",
      "eta_w: 0.9956, eta_b: 0.9967\n",
      "layer 3:\n",
      "eta_w: 0.9967, eta_b: 1.0002\n",
      "elapsed time: 35.3s\n",
      "\n",
      "Epoch 112 of 200\n",
      "loss: 61.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9949, eta_b: 0.9950\n",
      "layer 2:\n",
      "eta_w: 0.9953, eta_b: 0.9966\n",
      "layer 3:\n",
      "eta_w: 0.9966, eta_b: 1.0002\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 113 of 200\n",
      "loss: 61.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9946, eta_b: 0.9950\n",
      "layer 2:\n",
      "eta_w: 0.9952, eta_b: 0.9966\n",
      "layer 3:\n",
      "eta_w: 0.9966, eta_b: 1.0002\n",
      "elapsed time: 35.3s\n",
      "\n",
      "Epoch 114 of 200\n",
      "loss: 60.97\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9945, eta_b: 0.9951\n",
      "layer 2:\n",
      "eta_w: 0.9951, eta_b: 0.9966\n",
      "layer 3:\n",
      "eta_w: 0.9966, eta_b: 1.0002\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 115 of 200\n",
      "loss: 60.91\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9948, eta_b: 0.9950\n",
      "layer 2:\n",
      "eta_w: 0.9953, eta_b: 0.9965\n",
      "layer 3:\n",
      "eta_w: 0.9964, eta_b: 1.0002\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 116 of 200\n",
      "loss: 60.87\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9944, eta_b: 0.9949\n",
      "layer 2:\n",
      "eta_w: 0.9953, eta_b: 0.9965\n",
      "layer 3:\n",
      "eta_w: 0.9965, eta_b: 1.0001\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 117 of 200\n",
      "loss: 60.83\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9938, eta_b: 0.9950\n",
      "layer 2:\n",
      "eta_w: 0.9954, eta_b: 0.9965\n",
      "layer 3:\n",
      "eta_w: 0.9965, eta_b: 1.0001\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 118 of 200\n",
      "loss: 60.79\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9943, eta_b: 0.9949\n",
      "layer 2:\n",
      "eta_w: 0.9959, eta_b: 0.9965\n",
      "layer 3:\n",
      "eta_w: 0.9964, eta_b: 1.0001\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 119 of 200\n",
      "loss: 60.77\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9947, eta_b: 0.9949\n",
      "layer 2:\n",
      "eta_w: 0.9964, eta_b: 0.9964\n",
      "layer 3:\n",
      "eta_w: 0.9966, eta_b: 1.0001\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 120 of 200\n",
      "loss: 60.73\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9945, eta_b: 0.9949\n",
      "layer 2:\n",
      "eta_w: 0.9962, eta_b: 0.9964\n",
      "layer 3:\n",
      "eta_w: 0.9965, eta_b: 1.0001\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 121 of 200\n",
      "loss: 60.69\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9941, eta_b: 0.9948\n",
      "layer 2:\n",
      "eta_w: 0.9965, eta_b: 0.9963\n",
      "layer 3:\n",
      "eta_w: 0.9966, eta_b: 1.0001\n",
      "elapsed time: 34.1s\n",
      "\n",
      "Epoch 122 of 200\n",
      "loss: 60.65\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9935, eta_b: 0.9948\n",
      "layer 2:\n",
      "eta_w: 0.9965, eta_b: 0.9963\n",
      "layer 3:\n",
      "eta_w: 0.9965, eta_b: 1.0001\n",
      "elapsed time: 33.4s\n",
      "\n",
      "Epoch 123 of 200\n",
      "loss: 60.60\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9933, eta_b: 0.9946\n",
      "layer 2:\n",
      "eta_w: 0.9964, eta_b: 0.9962\n",
      "layer 3:\n",
      "eta_w: 0.9965, eta_b: 1.0000\n",
      "elapsed time: 33.3s\n",
      "\n",
      "Epoch 124 of 200\n",
      "loss: 60.56\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9938, eta_b: 0.9943\n",
      "layer 2:\n",
      "eta_w: 0.9962, eta_b: 0.9961\n",
      "layer 3:\n",
      "eta_w: 0.9964, eta_b: 0.9999\n",
      "elapsed time: 33.4s\n",
      "\n",
      "Epoch 125 of 200\n",
      "loss: 60.50\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9932, eta_b: 0.9942\n",
      "layer 2:\n",
      "eta_w: 0.9961, eta_b: 0.9960\n",
      "layer 3:\n",
      "eta_w: 0.9963, eta_b: 0.9997\n",
      "elapsed time: 33.4s\n",
      "\n",
      "Epoch 126 of 200\n",
      "loss: 60.46\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9939, eta_b: 0.9941\n",
      "layer 2:\n",
      "eta_w: 0.9962, eta_b: 0.9959\n",
      "layer 3:\n",
      "eta_w: 0.9962, eta_b: 0.9996\n",
      "elapsed time: 34.4s\n",
      "\n",
      "Epoch 127 of 200\n",
      "loss: 60.42\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9933, eta_b: 0.9940\n",
      "layer 2:\n",
      "eta_w: 0.9962, eta_b: 0.9958\n",
      "layer 3:\n",
      "eta_w: 0.9963, eta_b: 0.9994\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 128 of 200\n",
      "loss: 60.37\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9942, eta_b: 0.9940\n",
      "layer 2:\n",
      "eta_w: 0.9962, eta_b: 0.9958\n",
      "layer 3:\n",
      "eta_w: 0.9961, eta_b: 0.9993\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 129 of 200\n",
      "loss: 60.34\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9945, eta_b: 0.9940\n",
      "layer 2:\n",
      "eta_w: 0.9961, eta_b: 0.9957\n",
      "layer 3:\n",
      "eta_w: 0.9961, eta_b: 0.9991\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 130 of 200\n",
      "loss: 60.29\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9935, eta_b: 0.9938\n",
      "layer 2:\n",
      "eta_w: 0.9958, eta_b: 0.9957\n",
      "layer 3:\n",
      "eta_w: 0.9960, eta_b: 0.9990\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 131 of 200\n",
      "loss: 60.24\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9932, eta_b: 0.9937\n",
      "layer 2:\n",
      "eta_w: 0.9957, eta_b: 0.9956\n",
      "layer 3:\n",
      "eta_w: 0.9960, eta_b: 0.9988\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 132 of 200\n",
      "loss: 60.21\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9939, eta_b: 0.9936\n",
      "layer 2:\n",
      "eta_w: 0.9960, eta_b: 0.9955\n",
      "layer 3:\n",
      "eta_w: 0.9961, eta_b: 0.9987\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 133 of 200\n",
      "loss: 60.18\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9943, eta_b: 0.9937\n",
      "layer 2:\n",
      "eta_w: 0.9958, eta_b: 0.9955\n",
      "layer 3:\n",
      "eta_w: 0.9959, eta_b: 0.9986\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 134 of 200\n",
      "loss: 60.13\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9931, eta_b: 0.9936\n",
      "layer 2:\n",
      "eta_w: 0.9955, eta_b: 0.9954\n",
      "layer 3:\n",
      "eta_w: 0.9959, eta_b: 0.9984\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 135 of 200\n",
      "loss: 60.09\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9932, eta_b: 0.9935\n",
      "layer 2:\n",
      "eta_w: 0.9949, eta_b: 0.9953\n",
      "layer 3:\n",
      "eta_w: 0.9958, eta_b: 0.9983\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 136 of 200\n",
      "loss: 60.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9937, eta_b: 0.9934\n",
      "layer 2:\n",
      "eta_w: 0.9951, eta_b: 0.9953\n",
      "layer 3:\n",
      "eta_w: 0.9959, eta_b: 0.9981\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 137 of 200\n",
      "loss: 60.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9924, eta_b: 0.9935\n",
      "layer 2:\n",
      "eta_w: 0.9947, eta_b: 0.9953\n",
      "layer 3:\n",
      "eta_w: 0.9958, eta_b: 0.9980\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 138 of 200\n",
      "loss: 59.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9927, eta_b: 0.9934\n",
      "layer 2:\n",
      "eta_w: 0.9945, eta_b: 0.9952\n",
      "layer 3:\n",
      "eta_w: 0.9958, eta_b: 0.9978\n",
      "elapsed time: 35.7s\n",
      "\n",
      "Epoch 139 of 200\n",
      "loss: 59.95\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9923, eta_b: 0.9932\n",
      "layer 2:\n",
      "eta_w: 0.9945, eta_b: 0.9951\n",
      "layer 3:\n",
      "eta_w: 0.9957, eta_b: 0.9977\n",
      "elapsed time: 35.6s\n",
      "\n",
      "Epoch 140 of 200\n",
      "loss: 59.89\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9917, eta_b: 0.9930\n",
      "layer 2:\n",
      "eta_w: 0.9943, eta_b: 0.9950\n",
      "layer 3:\n",
      "eta_w: 0.9956, eta_b: 0.9975\n",
      "elapsed time: 35.4s\n",
      "\n",
      "Epoch 141 of 200\n",
      "loss: 59.86\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9921, eta_b: 0.9928\n",
      "layer 2:\n",
      "eta_w: 0.9943, eta_b: 0.9949\n",
      "layer 3:\n",
      "eta_w: 0.9956, eta_b: 0.9975\n",
      "elapsed time: 34.9s\n",
      "\n",
      "Epoch 142 of 200\n",
      "loss: 59.83\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9925, eta_b: 0.9928\n",
      "layer 2:\n",
      "eta_w: 0.9939, eta_b: 0.9948\n",
      "layer 3:\n",
      "eta_w: 0.9955, eta_b: 0.9975\n",
      "elapsed time: 36.1s\n",
      "\n",
      "Epoch 143 of 200\n",
      "loss: 59.80\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9928, eta_b: 0.9927\n",
      "layer 2:\n",
      "eta_w: 0.9938, eta_b: 0.9947\n",
      "layer 3:\n",
      "eta_w: 0.9956, eta_b: 0.9974\n",
      "elapsed time: 35.3s\n",
      "\n",
      "Epoch 144 of 200\n",
      "loss: 59.76\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9918, eta_b: 0.9926\n",
      "layer 2:\n",
      "eta_w: 0.9936, eta_b: 0.9946\n",
      "layer 3:\n",
      "eta_w: 0.9955, eta_b: 0.9974\n",
      "elapsed time: 35.8s\n",
      "\n",
      "Epoch 145 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 59.72\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9919, eta_b: 0.9925\n",
      "layer 2:\n",
      "eta_w: 0.9938, eta_b: 0.9945\n",
      "layer 3:\n",
      "eta_w: 0.9954, eta_b: 0.9973\n",
      "elapsed time: 35.8s\n",
      "\n",
      "Epoch 146 of 200\n",
      "loss: 59.68\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9919, eta_b: 0.9924\n",
      "layer 2:\n",
      "eta_w: 0.9937, eta_b: 0.9944\n",
      "layer 3:\n",
      "eta_w: 0.9953, eta_b: 0.9973\n",
      "elapsed time: 35.8s\n",
      "\n",
      "Epoch 147 of 200\n",
      "loss: 59.65\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9915, eta_b: 0.9925\n",
      "layer 2:\n",
      "eta_w: 0.9937, eta_b: 0.9944\n",
      "layer 3:\n",
      "eta_w: 0.9953, eta_b: 0.9972\n",
      "elapsed time: 35.8s\n",
      "\n",
      "Epoch 148 of 200\n",
      "loss: 59.62\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9913, eta_b: 0.9925\n",
      "layer 2:\n",
      "eta_w: 0.9938, eta_b: 0.9943\n",
      "layer 3:\n",
      "eta_w: 0.9952, eta_b: 0.9972\n",
      "elapsed time: 35.7s\n",
      "\n",
      "Epoch 149 of 200\n",
      "loss: 59.61\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9911, eta_b: 0.9926\n",
      "layer 2:\n",
      "eta_w: 0.9933, eta_b: 0.9943\n",
      "layer 3:\n",
      "eta_w: 0.9952, eta_b: 0.9972\n",
      "elapsed time: 35.5s\n",
      "\n",
      "Epoch 150 of 200\n",
      "loss: 59.58\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9914, eta_b: 0.9926\n",
      "layer 2:\n",
      "eta_w: 0.9933, eta_b: 0.9943\n",
      "layer 3:\n",
      "eta_w: 0.9952, eta_b: 0.9971\n",
      "elapsed time: 35.8s\n",
      "\n",
      "Epoch 151 of 200\n",
      "loss: 59.57\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9909, eta_b: 0.9926\n",
      "layer 2:\n",
      "eta_w: 0.9931, eta_b: 0.9943\n",
      "layer 3:\n",
      "eta_w: 0.9953, eta_b: 0.9971\n",
      "elapsed time: 35.9s\n",
      "\n",
      "Epoch 152 of 200\n",
      "loss: 59.53\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9916, eta_b: 0.9926\n",
      "layer 2:\n",
      "eta_w: 0.9930, eta_b: 0.9943\n",
      "layer 3:\n",
      "eta_w: 0.9952, eta_b: 0.9971\n",
      "elapsed time: 35.7s\n",
      "\n",
      "Epoch 153 of 200\n",
      "loss: 59.48\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9908, eta_b: 0.9924\n",
      "layer 2:\n",
      "eta_w: 0.9926, eta_b: 0.9942\n",
      "layer 3:\n",
      "eta_w: 0.9950, eta_b: 0.9971\n",
      "elapsed time: 35.5s\n",
      "\n",
      "Epoch 154 of 200\n",
      "loss: 59.46\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9905, eta_b: 0.9923\n",
      "layer 2:\n",
      "eta_w: 0.9926, eta_b: 0.9942\n",
      "layer 3:\n",
      "eta_w: 0.9951, eta_b: 0.9971\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 155 of 200\n",
      "loss: 59.43\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9910, eta_b: 0.9923\n",
      "layer 2:\n",
      "eta_w: 0.9922, eta_b: 0.9942\n",
      "layer 3:\n",
      "eta_w: 0.9950, eta_b: 0.9971\n",
      "elapsed time: 35.6s\n",
      "\n",
      "Epoch 156 of 200\n",
      "loss: 59.40\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9903, eta_b: 0.9922\n",
      "layer 2:\n",
      "eta_w: 0.9923, eta_b: 0.9942\n",
      "layer 3:\n",
      "eta_w: 0.9952, eta_b: 0.9970\n",
      "elapsed time: 36.1s\n",
      "\n",
      "Epoch 157 of 200\n",
      "loss: 59.37\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9905, eta_b: 0.9920\n",
      "layer 2:\n",
      "eta_w: 0.9924, eta_b: 0.9941\n",
      "layer 3:\n",
      "eta_w: 0.9950, eta_b: 0.9970\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 158 of 200\n",
      "loss: 59.34\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9900, eta_b: 0.9918\n",
      "layer 2:\n",
      "eta_w: 0.9921, eta_b: 0.9941\n",
      "layer 3:\n",
      "eta_w: 0.9950, eta_b: 0.9970\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 159 of 200\n",
      "loss: 59.32\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9910, eta_b: 0.9917\n",
      "layer 2:\n",
      "eta_w: 0.9924, eta_b: 0.9940\n",
      "layer 3:\n",
      "eta_w: 0.9950, eta_b: 0.9970\n",
      "elapsed time: 36.3s\n",
      "\n",
      "Epoch 160 of 200\n",
      "loss: 59.28\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9904, eta_b: 0.9917\n",
      "layer 2:\n",
      "eta_w: 0.9924, eta_b: 0.9940\n",
      "layer 3:\n",
      "eta_w: 0.9948, eta_b: 0.9969\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 161 of 200\n",
      "loss: 59.23\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9895, eta_b: 0.9917\n",
      "layer 2:\n",
      "eta_w: 0.9920, eta_b: 0.9940\n",
      "layer 3:\n",
      "eta_w: 0.9949, eta_b: 0.9969\n",
      "elapsed time: 36.2s\n",
      "\n",
      "Epoch 162 of 200\n",
      "loss: 59.19\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9899, eta_b: 0.9915\n",
      "layer 2:\n",
      "eta_w: 0.9922, eta_b: 0.9939\n",
      "layer 3:\n",
      "eta_w: 0.9948, eta_b: 0.9968\n",
      "elapsed time: 35.8s\n",
      "\n",
      "Epoch 163 of 200\n",
      "loss: 59.15\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9895, eta_b: 0.9915\n",
      "layer 2:\n",
      "eta_w: 0.9921, eta_b: 0.9938\n",
      "layer 3:\n",
      "eta_w: 0.9946, eta_b: 0.9968\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 164 of 200\n",
      "loss: 59.12\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9898, eta_b: 0.9914\n",
      "layer 2:\n",
      "eta_w: 0.9921, eta_b: 0.9937\n",
      "layer 3:\n",
      "eta_w: 0.9947, eta_b: 0.9967\n",
      "elapsed time: 36.1s\n",
      "\n",
      "Epoch 165 of 200\n",
      "loss: 59.09\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9898, eta_b: 0.9914\n",
      "layer 2:\n",
      "eta_w: 0.9917, eta_b: 0.9937\n",
      "layer 3:\n",
      "eta_w: 0.9946, eta_b: 0.9966\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 166 of 200\n",
      "loss: 59.08\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9897, eta_b: 0.9914\n",
      "layer 2:\n",
      "eta_w: 0.9917, eta_b: 0.9936\n",
      "layer 3:\n",
      "eta_w: 0.9947, eta_b: 0.9965\n",
      "elapsed time: 35.7s\n",
      "\n",
      "Epoch 167 of 200\n",
      "loss: 59.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9889, eta_b: 0.9913\n",
      "layer 2:\n",
      "eta_w: 0.9917, eta_b: 0.9935\n",
      "layer 3:\n",
      "eta_w: 0.9946, eta_b: 0.9965\n",
      "elapsed time: 36.3s\n",
      "\n",
      "Epoch 168 of 200\n",
      "loss: 58.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9903, eta_b: 0.9913\n",
      "layer 2:\n",
      "eta_w: 0.9919, eta_b: 0.9935\n",
      "layer 3:\n",
      "eta_w: 0.9945, eta_b: 0.9965\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 169 of 200\n",
      "loss: 58.96\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9906, eta_b: 0.9911\n",
      "layer 2:\n",
      "eta_w: 0.9920, eta_b: 0.9934\n",
      "layer 3:\n",
      "eta_w: 0.9944, eta_b: 0.9964\n",
      "elapsed time: 36.3s\n",
      "\n",
      "Epoch 170 of 200\n",
      "loss: 58.93\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9898, eta_b: 0.9911\n",
      "layer 2:\n",
      "eta_w: 0.9920, eta_b: 0.9934\n",
      "layer 3:\n",
      "eta_w: 0.9945, eta_b: 0.9964\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 171 of 200\n",
      "loss: 58.92\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9913, eta_b: 0.9910\n",
      "layer 2:\n",
      "eta_w: 0.9927, eta_b: 0.9933\n",
      "layer 3:\n",
      "eta_w: 0.9947, eta_b: 0.9964\n",
      "elapsed time: 36.2s\n",
      "\n",
      "Epoch 172 of 200\n",
      "loss: 58.87\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9901, eta_b: 0.9910\n",
      "layer 2:\n",
      "eta_w: 0.9925, eta_b: 0.9933\n",
      "layer 3:\n",
      "eta_w: 0.9943, eta_b: 0.9964\n",
      "elapsed time: 35.8s\n",
      "\n",
      "Epoch 173 of 200\n",
      "loss: 58.84\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9906, eta_b: 0.9908\n",
      "layer 2:\n",
      "eta_w: 0.9923, eta_b: 0.9933\n",
      "layer 3:\n",
      "eta_w: 0.9943, eta_b: 0.9963\n",
      "elapsed time: 35.4s\n",
      "\n",
      "Epoch 174 of 200\n",
      "loss: 58.80\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9901, eta_b: 0.9908\n",
      "layer 2:\n",
      "eta_w: 0.9922, eta_b: 0.9932\n",
      "layer 3:\n",
      "eta_w: 0.9943, eta_b: 0.9963\n",
      "elapsed time: 36.2s\n",
      "\n",
      "Epoch 175 of 200\n",
      "loss: 58.78\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9907, eta_b: 0.9908\n",
      "layer 2:\n",
      "eta_w: 0.9923, eta_b: 0.9932\n",
      "layer 3:\n",
      "eta_w: 0.9943, eta_b: 0.9963\n",
      "elapsed time: 35.7s\n",
      "\n",
      "Epoch 176 of 200\n",
      "loss: 58.74\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9902, eta_b: 0.9908\n",
      "layer 2:\n",
      "eta_w: 0.9919, eta_b: 0.9931\n",
      "layer 3:\n",
      "eta_w: 0.9942, eta_b: 0.9962\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 177 of 200\n",
      "loss: 58.71\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9895, eta_b: 0.9907\n",
      "layer 2:\n",
      "eta_w: 0.9917, eta_b: 0.9931\n",
      "layer 3:\n",
      "eta_w: 0.9942, eta_b: 0.9962\n",
      "elapsed time: 36.1s\n",
      "\n",
      "Epoch 178 of 200\n",
      "loss: 58.69\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9901, eta_b: 0.9906\n",
      "layer 2:\n",
      "eta_w: 0.9916, eta_b: 0.9930\n",
      "layer 3:\n",
      "eta_w: 0.9942, eta_b: 0.9962\n",
      "elapsed time: 36.0s\n",
      "\n",
      "Epoch 179 of 200\n",
      "loss: 58.68\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9906, eta_b: 0.9905\n",
      "layer 2:\n",
      "eta_w: 0.9918, eta_b: 0.9930\n",
      "layer 3:\n",
      "eta_w: 0.9943, eta_b: 0.9961\n",
      "elapsed time: 36.5s\n",
      "\n",
      "Epoch 180 of 200\n",
      "loss: 58.65\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9912, eta_b: 0.9906\n",
      "layer 2:\n",
      "eta_w: 0.9922, eta_b: 0.9930\n",
      "layer 3:\n",
      "eta_w: 0.9941, eta_b: 0.9961\n",
      "elapsed time: 35.7s\n",
      "\n",
      "Epoch 181 of 200\n",
      "loss: 58.64\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9910, eta_b: 0.9906\n",
      "layer 2:\n",
      "eta_w: 0.9925, eta_b: 0.9930\n",
      "layer 3:\n",
      "eta_w: 0.9943, eta_b: 0.9961\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 182 of 200\n",
      "loss: 58.61\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9912, eta_b: 0.9906\n",
      "layer 2:\n",
      "eta_w: 0.9923, eta_b: 0.9930\n",
      "layer 3:\n",
      "eta_w: 0.9942, eta_b: 0.9961\n",
      "elapsed time: 35.7s\n",
      "\n",
      "Epoch 183 of 200\n",
      "loss: 58.59\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9907, eta_b: 0.9909\n",
      "layer 2:\n",
      "eta_w: 0.9923, eta_b: 0.9930\n",
      "layer 3:\n",
      "eta_w: 0.9942, eta_b: 0.9961\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 184 of 200\n",
      "loss: 58.54\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9904, eta_b: 0.9909\n",
      "layer 2:\n",
      "eta_w: 0.9919, eta_b: 0.9930\n",
      "layer 3:\n",
      "eta_w: 0.9940, eta_b: 0.9961\n",
      "elapsed time: 34.6s\n",
      "\n",
      "Epoch 185 of 200\n",
      "loss: 58.50\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9901, eta_b: 0.9907\n",
      "layer 2:\n",
      "eta_w: 0.9917, eta_b: 0.9929\n",
      "layer 3:\n",
      "eta_w: 0.9939, eta_b: 0.9960\n",
      "elapsed time: 34.8s\n",
      "\n",
      "Epoch 186 of 200\n",
      "loss: 58.46\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9900, eta_b: 0.9904\n",
      "layer 2:\n",
      "eta_w: 0.9919, eta_b: 0.9928\n",
      "layer 3:\n",
      "eta_w: 0.9938, eta_b: 0.9959\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 187 of 200\n",
      "loss: 58.44\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9896, eta_b: 0.9903\n",
      "layer 2:\n",
      "eta_w: 0.9919, eta_b: 0.9928\n",
      "layer 3:\n",
      "eta_w: 0.9939, eta_b: 0.9959\n",
      "elapsed time: 34.5s\n",
      "\n",
      "Epoch 188 of 200\n",
      "loss: 58.41\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9889, eta_b: 0.9902\n",
      "layer 2:\n",
      "eta_w: 0.9918, eta_b: 0.9927\n",
      "layer 3:\n",
      "eta_w: 0.9938, eta_b: 0.9958\n",
      "elapsed time: 36.1s\n",
      "\n",
      "Epoch 189 of 200\n",
      "loss: 58.38\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9891, eta_b: 0.9901\n",
      "layer 2:\n",
      "eta_w: 0.9919, eta_b: 0.9926\n",
      "layer 3:\n",
      "eta_w: 0.9937, eta_b: 0.9958\n",
      "elapsed time: 35.4s\n",
      "\n",
      "Epoch 190 of 200\n",
      "loss: 58.37\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9895, eta_b: 0.9902\n",
      "layer 2:\n",
      "eta_w: 0.9923, eta_b: 0.9925\n",
      "layer 3:\n",
      "eta_w: 0.9937, eta_b: 0.9958\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 191 of 200\n",
      "loss: 58.34\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9896, eta_b: 0.9902\n",
      "layer 2:\n",
      "eta_w: 0.9918, eta_b: 0.9925\n",
      "layer 3:\n",
      "eta_w: 0.9938, eta_b: 0.9957\n",
      "elapsed time: 34.7s\n",
      "\n",
      "Epoch 192 of 200\n",
      "loss: 58.32\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9892, eta_b: 0.9902\n",
      "layer 2:\n",
      "eta_w: 0.9923, eta_b: 0.9924\n",
      "layer 3:\n",
      "eta_w: 0.9936, eta_b: 0.9957\n",
      "elapsed time: 35.0s\n",
      "\n",
      "Epoch 193 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 58.28\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9893, eta_b: 0.9902\n",
      "layer 2:\n",
      "eta_w: 0.9920, eta_b: 0.9924\n",
      "layer 3:\n",
      "eta_w: 0.9935, eta_b: 0.9957\n",
      "elapsed time: 35.8s\n",
      "\n",
      "Epoch 194 of 200\n",
      "loss: 58.26\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9894, eta_b: 0.9901\n",
      "layer 2:\n",
      "eta_w: 0.9916, eta_b: 0.9924\n",
      "layer 3:\n",
      "eta_w: 0.9935, eta_b: 0.9956\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 195 of 200\n",
      "loss: 58.24\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9895, eta_b: 0.9901\n",
      "layer 2:\n",
      "eta_w: 0.9912, eta_b: 0.9923\n",
      "layer 3:\n",
      "eta_w: 0.9934, eta_b: 0.9956\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 196 of 200\n",
      "loss: 58.23\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9890, eta_b: 0.9901\n",
      "layer 2:\n",
      "eta_w: 0.9915, eta_b: 0.9923\n",
      "layer 3:\n",
      "eta_w: 0.9936, eta_b: 0.9956\n",
      "elapsed time: 35.1s\n",
      "\n",
      "Epoch 197 of 200\n",
      "loss: 58.20\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9888, eta_b: 0.9901\n",
      "layer 2:\n",
      "eta_w: 0.9915, eta_b: 0.9923\n",
      "layer 3:\n",
      "eta_w: 0.9934, eta_b: 0.9956\n",
      "elapsed time: 35.3s\n",
      "\n",
      "Epoch 198 of 200\n",
      "loss: 58.19\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9893, eta_b: 0.9902\n",
      "layer 2:\n",
      "eta_w: 0.9916, eta_b: 0.9923\n",
      "layer 3:\n",
      "eta_w: 0.9935, eta_b: 0.9956\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 199 of 200\n",
      "loss: 58.16\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9890, eta_b: 0.9903\n",
      "layer 2:\n",
      "eta_w: 0.9917, eta_b: 0.9923\n",
      "layer 3:\n",
      "eta_w: 0.9935, eta_b: 0.9955\n",
      "elapsed time: 35.2s\n",
      "\n",
      "Epoch 200 of 200\n",
      "loss: 58.12\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 0.9893, eta_b: 0.9903\n",
      "layer 2:\n",
      "eta_w: 0.9915, eta_b: 0.9923\n",
      "layer 3:\n",
      "eta_w: 0.9933, eta_b: 0.9955\n",
      "elapsed time: 35.2s\n",
      "\n",
      "\n",
      "reparam_0.1\n",
      "Epoch 1 of 200\n",
      "loss: 115.16\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.7s\n",
      "\n",
      "Epoch 2 of 200\n",
      "loss: 109.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 3 of 200\n",
      "loss: 109.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 4 of 200\n",
      "loss: 109.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 5 of 200\n",
      "loss: 109.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 6 of 200\n",
      "loss: 109.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 7 of 200\n",
      "loss: 108.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 8 of 200\n",
      "loss: 108.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 9 of 200\n",
      "loss: 108.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 10 of 200\n",
      "loss: 105.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 11 of 200\n",
      "loss: 97.97\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 12 of 200\n",
      "loss: 92.69\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 13 of 200\n",
      "loss: 88.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.1s\n",
      "\n",
      "Epoch 14 of 200\n",
      "loss: 85.60\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.0s\n",
      "\n",
      "Epoch 15 of 200\n",
      "loss: 82.90\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 16 of 200\n",
      "loss: 80.62\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.0s\n",
      "\n",
      "Epoch 17 of 200\n",
      "loss: 78.75\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.0s\n",
      "\n",
      "Epoch 18 of 200\n",
      "loss: 77.30\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 19 of 200\n",
      "loss: 76.10\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 20 of 200\n",
      "loss: 75.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.7s\n",
      "\n",
      "Epoch 21 of 200\n",
      "loss: 74.16\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 22 of 200\n",
      "loss: 73.37\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.5s\n",
      "\n",
      "Epoch 23 of 200\n",
      "loss: 72.68\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.6s\n",
      "\n",
      "Epoch 24 of 200\n",
      "loss: 72.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.5s\n",
      "\n",
      "Epoch 25 of 200\n",
      "loss: 71.49\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.4s\n",
      "\n",
      "Epoch 26 of 200\n",
      "loss: 71.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.4s\n",
      "\n",
      "Epoch 27 of 200\n",
      "loss: 70.54\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 28 of 200\n",
      "loss: 70.11\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.1s\n",
      "\n",
      "Epoch 29 of 200\n",
      "loss: 69.72\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 30 of 200\n",
      "loss: 69.36\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 31 of 200\n",
      "loss: 69.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.0s\n",
      "\n",
      "Epoch 32 of 200\n",
      "loss: 68.72\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 33 of 200\n",
      "loss: 68.42\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.0s\n",
      "\n",
      "Epoch 34 of 200\n",
      "loss: 68.16\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.1s\n",
      "\n",
      "Epoch 35 of 200\n",
      "loss: 67.91\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 36 of 200\n",
      "loss: 67.66\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 37 of 200\n",
      "loss: 67.44\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 38 of 200\n",
      "loss: 67.23\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.7s\n",
      "\n",
      "Epoch 39 of 200\n",
      "loss: 67.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.3s\n",
      "\n",
      "Epoch 40 of 200\n",
      "loss: 66.81\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 41 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 66.63\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.7s\n",
      "\n",
      "Epoch 42 of 200\n",
      "loss: 66.45\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 43 of 200\n",
      "loss: 66.26\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 44 of 200\n",
      "loss: 66.09\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 45 of 200\n",
      "loss: 65.91\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 46 of 200\n",
      "loss: 65.78\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 47 of 200\n",
      "loss: 65.63\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 48 of 200\n",
      "loss: 65.46\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 49 of 200\n",
      "loss: 65.32\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 50 of 200\n",
      "loss: 65.18\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 51 of 200\n",
      "loss: 65.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 52 of 200\n",
      "loss: 64.93\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 53 of 200\n",
      "loss: 64.80\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 54 of 200\n",
      "loss: 64.68\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.7s\n",
      "\n",
      "Epoch 55 of 200\n",
      "loss: 64.57\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 56 of 200\n",
      "loss: 64.46\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 57 of 200\n",
      "loss: 64.35\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 58 of 200\n",
      "loss: 64.24\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 59 of 200\n",
      "loss: 64.12\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 60 of 200\n",
      "loss: 64.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 61 of 200\n",
      "loss: 63.92\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 62 of 200\n",
      "loss: 63.84\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 63 of 200\n",
      "loss: 63.72\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 64 of 200\n",
      "loss: 63.63\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 65 of 200\n",
      "loss: 63.55\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 66 of 200\n",
      "loss: 63.46\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 67 of 200\n",
      "loss: 63.38\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 68 of 200\n",
      "loss: 63.30\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 69 of 200\n",
      "loss: 63.20\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 70 of 200\n",
      "loss: 63.14\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 71 of 200\n",
      "loss: 63.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 72 of 200\n",
      "loss: 62.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 73 of 200\n",
      "loss: 62.91\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 74 of 200\n",
      "loss: 62.84\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 75 of 200\n",
      "loss: 62.76\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.1s\n",
      "\n",
      "Epoch 76 of 200\n",
      "loss: 62.70\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.0s\n",
      "\n",
      "Epoch 77 of 200\n",
      "loss: 62.64\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.0s\n",
      "\n",
      "Epoch 78 of 200\n",
      "loss: 62.56\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.0s\n",
      "\n",
      "Epoch 79 of 200\n",
      "loss: 62.50\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.1s\n",
      "\n",
      "Epoch 80 of 200\n",
      "loss: 62.43\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.0s\n",
      "\n",
      "Epoch 81 of 200\n",
      "loss: 62.38\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.1s\n",
      "\n",
      "Epoch 82 of 200\n",
      "loss: 62.32\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.2s\n",
      "\n",
      "Epoch 83 of 200\n",
      "loss: 62.25\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.2s\n",
      "\n",
      "Epoch 84 of 200\n",
      "loss: 62.18\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 14.9s\n",
      "\n",
      "Epoch 85 of 200\n",
      "loss: 62.11\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.2s\n",
      "\n",
      "Epoch 86 of 200\n",
      "loss: 62.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.2s\n",
      "\n",
      "Epoch 87 of 200\n",
      "loss: 61.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.2s\n",
      "\n",
      "Epoch 88 of 200\n",
      "loss: 61.93\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 89 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 61.87\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.4s\n",
      "\n",
      "Epoch 90 of 200\n",
      "loss: 61.80\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.1s\n",
      "\n",
      "Epoch 91 of 200\n",
      "loss: 61.74\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.0s\n",
      "\n",
      "Epoch 92 of 200\n",
      "loss: 61.68\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.0s\n",
      "\n",
      "Epoch 93 of 200\n",
      "loss: 61.63\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.1s\n",
      "\n",
      "Epoch 94 of 200\n",
      "loss: 61.58\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 95 of 200\n",
      "loss: 61.52\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 96 of 200\n",
      "loss: 61.48\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 97 of 200\n",
      "loss: 61.43\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 98 of 200\n",
      "loss: 61.38\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.1s\n",
      "\n",
      "Epoch 99 of 200\n",
      "loss: 61.33\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.1s\n",
      "\n",
      "Epoch 100 of 200\n",
      "loss: 61.28\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 101 of 200\n",
      "loss: 61.23\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.1s\n",
      "\n",
      "Epoch 102 of 200\n",
      "loss: 61.19\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 103 of 200\n",
      "loss: 61.13\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.2s\n",
      "\n",
      "Epoch 104 of 200\n",
      "loss: 61.08\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.2s\n",
      "\n",
      "Epoch 105 of 200\n",
      "loss: 61.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.2s\n",
      "\n",
      "Epoch 106 of 200\n",
      "loss: 60.96\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.3s\n",
      "\n",
      "Epoch 107 of 200\n",
      "loss: 60.90\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.4s\n",
      "\n",
      "Epoch 108 of 200\n",
      "loss: 60.84\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.3s\n",
      "\n",
      "Epoch 109 of 200\n",
      "loss: 60.81\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 110 of 200\n",
      "loss: 60.76\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 111 of 200\n",
      "loss: 60.74\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 112 of 200\n",
      "loss: 60.70\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.1s\n",
      "\n",
      "Epoch 113 of 200\n",
      "loss: 60.66\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 114 of 200\n",
      "loss: 60.62\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 115 of 200\n",
      "loss: 60.55\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 116 of 200\n",
      "loss: 60.52\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 117 of 200\n",
      "loss: 60.47\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 118 of 200\n",
      "loss: 60.42\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 119 of 200\n",
      "loss: 60.39\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.3s\n",
      "\n",
      "Epoch 120 of 200\n",
      "loss: 60.34\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.3s\n",
      "\n",
      "Epoch 121 of 200\n",
      "loss: 60.29\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 122 of 200\n",
      "loss: 60.26\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 123 of 200\n",
      "loss: 60.21\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 124 of 200\n",
      "loss: 60.18\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 125 of 200\n",
      "loss: 60.14\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.9s\n",
      "\n",
      "Epoch 126 of 200\n",
      "loss: 60.10\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.1s\n",
      "\n",
      "Epoch 127 of 200\n",
      "loss: 60.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 128 of 200\n",
      "loss: 60.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.1s\n",
      "\n",
      "Epoch 129 of 200\n",
      "loss: 59.97\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 130 of 200\n",
      "loss: 59.92\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.5s\n",
      "\n",
      "Epoch 131 of 200\n",
      "loss: 59.88\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 132 of 200\n",
      "loss: 59.84\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 133 of 200\n",
      "loss: 59.81\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.3s\n",
      "\n",
      "Epoch 134 of 200\n",
      "loss: 59.77\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 135 of 200\n",
      "loss: 59.75\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.3s\n",
      "\n",
      "Epoch 136 of 200\n",
      "loss: 59.71\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 137 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 59.69\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.3s\n",
      "\n",
      "Epoch 138 of 200\n",
      "loss: 59.66\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.1s\n",
      "\n",
      "Epoch 139 of 200\n",
      "loss: 59.62\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.3s\n",
      "\n",
      "Epoch 140 of 200\n",
      "loss: 59.58\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.1s\n",
      "\n",
      "Epoch 141 of 200\n",
      "loss: 59.55\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.9s\n",
      "\n",
      "Epoch 142 of 200\n",
      "loss: 59.54\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.3s\n",
      "\n",
      "Epoch 143 of 200\n",
      "loss: 59.50\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.3s\n",
      "\n",
      "Epoch 144 of 200\n",
      "loss: 59.45\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.2s\n",
      "\n",
      "Epoch 145 of 200\n",
      "loss: 59.41\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.4s\n",
      "\n",
      "Epoch 146 of 200\n",
      "loss: 59.38\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.2s\n",
      "\n",
      "Epoch 147 of 200\n",
      "loss: 59.35\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.5s\n",
      "\n",
      "Epoch 148 of 200\n",
      "loss: 59.31\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.9s\n",
      "\n",
      "Epoch 149 of 200\n",
      "loss: 59.28\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.2s\n",
      "\n",
      "Epoch 150 of 200\n",
      "loss: 59.25\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.0s\n",
      "\n",
      "Epoch 151 of 200\n",
      "loss: 59.20\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.9s\n",
      "\n",
      "Epoch 152 of 200\n",
      "loss: 59.16\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.2s\n",
      "\n",
      "Epoch 153 of 200\n",
      "loss: 59.11\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.1s\n",
      "\n",
      "Epoch 154 of 200\n",
      "loss: 59.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.2s\n",
      "\n",
      "Epoch 155 of 200\n",
      "loss: 59.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.1s\n",
      "\n",
      "Epoch 156 of 200\n",
      "loss: 59.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.1s\n",
      "\n",
      "Epoch 157 of 200\n",
      "loss: 58.98\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.3s\n",
      "\n",
      "Epoch 158 of 200\n",
      "loss: 58.96\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.1s\n",
      "\n",
      "Epoch 159 of 200\n",
      "loss: 58.92\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.0s\n",
      "\n",
      "Epoch 160 of 200\n",
      "loss: 58.90\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.0s\n",
      "\n",
      "Epoch 161 of 200\n",
      "loss: 58.87\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.0s\n",
      "\n",
      "Epoch 162 of 200\n",
      "loss: 58.84\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.1s\n",
      "\n",
      "Epoch 163 of 200\n",
      "loss: 58.80\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.9s\n",
      "\n",
      "Epoch 164 of 200\n",
      "loss: 58.77\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.2s\n",
      "\n",
      "Epoch 165 of 200\n",
      "loss: 58.74\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 17.0s\n",
      "\n",
      "Epoch 166 of 200\n",
      "loss: 58.72\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.2s\n",
      "\n",
      "Epoch 167 of 200\n",
      "loss: 58.68\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.8s\n",
      "\n",
      "Epoch 168 of 200\n",
      "loss: 58.64\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.1s\n",
      "\n",
      "Epoch 169 of 200\n",
      "loss: 58.60\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.6s\n",
      "\n",
      "Epoch 170 of 200\n",
      "loss: 58.57\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.0s\n",
      "\n",
      "Epoch 171 of 200\n",
      "loss: 58.55\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 15.5s\n",
      "\n",
      "Epoch 172 of 200\n",
      "loss: 58.51\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.4s\n",
      "\n",
      "Epoch 173 of 200\n",
      "loss: 58.49\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 16.0s\n",
      "\n",
      "Epoch 174 of 200\n",
      "loss: 91.23\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.8s\n",
      "\n",
      "Epoch 23 of 200\n",
      "loss: 91.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.2s\n",
      "\n",
      "Epoch 24 of 200\n",
      "loss: 90.92\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.3s\n",
      "\n",
      "Epoch 25 of 200\n",
      "loss: 90.76\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.5s\n",
      "\n",
      "Epoch 26 of 200\n",
      "loss: 90.62\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 27 of 200\n",
      "loss: 90.50\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 28 of 200\n",
      "loss: 90.38\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 29 of 200\n",
      "loss: 90.28\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.4s\n",
      "\n",
      "Epoch 30 of 200\n",
      "loss: 90.19\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 31 of 200\n",
      "loss: 90.10\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 32 of 200\n",
      "loss: 90.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 33 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 89.92\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 34 of 200\n",
      "loss: 89.82\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.3s\n",
      "\n",
      "Epoch 35 of 200\n",
      "loss: 89.76\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.4s\n",
      "\n",
      "Epoch 36 of 200\n",
      "loss: 89.70\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 37 of 200\n",
      "loss: 89.62\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 38 of 200\n",
      "loss: 89.57\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.6s\n",
      "\n",
      "Epoch 39 of 200\n",
      "loss: 89.52\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 40 of 200\n",
      "loss: 89.45\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.1s\n",
      "\n",
      "Epoch 41 of 200\n",
      "loss: 89.38\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.4s\n",
      "\n",
      "Epoch 42 of 200\n",
      "loss: 89.34\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.9s\n",
      "\n",
      "Epoch 43 of 200\n",
      "loss: 89.28\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.4s\n",
      "\n",
      "Epoch 44 of 200\n",
      "loss: 89.22\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.7s\n",
      "\n",
      "Epoch 45 of 200\n",
      "loss: 89.18\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.6s\n",
      "\n",
      "Epoch 46 of 200\n",
      "loss: 89.12\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.0s\n",
      "\n",
      "Epoch 47 of 200\n",
      "loss: 89.08\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 48 of 200\n",
      "loss: 89.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 49 of 200\n",
      "loss: 88.99\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 50 of 200\n",
      "loss: 88.95\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 51 of 200\n",
      "loss: 88.92\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 52 of 200\n",
      "loss: 88.88\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 53 of 200\n",
      "loss: 88.84\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 54 of 200\n",
      "loss: 88.81\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 55 of 200\n",
      "loss: 88.77\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 56 of 200\n",
      "loss: 88.76\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 57 of 200\n",
      "loss: 88.74\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 58 of 200\n",
      "loss: 88.71\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 59 of 200\n",
      "loss: 88.67\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 60 of 200\n",
      "loss: 88.64\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 61 of 200\n",
      "loss: 88.61\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.1s\n",
      "\n",
      "Epoch 62 of 200\n",
      "loss: 88.59\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.7s\n",
      "\n",
      "Epoch 63 of 200\n",
      "loss: 88.57\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 64 of 200\n",
      "loss: 88.55\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.9s\n",
      "\n",
      "Epoch 65 of 200\n",
      "loss: 88.52\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 66 of 200\n",
      "loss: 88.51\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.9s\n",
      "\n",
      "Epoch 67 of 200\n",
      "loss: 88.49\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.2s\n",
      "\n",
      "Epoch 68 of 200\n",
      "loss: 88.48\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.0s\n",
      "\n",
      "Epoch 69 of 200\n",
      "loss: 88.45\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.5s\n",
      "\n",
      "Epoch 70 of 200\n",
      "loss: 88.44\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 71 of 200\n",
      "loss: 88.43\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 72 of 200\n",
      "loss: 88.42\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 73 of 200\n",
      "loss: 88.40\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 74 of 200\n",
      "loss: 88.38\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 75 of 200\n",
      "loss: 88.35\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.6s\n",
      "\n",
      "Epoch 76 of 200\n",
      "loss: 88.33\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 77 of 200\n",
      "loss: 88.31\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 78 of 200\n",
      "loss: 88.29\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 79 of 200\n",
      "loss: 88.29\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 80 of 200\n",
      "loss: 88.27\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 81 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 88.25\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 82 of 200\n",
      "loss: 88.24\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 83 of 200\n",
      "loss: 88.21\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.4s\n",
      "\n",
      "Epoch 84 of 200\n",
      "loss: 88.20\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.5s\n",
      "\n",
      "Epoch 85 of 200\n",
      "loss: 88.20\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.9s\n",
      "\n",
      "Epoch 86 of 200\n",
      "loss: 88.18\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.0s\n",
      "\n",
      "Epoch 87 of 200\n",
      "loss: 88.17\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.7s\n",
      "\n",
      "Epoch 88 of 200\n",
      "loss: 88.17\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.2s\n",
      "\n",
      "Epoch 89 of 200\n",
      "loss: 88.15\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.7s\n",
      "\n",
      "Epoch 90 of 200\n",
      "loss: 88.15\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 91 of 200\n",
      "loss: 88.15\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.1s\n",
      "\n",
      "Epoch 92 of 200\n",
      "loss: 88.13\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.3s\n",
      "\n",
      "Epoch 93 of 200\n",
      "loss: 88.12\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 94 of 200\n",
      "loss: 88.12\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.3s\n",
      "\n",
      "Epoch 95 of 200\n",
      "loss: 88.11\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.3s\n",
      "\n",
      "Epoch 96 of 200\n",
      "loss: 88.11\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 97 of 200\n",
      "loss: 88.11\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 98 of 200\n",
      "loss: 88.10\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 99 of 200\n",
      "loss: 88.09\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 100 of 200\n",
      "loss: 88.10\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 101 of 200\n",
      "loss: 88.09\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 102 of 200\n",
      "loss: 88.08\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 103 of 200\n",
      "loss: 88.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 104 of 200\n",
      "loss: 88.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 105 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.5s\n",
      "\n",
      "Epoch 106 of 200\n",
      "loss: 88.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.9s\n",
      "\n",
      "Epoch 107 of 200\n",
      "loss: 88.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.9s\n",
      "\n",
      "Epoch 108 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.7s\n",
      "\n",
      "Epoch 109 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.7s\n",
      "\n",
      "Epoch 110 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.1s\n",
      "\n",
      "Epoch 111 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 112 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.4s\n",
      "\n",
      "Epoch 113 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.2s\n",
      "\n",
      "Epoch 114 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 115 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.4s\n",
      "\n",
      "Epoch 116 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 117 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 118 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 119 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.3s\n",
      "\n",
      "Epoch 120 of 200\n",
      "loss: 88.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.4s\n",
      "\n",
      "Epoch 121 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 122 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.6s\n",
      "\n",
      "Epoch 123 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.3s\n",
      "\n",
      "Epoch 124 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 125 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 126 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.6s\n",
      "\n",
      "Epoch 127 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.5s\n",
      "\n",
      "Epoch 128 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.2s\n",
      "\n",
      "Epoch 129 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.1s\n",
      "\n",
      "Epoch 130 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 131 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.3s\n",
      "\n",
      "Epoch 132 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.1s\n",
      "\n",
      "Epoch 133 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.1s\n",
      "\n",
      "Epoch 134 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 135 of 200\n",
      "loss: 88.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.7s\n",
      "\n",
      "Epoch 136 of 200\n",
      "loss: 88.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.6s\n",
      "\n",
      "Epoch 137 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 138 of 200\n",
      "loss: 88.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 139 of 200\n",
      "loss: 88.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.5s\n",
      "\n",
      "Epoch 140 of 200\n",
      "loss: 88.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 141 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 142 of 200\n",
      "loss: 88.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 143 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.5s\n",
      "\n",
      "Epoch 144 of 200\n",
      "loss: 88.00\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 145 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 146 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.3s\n",
      "\n",
      "Epoch 147 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.3s\n",
      "\n",
      "Epoch 148 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 149 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 150 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.1s\n",
      "\n",
      "Epoch 151 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 152 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.0s\n",
      "\n",
      "Epoch 153 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 154 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 155 of 200\n",
      "loss: 88.01\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.3s\n",
      "\n",
      "Epoch 156 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.2s\n",
      "\n",
      "Epoch 157 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 158 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 159 of 200\n",
      "loss: 88.02\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.4s\n",
      "\n",
      "Epoch 160 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.1s\n",
      "\n",
      "Epoch 161 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.7s\n",
      "\n",
      "Epoch 162 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.7s\n",
      "\n",
      "Epoch 163 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 164 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.7s\n",
      "\n",
      "Epoch 165 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.9s\n",
      "\n",
      "Epoch 166 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 167 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.7s\n",
      "\n",
      "Epoch 168 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.6s\n",
      "\n",
      "Epoch 169 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 170 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.3s\n",
      "\n",
      "Epoch 171 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.0s\n",
      "\n",
      "Epoch 172 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.6s\n",
      "\n",
      "Epoch 173 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.0s\n",
      "\n",
      "Epoch 174 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.3s\n",
      "\n",
      "Epoch 175 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 176 of 200\n",
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.9s\n",
      "\n",
      "Epoch 177 of 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 88.04\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.1s\n",
      "\n",
      "Epoch 178 of 200\n",
      "loss: 88.03\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 179 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.4s\n",
      "\n",
      "Epoch 180 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.9s\n",
      "\n",
      "Epoch 181 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.4s\n",
      "\n",
      "Epoch 182 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 22.0s\n",
      "\n",
      "Epoch 183 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 184 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 185 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 186 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 187 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.2s\n",
      "\n",
      "Epoch 188 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 189 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 21.0s\n",
      "\n",
      "Epoch 190 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 191 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.7s\n",
      "\n",
      "Epoch 192 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 20.8s\n",
      "\n",
      "Epoch 193 of 200\n",
      "loss: 88.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 194 of 200\n",
      "loss: 88.07\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.7s\n",
      "\n",
      "Epoch 195 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.6s\n",
      "\n",
      "Epoch 196 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.6s\n",
      "\n",
      "Epoch 197 of 200\n",
      "loss: 88.06\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.6s\n",
      "\n",
      "Epoch 198 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.9s\n",
      "\n",
      "Epoch 199 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 18.8s\n",
      "\n",
      "Epoch 200 of 200\n",
      "loss: 88.05\n",
      "block 1:\n",
      "layer 1:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 2:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "layer 3:\n",
      "eta_w: 1.0000, eta_b: 1.0000\n",
      "elapsed time: 19.1s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "num_steps = 500 * 1000\n",
    "num_epochs = num_steps * batch_size // train_loader.dataset.train_data.size(0)\n",
    "#num_epochs = 10\n",
    "num_blocks = 1\n",
    "\n",
    "#opt_modes = ['last_epoch_reward_baseline', 'no_baseline', 'reparam_1.0', 'reparam_0.1', 'reparam_10.']\n",
    "opt_modes = ['rebar_0.1', 'reparam_0.1', 'no_baseline']\n",
    "train_losses = {}\n",
    "\n",
    "learning_rate = 0.0001\n",
    "eta_learning_rate = 1e-11\n",
    "eta_start = 1.0\n",
    "\n",
    "logsigmoid = nn.LogSigmoid()\n",
    "\n",
    "for opt_mode in opt_modes:\n",
    "    print()\n",
    "    print(opt_mode)\n",
    "    train_losses[opt_mode] = []\n",
    "    model = cuda_wrapper(SigmoidBeliefNetwork(input_dim, num_blocks=num_blocks, hidden_dim=200, nonlinear_blocks=True))\n",
    "    if num_blocks > 0:\n",
    "        num_layers = len(model.dense_layers[0])\n",
    "    else:\n",
    "        num_layers = 0\n",
    "        \n",
    "    eta = cuda_wrapper(torch.Tensor(num_blocks, num_layers, 2).fill_(eta_start))\n",
    "    variance_grad_smoothed = cuda_wrapper(torch.Tensor(num_blocks, num_layers, 2).zero_())\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99999))\n",
    "    \n",
    "    alpha = 0.999\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time()\n",
    "        print('Epoch {} of {}'.format(epoch+1, num_epochs))\n",
    "        \n",
    "        torch.manual_seed(42)\n",
    "        \n",
    "        if opt_mode.startswith('reparam') or opt_mode.startswith('rebar'):\n",
    "            sigmoid_temp = float(opt_mode.split('_')[1])\n",
    "        else:\n",
    "            sigmoid_temp = 1.0\n",
    "        \n",
    "        loader = train_loader\n",
    "        num_samples = train_loader.dataset.train_data.size(0)\n",
    "        \n",
    "        cum_losses = 0\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            top, bottom = torch.chunk(\n",
    "                (data.view(data.size(0), -1) > 0.5).float(), 2, dim=1\n",
    "            )\n",
    "            top, bottom = autograd.Variable(cuda_wrapper(top), requires_grad=False), \\\n",
    "                          autograd.Variable(cuda_wrapper(bottom), requires_grad=False)\n",
    "            hard_bottom_logit, soft_bottom_logits, soft_cond_bottom_logits = model(top, sigmoid_temp)\n",
    "\n",
    "            hard_samplewise_loss = -torch.sum(\n",
    "                logsigmoid(hard_bottom_logit) * bottom + logsigmoid(-hard_bottom_logit) * (1 - bottom), dim=1\n",
    "            )\n",
    "            hard_loss = torch.sum(hard_samplewise_loss)\n",
    "\n",
    "            soft_samplewise_losses = []\n",
    "            soft_cond_samplewise_losses = []\n",
    "            soft_losses = []\n",
    "            soft_cond_losses = []\n",
    "            for i in range(num_blocks):\n",
    "                soft_samplewise_losses.append(\n",
    "                    -torch.sum(\n",
    "                        logsigmoid(soft_bottom_logits[i]) * bottom +\\\n",
    "                        logsigmoid(-soft_bottom_logits[i]) * (1 - bottom), dim=1\n",
    "                    )\n",
    "                )\n",
    "                soft_losses.append(torch.sum(soft_samplewise_losses[-1]))\n",
    "                \n",
    "                soft_cond_samplewise_losses.append(\n",
    "                    -torch.sum\n",
    "                    (\n",
    "                        logsigmoid(soft_cond_bottom_logits[i]) * bottom +\\\n",
    "                        logsigmoid(-soft_cond_bottom_logits[i]) * (1 - bottom), dim=1\n",
    "                    )\n",
    "                )\n",
    "                soft_cond_losses.append(torch.sum(soft_cond_samplewise_losses[-1]))\n",
    "            \n",
    "            cum_losses += hard_loss.data.mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if opt_mode in ['no_baseline', 'last_epoch_reward_baseline']:\n",
    "                cost = torch.stack([hard_samplewise_loss.detach()] * model.hidden_dim, dim=1)\n",
    "                if opt_mode == 'no_baseline':\n",
    "                    baseline = 0\n",
    "                elif opt_mode == 'last_epoch_reward_baseline':\n",
    "                    baseline = autograd.Variable(train_losses[opt_mode][-1], requires_grad=False) if epoch > 0 else 0\n",
    "                for sample_log_prob in model.sample_log_probs:\n",
    "                    hard_loss += torch.sum(sample_log_prob * (cost - baseline))\n",
    "                hard_loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            elif opt_mode.startswith('reparam'):\n",
    "                soft_losses[0].backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            elif opt_mode.startswith('rebar'):\n",
    "                for i in range(num_blocks):\n",
    "                    cost = torch.stack(\n",
    "                        [-soft_cond_samplewise_losses[i].detach()] * model.hidden_dim, dim=1\n",
    "                    )\n",
    "                    loss_eta_linear_coef = soft_losses[i] - soft_cond_losses[i]\n",
    "                    loss_eta_linear_coef += torch.sum(model.sample_log_probs[i] * cost)\n",
    "                    loss_eta_linear_coef.backward(retain_graph=True)\n",
    "                    for j in range(i+1, num_blocks):\n",
    "                        for dense_layer in model.dense_layers[j]:\n",
    "                            dense_layer.zero_grad()\n",
    "                \n",
    "                loss_eta_linear_coef_grads = []\n",
    "                for i in range(num_blocks):\n",
    "                    loss_eta_linear_coef_grads.append([])\n",
    "                    for dense_layer in model.dense_layers[i]:\n",
    "                        loss_eta_linear_coef_grads[-1].append([])\n",
    "                        for param in dense_layer.parameters():\n",
    "                            loss_eta_linear_coef_grads[-1][-1].append(param.grad.data.clone())\n",
    "                \n",
    "                for i in range(num_blocks):\n",
    "                    for j, dense_layer in enumerate(model.dense_layers[i]):\n",
    "                        for k, param in enumerate(dense_layer.parameters()):\n",
    "                            param.grad.data *= eta[i, j, k]\n",
    "\n",
    "                cost_additional = torch.stack(\n",
    "                    [hard_samplewise_loss.detach()] * model.hidden_dim, dim=1\n",
    "                )\n",
    "                loss_additional = 0\n",
    "                for sample_log_prob in model.sample_log_probs:\n",
    "                    loss_additional += torch.sum(sample_log_prob * cost_additional)\n",
    "                loss_additional.backward(retain_graph=True)\n",
    "                \n",
    "                loss_grads = []\n",
    "                for i in range(num_blocks):\n",
    "                    loss_grads.append([])\n",
    "                    for dense_layer in model.dense_layers[i]:\n",
    "                        loss_grads[-1].append([])\n",
    "                        for param in dense_layer.parameters():\n",
    "                            loss_grads[-1][-1].append(param.grad.data.clone())\n",
    "                \n",
    "                model.output_layer.zero_grad()\n",
    "                hard_loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                variance_grad = cuda_wrapper(torch.Tensor(num_blocks, num_layers, 2).zero_())\n",
    "                for i in range(num_blocks):\n",
    "                    for j in range(num_layers):\n",
    "                        for k in range(2):\n",
    "                            variance_grad[i, j, k] = torch.sum(\n",
    "                                loss_grads[i][j][k] * loss_eta_linear_coef_grads[i][j][k]\n",
    "                            ) * 2\n",
    "                variance_grad_smoothed = alpha * variance_grad_smoothed + (1 - alpha) * variance_grad\n",
    "                eta = torch.clamp(eta - variance_grad_smoothed * eta_learning_rate, min=0.)\n",
    "                \n",
    "        mean_loss = cum_losses / num_samples\n",
    "        print(\"loss: {:.2f}\".format(mean_loss))\n",
    "        train_losses[opt_mode].append(mean_loss)\n",
    "        \n",
    "        for i in range(num_blocks):\n",
    "            print('block {}:'.format(i + 1))\n",
    "            for j in range(num_layers):\n",
    "                print('layer {}:'.format(j + 1))\n",
    "                print('eta_w: {:.4f}, eta_b: {:.4f}'.format(eta[i, j, 0], eta[i, j, 1]))\n",
    "        \n",
    "        print('elapsed time: {:.1f}s'.format(time() - start_time))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 layer non-linear model:\n",
    "\n",
    "##### 200 epochs corresponds to 500 thousands steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcc068ae550>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAHVCAYAAABMsTJpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XecXWWB//HPmdvvnTs9UzKTZNIb\nJYGQQigJSxFXg6KAWEAsrD8FBH6ruLIiurIqrigKrusiAQQhCirFAoLkpykYEyCQXidkSjKZfsvc\nfn5/nDstmZB279Tv+/W6r3PuuWee58wzeSXzzdMM0zQRERERERGRkSFnsB9AREREREREMkchT0RE\nREREZARRyBMRERERERlBFPJERERERERGEIU8ERERERGREUQhT0REREREZARRyBMRERERERlBFPJE\nRERERERGEIU8ERERERGREcQ+2A9wvEpKSszq6urBfgxCoRA+n2+wH2NUUtsPLrX/4FL7Dx61/eBS\n+w8etf3gUvsPrqHa/hs2bGgyTXPMse4bNiGvurqa9evXD/ZjsHLlSpYsWTLYjzEqqe0Hl9p/cKn9\nB4/afnCp/QeP2n5wqf0H11Btf8Mw9h3PfRquKSIiIiIiMoIo5ImIiIiIiIwgCnkiIiIiIiIjyLCZ\nk9efeDxObW0tkUhkwOrMz89n69atA1bfcOB2u6mqqsLhcAz2o4iIiIiIjHrDOuTV1tbi9/uprq7G\nMIwBqTMQCOD3+wekruHANE2am5upra1l4sSJg/04IiIiIiKj3rAerhmJRCguLh6wgCdHMgyD4uLi\nAe1NFRERERGRoxvWIQ9QwBsC9DMQERERERk6hn3IExERERERkR4KeSIiIiIiIiOIQt4AqK6upqmp\nKePlfvvb32bKlClMnz6dF198sd97HnjgAaZMmYJhGFl5BhERERERGVqG9eqavX3j+c1sqe/IaJmz\nxubx9ffPPq57TdPENE1ycjKbmxOJBHb7kT+mLVu28NRTT7F582bq6+u5+OKL2bFjBzabrc99ixcv\n5n3vex9LlizJ6HOJiIiIiMjQpJ68U1BTU8PMmTP5/Oc/z1lnncUvfvELFi1axFlnncVVV11FMBjs\nvvd73/se8+fPZ/78+ezatQuA559/ngULFjB37lwuvvhiDh48CMDdd9/NjTfeyKWXXsp1113Xb93P\nPvssH/nIR3C5XEycOJEpU6awbt26I+6bO3cu1dXVmf/mRURERERkSBoxPXnH2+OWadu3b2f58uV8\n85vf5Morr+Tll1/G5/Px3e9+l/vuu4+77roLgLy8PNatW8djjz3GrbfeygsvvMB5553Ha6+9hmEY\nPPTQQ9x77718//vfB2DDhg2sWrUKj8fTb711dXUsXLiw+31VVRV1dXXZ/4ZFRERERGRIGzEhb7BM\nmDCBhQsX8sILL7BlyxYWL14MQCwWY9GiRd33XXvttd3H2267DbA2c7/mmmtoaGggFov12Ux82bJl\nRw14YA0PPZy2MhAREREREYW8U+Tz+QArdF1yySU8+eST/d7XO4B1nd98883cfvvtLFu2jJUrV3L3\n3XcfUe7RVFVVsX///u73tbW1jB079mS/DRERERERGSE0Jy9DFi5cyOrVq7vn24XDYXbs2NH9+YoV\nK7qPXT187e3tVFZWAvDoo4+eUH3Lli3jqaeeIhqNsnfvXnbu3Mn8+fMz8a2IiIiIiMgwppCXIWPG\njOGRRx7h2muv5YwzzmDhwoVs27at+/NoNMqCBQu4//77+cEPfgBYC6xcddVVnH/++ZSUlJxQfbNn\nz+bqq69m1qxZvOc97+HBBx/sXlnzve99L/X19QD86Ec/oqqqitraWs444ww+85nPZOg7FhEREREZ\nQUwT4hHobMNIxQf7aU6JhmuegurqajZt2tT9/qKLLuIf//jHEffV1NQA8PWvf73P9SuuuIIrrrji\niPt7D9t8N3feeSd33nnnEdf/8Ic/dJ/fcsst3HLLLcdVnoiIiIjIsJBKQTzc84p1HYP9nIcgGoRo\nB0Q6IBrodZ5+xSOQjHYXX3DG3cAlg/btnSqFPBERERERyY5EzApb0UD62HUesM67rh3+PtoBiSik\n4pBMv+KdVmCLhSHReWLPYXOCKw9cfnDnWeeF1elzPzi8YHeD3QV2N51txVlpjoGikDfEvfjii9xx\nxx19rk2cOJHf/va3g/REIiIiIjLiJOPpnq9QOkx1QiKS7imLWKEqHunpFTtqODsswCVjx1e/zQWu\nXCtwOf3WudMHNgfkOMBmt4KYwwtOLzh86aPXuq/P0QvO3L732p1HVGmaJtFEimg8RUckTntnnI5O\n6xjr2NbPQw4fCnlD3GWXXcZll1022I8hIiIiIkOJaVohrGvIYaQDou09wxFjIStsxbpC2eHvewe1\nUJ+hisfHsIKUqyuQ5VpHb3Wv912fHXaPK6/nvOs+myP9bVnBqzOWJBhN0BGJE4gk6OiM0xlPpkNZ\n+hhLEQn1XIvEU0QT1vtIvJVoojl9nr4nkb6n+33qqN/d7We7Tv5nMwQo5ImIiIiIDKRUMh22uuaH\nBfrOD4sGqN77FnT+sVeIa+87jyzSYQ1lPBab0+rhcvqtY1cPWW5pr6DV6/Ou3jCHG+yevkeHh5TN\nQ8hwE0g66YgmCUWTROLWqzOepDPWcx6Jp+gMJ+ls630tSWc8RSTWTme85Yiv6Ywn6Wc76KMyDHDZ\nc3DZbbgd1tFlz8Ht6DrmUOBx4HIceY8rfY/LnkOe20Gex0F++vXOlg0n//MdAhTyRERERESOJRHt\nP3D1Pu8a7hgL9Vr4I3Tk6zjmk03AgAN5PfPH3HmQWw4l03redx/z+841c6d7ypy5mDYH8aTZ04vV\n7zFJOGaFrXA0SVtrnLbOGG3hOG3hGK3hCG3hDtrSwxlTJxDCnDYraHmcNtwOGx6HdXQ7cijOdeJ1\n2vA47HicOXi6PndaR5/LboUvtx2/24HH2SvAOaxw5rTl9NmPOlMad2S+zIGkkCciIiIiI08q2Ws4\nYq/5Y93DFQO9hjEGewJZ76GNvVdkPJ7hjH3mhXX1kOVCbllPL1nXNYe3O5SlnH6itlzCOR7Cho8g\nHv72+lamzj6TcDRJKJYgHE0QiiUJxxKEoklCrQnCsa7PkumwliCaOEQkfrBPiDuRUNbF77JT4HNQ\n4HFS4HUwrshLodfq5cpzO/Cng5fXZcPrsOFx9gS43ue2nOEdloYrhTwRERERGXz9hrL+FvgIHbla\nY+9Q1nXtuFdfNHoCmeuwYFY0+cgeM3cecUcunTk+QvgI4CFALu0pF7FUDsmUSdI0SaZStIXjtIZi\nNIesXrFgW6I7pIVjVmgLRROEYzGg5chHW3fk1ly2HAOf0+rl8qaPHoeNAq+zeyii29F7uGLfoysd\nvnpf8zhseNM9bV6njTyPA4dN22kPZwp5o1Q0GuW6665jw4YNFBcXs2LFCqqrq4+471Of+hQvvPAC\npaWlffYEFBEREQGs/cpiAWvY4ru9ukLZET1pXSs6ho+zQuOwRTvSx7yqw671rNCYcuQSs3mJ5HiJ\n5niIGG7CeAnhIWw66UwvzhGOJbtXV2xLHzs6rGPXyouhaJJYMgWE069jPK0BhV6rN8zvsuNz2Rlb\n4MTnsuF12vE5bXhdPcfc9PVdWzezaP5Z+Jw9Yc6bHq6YjeGJMrKMnJD3x6/AgbczW2b56XD5d47r\nVtM0MU2TnJzM/q9HIpHAbs/8j+nnP/85hYWF7Nq1i6eeeoo77riDFStWHHHfJz/5SW666Sauu+66\njD+DiIiIDAGmaQWtrvllkTaItFN24DV4bVufaz2v3u87gGOMB+xaQbG7x8zfTyg77Nzl7+5VM525\nRG1eQqabUMpFeyRBazhmBbGw1UvWGrbmkbU3x3t9FicQTRBLpNLPGEq/3p09x+hegCPf66DI52Ri\nia97iGKuy05uOrD1nNtw2nOw5+RgywFbTk53GSczZNF1aBtnjS884a8TgZEU8gZBTU0Nl19+OUuX\nLmXt2rXceuut/PSnPyUajTJ58mSWL19Obm4u1dXVXHPNNbz66qsA/PKXv2TKlCk8//zzfOtb3yIW\ni1FcXMwTTzxBWVkZd999N/X19dTU1FBSUsJ//ud/8olPfIJQyPpL6YEHHuDcc89l5cqVfP3rX6es\nrIw333yTK6+8ktNPP53777+fzs5Ofve73zF58uR+n/3ZZ5/l7rvvBuDDH/4wN910E6ZpHvE/Qxdc\ncAE1NTVZa0MRERE5Rcl4OqC19SwK0mdBkF7vu6+19bonAGbyiGJnAnRtFeZML3vvKQB3PuRVQuks\n69ydvnbYK2r3EzR8BEwPwTgEIgkCkTjBaIJgtNeQxWiScKBn6KI1fLFrrlmUUCxEOFZP8hgTy3xO\na8higddBgddBRb6HAq+DXLe9e0GP3ot/9Mwfy+m55rSR53bgddrUWybD2sgJecfZ45Zp27dvZ/ny\n5Xzzm9/kyiuv5OWXX8bn8/Hd736X++67j7vuuguAvLw81q1bx2OPPcatt97KCy+8wHnnncdrr72G\nYRg89NBD3HvvvXz/+98HYMOGDaxatQqPx0M4HObPf/4zbrebnTt3cu2117J+/XoANm7cyNatWykq\nKmLSpEl85jOfYd26ddx///38+Mc/5oc//GG/z11XV8e4ceMAsNvt5Ofn09zcTElJyQC0moiIyCjV\ntbdZ93DFrsU9Aj3zzBJRa2n8VAKSifRQyKOEtmjHcQxzNHrmlLnzrfO8KijNI+XKI+nII+H0E7fn\nErXnEXX4idhy2bDtHSaeNp9wjo9IKodwet+yQCSRPsYJdiQIHkqkA1wiHeBiBCMNxJJ1x2wOw6B7\nOGKuy24t4uG0U5LrZLzLS67TuuZLH3NddrxOO/keK8hZC4E4yfc4cNo1h0ykS1ZDnmEYNwM3AQng\n96Zpfjl9/d+ATwNJ4BbTNF/M5nNk04QJE1i4cCEvvPACW7ZsYfHixQDEYjEWLVrUfd+1117bfbzt\nttsAqK2t5ZprrqGhoYFYLMbEiRO771+2bBkejweAeDzOTTfdxJtvvonNZmPHjh3d951zzjlUVFQA\nMHnyZC699FIATj/99O6ew/6Y/WxAov+xEhER6YdpQryzVxDr6LXAR6BvQOsObP2Et67zVOLE6re5\n0r1jPSHNzKsk6fQTtfmJ2HyEc3IJGV4C+OgwPbSlvLQk3DQlPTTHrP3MApEEgWicQDAdyCKJ9Nyy\nI75hIAAUwps7+30kh83An15hsWu44tgCt3Xea0hj789z3dZy+L2HObodml8mkg1ZC3mGYSwFrgDO\nME0zahhGafr6LOAjwGxgLPCyYRjTTLOfcQLDgM/nA6zQdMkll/Dkk0/2e1/vv8C6zm+++WZuv/12\nli1bxsqVK7uHT/YuF+AHP/gBZWVlbNy4kVQqhdvt7v7M5XJ1n+fk5HS/z8nJIZE4+j8iVVVV7N+/\nn6qqKhKJBO3t7RQVFZ3Ady4iIjJMxCPQ2QLhFgg395x3b0Qd7Bveeq/a2BXYzP7C0OGMnnlnrvSi\nHy6/tem0y9/9menMJWb30Wl4CBnWPLMO001HykNb0kl73E4gatIeg/aoSVsUApG4FdJa490BLfGu\nwxeTGEaIXFe013L3dkr9biaP6Qpfju6FPPpuDG0dt23ZxPyz56Y/y8Ftt1lf57bjstsy9dMRkSzI\nZk/e/wG+Y5pmFMA0zcb09SuAp9LX9xqGsQuYD6zN4rNk3cKFC/nCF77Arl27mDJlCuFwmNraWqZN\nmwbAihUr+MpXvsKKFSu6e/ja29uprKwE4NFHHz1q2e3t7VRVVZGTk8Ojjz5KMnnqeXjZsmU8+uij\nLFq0iKeffpqLLrpI/5MmIiJDVyoF0XbobIPOVmtOWWdbz/Fo18ItEH+XhTYMW6+VGNPBzJ0HeWP7\nBLOuwGY6c+nMsVZltMKZh46Ui7aki9a4k0A00T33rCuMBdoSdHSFtPSctCPzWSz9suQYdPeUdR3H\nFrjxu/3dga3P567Dr9nxOe3knMIeZfbGrcyfqP8AFhmOshnypgHnG4ZxDxAB/tU0zX8AlcBrve6r\nTV87gmEYNwI3ApSVlbFy5co+n+fn5xMIBDL/5O8imUx21xkMBkmlUgQCAdxuNz/5yU+4+uqricWs\nv6S/9rWvUVFRgWmadHR0MG/ePFKpFA8//DCBQIA77riDD3/4w1RUVHDOOed0lx2NRnE4HN31XHfd\ndXziE5/gqaee4oILLsDn8xEIBAiHwyQSie77kskkoVCo388Od/XVV/Pyyy8zadIkCgsLWb58OYFA\ngIaGBm666SaeeeYZAG644QZWrVpFc3MzlZWVfPWrX+13pc1IJHLEzyfTgsFg1uuQo1P7Dy61/+BR\n22eQmcKW7MQRD2JPWC/rPHTY+57zc+IB4qtC2BNhjHdZwTFlOIg7cknYfSTsfuvcPYW4P4+4w59+\n5ZGw+4k5/AQMP+0pL4GUg1DCIBQ3CcdNQgmTcCeEOsz0Naxr8fT7BOmA1hXKOo54FpsBHjt47AZe\nh9F9Xuw18OSBx+HAa7eudx09DqPn3G7gsvUeBZRMvw7bjNsEOtMvIJh+NZzSD6mH/uwPLrX/4Bru\n7W/0NzfruL/YMF4Gyvv56E7gHuAvwBeBc4AVwCTgAWCtaZqPp8v4OfAH0zSfebe65s2bZ3YtNtJl\n69atzJw586Sf/2QEAgH8fv8JfU11dTXr168f0YuaDMTPYuXKlSxZsiSrdcjRqf0Hl9p/8KjtD2Oa\n1rDGztaenrKu8yPet1g9al3z0d6tRw0gxw6eQmu1Rk8BeAo52B6lrHp6+lphenXHAlKufEI2Px3k\n0mb6aIvbuvcyO/zV0c/7dxvp2Hv5/LyuZfQPe+V57Ef0tPnTc85Gyj5m+rM/uNT+g2uotr9hGBtM\n05x3rPtOqSfPNM2L3+UB/g/wG9NKkesMw0gBJVg9d+N63VoF1J/Kc4iIiMhJSEQh0ACBA+lQ1nbk\nkMdI25EB7t2m0Tv9PWHMW2Qtte/yWys6ds1ROyywxZ15VlhLOGgNx2kJxWgJxWgOxXgrsBtfoIzm\nAzFr77OwFdQCkTZSZttRH+PwoFbodVJd7OsnrDm6V2rsuqbl80VkuMvmcM3fARcBKw3DmAY4gSbg\nOeCXhmHch7XwylRgXRafY9AN5j5z99xzD7/+9a/7XLvqqqu48847B+mJREQkoxLRXsvpv8v+aH3e\nt1nBLtx09HJd+eDJ7+lVK51lBTNvUTqgFYLHOjc9hcSc+YRz/ISSOT29ZuG4tSF1Z9wKZ62x7nMr\nrMVo76wjGN131Mdw2mBMWwvFuU4KvdaG1P2FtMNfCmoiMpplM+Q9DDxsGMYmrEHr16d79TYbhvEr\nYAvW1gpfGK4raw4Hd955pwKdiMhwEO+E4EEINloBLHgwvWH1MYJbInKMgg1rIRFXryX488dB1Tyr\nl81fQdxXTsiWRzs+2kwfrQk37dFU9zDHjkiC9nCc9rY4HQfi6Y2s0xtWRzsIx1qPsdIjOG055Kd7\nywo8DsYWuJlR4acgvcdZV09aoc9JkddJUa51/Puavw3JIVMiIkNZ1kKeaZox4ONH+ewerDl7IiIi\nI5NpWkEs1GT1mIUOpV9N6Vf6ffAgBA5avXD9sXv67pHmLoCC8T2bWrvzu1+my09njo+Orr3Skl5a\nEtYeaR2HzU1rOhijcVeExkCUtnAMa7BN/z17bkeO1WvmtoJYkc/JuCIvPqe1cbUvvYG112ltWt17\nCGRXePM41LMmIjJQsroZuoiIyIgSC/UKaocd+wtyqXj/5bjywVcCvjFQOhMmLYHcMvCXW8f0K+Uu\noCNu0BKy5qM1BWM0BaM0BWI0h6I0HbLOm4JRWsKx9IIiAayNrI9kGOB32cn3OijJdVFd7GP+xCLG\n5Lop9PWEuLxei4vkexzaE01EZJhRyBMRkdEr3tkroPXqYQv3nJ91YC+8EbWuJzr7L8fh6wlteZVQ\ncaZ17k1f8xWDbwxRVxHNKT+HOqEpGKU5aIW3lnCM1sYYrTVxWkMxWsMttIYP0haOHXUVyHyPg5Jc\nJyW5LmZW5FHkcx6x+mOep29w87tObd80EREZHhTyBtmSJUv4r//6L+bNO+ZKqCel9/YN5557LmvW\nrMlKPSIig65rs+xwS3oVyBYIN1uvw4Nc13ks2H9ZNld3OIs7/DBuHniL09fGpAOdFeBiriKaYzaa\nAjEOBSPpY5RDgShNjeljMMqhwAE6IrX9Vue05VDos1aALPQ6mVGeR4HXGhZZ6HVS6HNQ4HUyJtdF\nSa6LIp8Tpz0ni40pIiLDmULeKKKAJyLDTjIBocb0Mv8He5b7Dx7oCXPh5nSgazn60v45jp5g5i2B\nokl93/cObt4SIjlemkLW8MhX166nonKaNUyyJcahd6I0BaI0BQM0h5ppC/c/JNPvsjPGb4WyGeV5\nnDfF6nXrujbGb4W1Ip9TK0GKiEhGjZiQ991132Vby7aMljmjaAZ3zL/jqJ/X1NRw+eWXc95557Fm\nzRoqKyt59tln2b59O5/73OcIh8NMnjyZhx9+mMLCwqOW8/jjj3PLLbfQ0dHBww8/zPz581m3bh23\n3nornZ2deDweli9fzvTp09m8eTM33HADsViMVCrFM888w9SpU3n88cf50Y9+RCwWY8GCBfzkJz/B\nZus7hyI3N5dgMMjKlSu5++67KSkpYdOmTZx99tk8/vjjGIbBhg0buP322wkGg5SUlPDII49QUVGR\nsTYVEQEglbR60rpCW+9jsHeYawQOG69o5KSHQhZbr9IZ1lL+3mJreX9vca/31jL/piuPUDyVDmfp\nnrVgjOZglKbmnnltTcF9NAV3Eowm+tb5+tuAFdxK/C5Kcp1MK/MfEdq6hk+O8btwOzSPTUREBseI\nCXmDZefOnTz55JP87//+L1dffTXPPPMM9957Lz/+8Y+58MILueuuu/jGN77BD3/4w6OWEQqFWLNm\nDX/961/51Kc+xaZNm5gxYwZ//etfsdvtvPzyy3z1q1/lmWee4ac//Slf/OIX+djHPkYsFiOZTLJ1\n61ZWrFjB6tWrcTgcfP7zn+eJJ57guuuuO2qdb7zxBps3b2bs2LEsXryY1atXs2DBAm6++WaeffZZ\nxowZw4oVK7jzzjt5+OGHs9F0IjISpVJWz9rh4S144LD3jf30uhlWePOXg7/Cmtfmr+h533X0jYEc\nG6ZpWqtEBqO9FiSJ0nQg1ivINdAcrKEpGCUST/X7yIVeB8W5VkA7rTK/T2Ar9rl4Z8cmLr1wESW5\nCm4iIjI8jJiQ9249btk0ceJE5syZA8DZZ5/N7t27aWtr48ILLwTg+uuv56qrrnrXMq699loALrjg\nAjo6OmhrayMQCHD99dezc+dODMMgHreGAy1atIh77rmH2tparrzySqZOncorr7zChg0bOOeccwDo\n7OyktLT0XeucP38+VVVVAMyZM4eamhoKCgrYtGkTl1xyCQDJZFK9eCJiMU1rOGSf0NYV5HqHt4OQ\nShz59d7inqBWNrtvaMstT68qWQo2BwCReJLGjigN7Z0c6Ihw4ECEhu0RDrTX0dCxm8aOCE3BKPHk\nkauS5BhQ5LNC2hi/i0klvu4etq4w13u4pMP27nPbVjZuparQm5FmFBERGQgjJuQNFpfL1X1us9lo\na2s74TIOn4dhGAZf+9rXWLp0Kb/97W+pqanp3gj2ox/9KAsWLOD3v/89l112GQ899BCmaXL99dfz\n7W9/+6SfO5FIYJoms2fPZu3atSf8PYjIMGWa0Nnad4hkn+PBnlCXjB359Z7CnsA2ZkZ6G4DDet9y\ny8Du7P6SaCLJwfYodW2dNLR30tAQob6thQPt9TS0RzjYEaE5dGRdfped8nw35fluppaWMMbvotjn\n7B4uWZIOcIVep1aQFBGRUU0hL8Py8/MpLCzkb3/7G+effz6/+MUvunv1jmbFihUsXbqUVatWkZ+f\nT35+Pu3t7VRWVgLwyCOPdN+7Z88eJk2axC233MKePXt46623uPTSS7niiiu47bbbKC0tpaWlhUAg\nwIQJE07o2adPn86hQ4dYu3YtixYtIh6Ps2PHDmbPnn3C7SAig8w0IdpxlNB2WJhLRo/8end+Tw/b\nhHMPGzLZ1fNWDg5395ekUiZtnXFrnlswRlNLlAN7I9S17bTCXHuE+jarB+5wBV4H5XluxhZ4mDO+\ngIo8N2X5birSr7I8N363I5stJiIiMmIo5GXBo48+2r3wyqRJk1i+fPm73l9YWMi5557bvfAKwJe/\n/GWuv/567rvvPi666KLue1esWMHjjz+Ow+GgvLycu+66i6KiIr71rW9x6aWXkkqlcDgcPPjggycc\n8pxOJ08//TS33HIL7e3tJBIJbr31VoU8kaEo0gHttdBRB+37rfP2up5rwYMQDx/5dU5/T0gbtwD8\n/fW8lYPzyOGJwWiC+rZO6to6qW/opL6thvq2CHWt1rWDHRES/Wzq5nPaqCjwMLbAw6yKPCryPVQU\nuBmbPlbku/E69c+RiIhIphimeZRdVoeYefPmmevXr+9zbevWrcycOXNAnyMQCOD3+we0zuFgIH4W\nK1eu7B62KgNP7T+AEjEI1PcKbvup37qOsblm+lqt1UvXm2GDvLGQX2WFtbyxRwY3fxm4+v/7K5FM\ncaDDCmz17Z3Ut0Wob+vqfeukvq2TjkjfuXa2HIPyPDeVBR7GFripKPBQ6k/Pe/M5Kc51UZ7vJs9t\nH9bbA+jP/uBS+w8etf3gUvsPrqHa/oZhbDBN85gbbOu/TkVEBpJpWlsHdPW+daR739r39/TEBQ9y\n+LYBY+x+MCdC4USoPs8Kc/lVkJc++ssh5+grP3bGkukhk03UtXZS2xqmtq2T2tZO6lqtxU2Sh/XC\nFXodVOR7qCr0smBiERUFHiry3VQVWr1ypX43Ns19ExERGXIU8gbIF77wBVavXt3n2he/+EVuuOGG\nQXoiEcmKWPiwIZS1vUJcumfu8Dlwdg/kV1phberFPcEtvxLyx0FeJavXrDvq/yiapklLKMa+lg72\nNYfSvXERDqR74Q50RI7YsNswoDzPCmznVBdSVeilstCT7pWzeuY0hFJERGR40r/gA+TBBx8c7EcQ\nkUwwTWuxkpY9Pa/WvdaxvdYq2wvAAAAgAElEQVTaI64PwxoymV9p7fs245+7g5sV5MZZG3gfYzhj\nyjSpb+tkX3OYfc0h9rWkj81h9jWHj9i8u8jn7A5x86oLrXlw6ZUpqwq8lOe7cdrffesAERERGZ6G\nfcgzTXNYz/UYCYbLvE6R45ZKWr1x3UFub8+xdW/fBU1y7FAw3hpGWXl2OryN6xlO6a/os33Au4kn\nU9S2drKvOcQ7LWFqmsK80xKiptk6T7z4l+57HTaDqkIvE4q9zJtQyIRiHxOKvUwo9lFV6NGm3SIi\nIqPYsA55breb5uZmiouLFfQGiWmaNDc343a7j32zyFCSjEPbOz3BrU/PXE3fPeFsLiishqJJMGkJ\nFE20zosmWYHOdvx/lXbGklaAaw7xTnP6mH5f39Z3XpzHYWNCsZfJY3xM8UY5b850qtNhriLfjf0Y\nm3iLiIjI6DSsQ15VVRW1tbUcOnRowOqMRCIKNIdxu91UVVUN9mOI9C8WhsatcPBtOLgZmndbQa7t\nHTCTPfc5fFZ4GzMdpl/eE+KKJoF/LOQcf6BqD8fZ1xLqGVqZHlK5ryXEwY6+8/HyPQ6qi73MGVfI\nB+Z4GV/kpbrEx4QiL2P8ru7/wFq5ciVLFp7YtigiIiIyOg3rkOdwOJg4ceKA1rly5Urmzp07oHWK\nyDGYprUi5cFN0LTzyF45M2Xd58yF4ikwdi6c9qG+QS639Jjz4nqLJVLsaw6xqzHIzsYguw8FqWmy\n5sodvshJqd/FhGIv508dw4QiLxPSIW5CsZcC7/EN5RQRERE5XsM65InIKJNKQts+qzeueZd1bNpu\n9dD1XvDElWf1ypWfAadfDeWnQdlpUDDhhHrkwBpeuftQkF2NwXSgC7CrMci+5nCfjb8rCzxMLPHx\nz6dXdM+Nm1Bs9cxplUoREREZSPrNQ0SGps5WOLjFCnBdQy0bt/Zd9MSVByVTrRUry06DstkwZgZ4\ni0+oVw6gIxJn58Egu3sFuV2HgtS2dtK1tpAtx2BCsZcpY3J5z2nlTCnNZcoYP5NLfQpyIiIiMmTo\ntxIRGVzJBLTstoZaHtiUDnWboaO25x5PkdUbd/YnoXQmlEyDosngKznhMBeKJtjVGGT7wQA7DwbY\ncTDIjoMBGtoj3fc47TlMKvExZ1whHz5rHFPLcplSmkt1sU/bDoiIiMiQp5AnIgMn0g4Nb8GBt61Q\nd3ATNG7r2Rw8xw4l02HCuVavXFfvnL/8hMOcaZrUtXWytSHAlvoOtjS0s6Whg/0tnd33OO05TBmT\ny4KJRUwr9zO11M/U0lzGFXmx5WjFXhERERmeFPJEJDvCLdCwMf160zq27On5PLfMCnALbuwJcyXT\nj3tPud5iiRS7GoNsaejoCXT1HXRErA3CDQMmFvs4o7KAq88ex9QyP9PKcplQ7FOYExERkRFHIU9E\nTl2oGRresIJc/ZtWqGt7p+fzgvFQMQfmfAzGzrEWRMktPamqgtEEWxs62FzXzqb6DjbXd7CrMUA8\naU2c8zhsTC/3874zxzKrIo9ZY/OYUe7XnDkREREZNfRbj4icmGBjT5DrCnW9588VToTKs2Hep6xg\nV3EmeItOqqrWUIzN9R1srk8Hurp29jaHuhdCKcl1MmtsPkumj+kOdNXqnRMREZFRTiFPRI4uHoG6\nDbBvDae9/SJs+BwEGno+L54C4xdavXMVZ1o9dJ6CE67GNE0aA1ErzNV1sKmunc31HdS19cyfqyzw\nMHtsHh+YW8lplXnMHptPaa/NwkVERETEopAnIj2iAdi/DvatsV516yEZAww83kqYckFP71z56eDO\nO6lqQtEEG/e3sWFfK2/sb+Ot2naagtbiK13z586aUMh1iyYwe2w+s8fmUejTpuEiIiIix0MhT2Q0\nC7fAO6/BvtVWqGvYCGYSDJvVO7fgX2DCYhi3gH+se4slS5accBWmaVLTHOb1fa28/k4rr7/TxvYD\nHXTtIz6lNJcLp43htMo8TqvMZ2ZFHrku/dUkIiIicrL0m5TIaBI40NNLt28NNG62rttcUDUPzr/d\n2r6gaj64ck+6mob2TlbvambNriZW727iYIfVS+d32ZkzvoBLLprKWeMLmDuukHyvIxPfmYiIiIik\nKeSJjFSJqLUfXd0GqF1vDb3s2sLA4YPxC+C0D1o9dWPPAof7pKtqD8dZu6eZNbubWLWriT2HQgAU\n+5wsmlzMosnFzJtQxJTSXC2KIiIiIpJlCnkiI0l7Hex8yXrtWQnxsHU9t9zqqZv3KaunrvwMsJ18\nD1oknmTDvlZW7Wpiza4m3q5rJ2WC12lj/sQiPjp/POdOLmFGuZ8chToRERGRAaWQJzKcpZJWL93O\nF2HHS3Dwbet6wXhrT7qJ50PlPMivPOWqDoVTPLa2hle3NbJmdzPRRAp7jsHc8QXcfNFUzptawplV\nBTjtOadcl4iIiIicPIU8keEm3AK7/wI7XoRdL0Nni7VQyvhFcMk3YeplMGa6tUzlKYglUvyjpoVX\ntzXy6vZGdh/qBDYzodjLtfPHc8G0EuZPLNYiKSIiIiJDjH47ExnqTBMat6Z7616E/X8HMwXeYph6\nKUy7FCb/00ntT3e4hvZOVm4/xKvbGlm9q4lQLInTlsOCSUUsKI7z2fedy8QSXwa+KRERERHJFoU8\nkaEo3gl7/2qFup0vQft+63r5GXD+/7V66yrPghzbKVVjmiab6jp4acsB/rzlINsOBAAYm+/mA3Mr\nWTq9lHOnFON12lm5cqUCnoiIiMgwoJAnMlQEG2Hr87DjT1bAS0SsVTAnL4ULvmT12uVVnHI18WSK\ndXtbeGmzFezq2yPkGDCvuoh/u3wGS2eUMrU0F+MUh3uKiIiIyOBQyBMZTKEm2PocbP4t1KyyhmEW\nToSzP2mFuurzwO465WrCsQR/3XGIlzYf5JVtjbR3xnHZc7hg2hhuu2Qa/zSzjCKf89S/HxEREREZ\ndAp5IgMt1AzbnreC3d6/gZmE4ilw/r/C7A9A6axTXjQFoDkY5ZWtjby05QB/29lENJGiwOvg4pll\nXDq7jPOnluB16q8AERERkZFGv+GJDIRwC2x7wQp2e/6fFeyKJsF5t8HsD0LZ7IwEu3eaw7y05QAv\nbTnI+poWUiZUFnj46ILxXDqrnHOqC7HbtMWBiIiIyEimkCeSLbGwNcfu7V9ZG5OnElBYDYu/aAW7\n8tMz1mP33MZ6fvN6HW/XtQMwo9zPzRdN5dLZZcyqyNP8OhEREZFRRCFPJJNM09qc/M3HYdNvINph\nbUy+6CYr2FWcmZFgF00k+cvWRp55vY6V2xtJpExOr8zn3/95JpfOKmd8sTcD34yIiIiIDEcKeSKZ\nEDgIbz0FbzwBTdvB7rHm1835GExYDDmnPkTSNE3e2N/Gb16v5fmNDbR3xinLc/Hp8ydy5dwqppf7\nM/CNiIiIiMhwp5AncrJSKdj9Cvzj59ZedmYSxi2A9//I6rVz52WkmtrWML97o47fvF7HnqYQbkcO\nl80u50NnVbF4Sgm2HA3FFBEREZEeCnkiJyrcAm8+YYW71r3gK4Vzb4a5H4eSqRmpIpky+fOWAzy2\ndh9rdjcDsGBiEZ9bMpnLTyvH73ZkpB4RERERGXkU8kSOV/2b8I//hbefgUQnjF8EF/07zFwG9szs\nMdfeGedX/9jPI2tqqGvrpKrQw+2XTOODcysZV6R5diIiIiJybAp5Iu8mlYQtv4PXfgq168DhhTOv\ngXM+Y62OmSF7m0I8snovv95QSziWZMHEIr72vllcMqtMwzFFRERE5IQo5In0JxmHt38Nf/s+NO+C\noslw2bdhzkfBU5CRKkzTZPWuZh5evZe/bGvEacvh/WeO5YbF1ZxWmZ+ROkRERERk9FHIE+ktEYU3\nfwmrfgBt+6zeuqsfgxnvz8gKmQCReJLfvlHH8tV72XEwSEmuk1svnsrHFkxgjN+VkTpEREREZPRS\nyBMBiHfC64/B6vuhow4qz4bL74Vpl2VkXzuA1lCM5av38ovX9tEajjN7bB7fv+pM3ndmBS67LSN1\niIiIiIgo5MnolojBhuXw1/+CUKO1p90VD8CkpRkLd42BCD//mxXuwrEkl84q49PnTWT+xCKMDNUh\nIiIiItJFIU9Gp1QKtvwWXvkmtNZA9flw1SNQvThjVbSH4zy4chePrqkhnkyx7MyxfH7pFKaVadNy\nEREREckehTwZffathRf/DerfgLLT4GPPwJR/yljPXTSR5LE1+3jg1V10ROJcObeKmy+aQnWJLyPl\ni4iIiIi8G4U8GT3aa+HPX4dNT4N/LHzgv+GMayAnM/PhUimT59+q53svbqe2tZMLp43hK5fPYGZF\nXkbKFxERERE5HlkLeYZhrACmp98WAG2mac5Jf/ZvwKeBJHCLaZovZus5REhErQVV/nYfYMKFd8Di\nL4Izcz1ra3c38+0/buWt2nZmVeTx+KfP4LypJRkrX0RERETkeGUt5JmmeU3XuWEY3wfa0+ezgI8A\ns4GxwMuGYUwzTTOZrWeRUWz/Onj2JmjaDrM+AJf+BxSMz1zxLWG+8fxmXt7ayNh8N/ddfSYfmFNJ\njjYwFxEREZFBkvXhmoa1fODVwEXpS1cAT5mmGQX2GoaxC5gPrM32s8goEg3AK/8B634G+VXWvLup\nF2es+GTK5JE1NfzXi9vJMeCO98zghsXVuB3aCkFEREREBpdhmmZ2KzCMC4D7TNOcl37/APCaaZqP\np9//HPijaZpP9/O1NwI3ApSVlZ391FNPZfVZj0cwGCQ3N3ewH2NUOt62L2h9mxnbfoQreoi6yvey\nd+LHSdq9GXuO2kCKhzdF2dOe4owxNq6f5aTYk5mN0ocy/dkfXGr/waO2H1xq/8Gjth9cav/BNVTb\nf+nSpRu6ctW7OaWePMMwXgbK+/noTtM0n02fXws82fvL+rm/36RpmubPgJ8BzJs3z1yyZMnJP2yG\nrFy5kqHwHKPRMds+3mltibDxJ1A0GT72C6rGL6QqQ/VHE0kefHU3//3aLvxuB/d/ZBbLzhw7ava6\n05/9waX2Hzxq+8Gl9h88avvBpfYfXMO9/U8p5Jmm+a7j3wzDsANXAmf3ulwLjOv1vgqoP5XnEKH+\nDfjNjdC0A+bfCBffndGFVTbsa+Urz7zFzsYgH5xbydfeN4sinzNj5YuIiIiIZEq25+RdDGwzTbO2\n17XngF8ahnEf1sIrU4F1WX4OGalME9b/HP70b+AbA5/4HUxemrHiY4kU9/5pGz9fvZex+R6W33AO\nS6eXZqx8EREREZFMy3bI+wh9h2pimuZmwzB+BWwBEsAXtLKmnJRYCF64Dd5aAVMugSt/Bt6ijBX/\nTnOYm558nbdq2/nEwgnccfkMcl3aWlJEREREhras/sZqmuYnj3L9HuCebNYtI1zTTljxCTi0DZb+\nO5z/fyEnc4uf/GlTA196+i0A/ucTZ3PZ7P6mnoqIiIiIDD3qlpDhZ8uz8LsvgN0Jn/gNTL7o2F9z\nnBLJFN/54zYeWrWXM6vyeeCjZzGuKHMrc4qIiIiIZJtCngwbRioBL94Jax+Aynlw9aPWHngZ0h6O\nc9OTr/O3nU1cv2gCd/7zLJz2kb81goiIiIiMLAp5MjwEGzlz49egfQvM/xe49FtWT16G7D4U5LOP\nrmd/a5jvXHk6H5k/PmNli4iIiIgMJIU8Gfpa98EvPoA/UAcf+jmc/uGMFr96VxOfe3wDTlsOv/zs\nQs6pztziLSIiIiIiA01j0WRoa9wKD18G4RY2nvnNjAe8P206wA3L/8HYfA/P3XyeAp6IiIiIDHsK\neTJ01a6H5Zdbe+Hd8Ec68mdktPhfr9/P55/YwOzKPFb8y0IqCzwZLV9EREREZDAo5MnQVLMaHl0G\n7nz41J+gbFZGi3941V6+9PRbLJ5SwuOfXkCBN3Pz+0REREREBpPm5MnQU7ManviwtXLm9c+DP7N7\n1D30tz186/dbec/scu6/dg4uuy2j5YuIiIiIDCaFPBla+gS8F8BfltHiH39tH9/6/Vb++fQK7v/I\nHOw2dWaLiIiIyMii33Bl6MhywPvN67V87dlN/NOMUn5wjQKeiIiIiIxM+i1Xhoa61+GJq7IW8P74\ndgP/+uuNLJpUzIMfO0ubnIuIiIjIiKXfdGXwteyBX14NvuL0HLzMBry/72nmlqfeYO74Qv73unm4\nHZqDJyIiIiIjl0KeDK7gIfjFlZBKwMd/k/FFVvY1h/jc4xsYV+Tl4evPwefSNFQRERERGdn0G68M\nnljI6sELHIDrn4OSqRktviMS59OPridlwsPXn0O+15HR8kVEREREhiKFPBkcqRQ8/WloeBOueQLG\nzc9o8Ylkipt++QY1TSF+8ekFVJf4Mlq+iIiIiMhQpZAng+Ov34Mdf4TLvwcz3pvx4u/5w1b+uuMQ\n37nydBZNLs54+SIiIiIiQ5Xm5MnA2/kyrPw2nPERmP/ZjBf/p00NLF9dw6cWT+Qj88dnvHwRERER\nkaFMIU8GVus+eObTUDYb3vcDMIyMFl/X1smXn36LM6vy+crlMzJatoiIiIjIcKCQJwMnHoFfXQem\nCVc/Bk5vRotPJFPc9tSbpEz40bVztReeiIiIiIxKmpMnA+fFf7MWWrn2KSienPHiH3h1F+tqWvjh\nNXOYUKyFVkRERERkdFJXhwyMHS/B+ofh3Jth+uUZL37d3hZ+9MpOrjyrkg/Mrcx4+SIiIiIiw4VC\nnmRfqBmeuwlKZ8FFX8t88dEEt//qTcYXefnmFadlvHwRERERkeFEwzUlu0wTfn8bhFvg48+A3ZXx\nKu790zbq2jr59b8sItelP9IiIiIiMrqpJ0+y661fwZZnYelXofz0jBe/bm8Lj67dxyfPrWZedVHG\nyxcRERERGW4U8iR72mvhD1+CcQth8RczXnxnLMmXn97IuCIPX7psesbLFxEREREZjjS2TbLnD1+G\nVBw++N+QY8t48ff9eTs1zWF++dkFeJ36oywiIiIiAurJk2zZ+WfY/nu48MtQNCnjxb/xTis/X7WX\njy0Yz7mTSzJevoiIiIjIcKWQJ5mXiMIf74DiKbDw8xkv3jRN7n5+C6V+N1+5fEbGyxcRERERGc4U\n8iTz1j4ILbvh8u9mZTXNP206wMb9bdx+6TT8bkfGyxcRERERGc4U8iSz2uvgr9+DGe+DKRdnvPh4\nMsX3XtzO1NJcPnRWVcbLFxEREREZ7hTyJLNe+ncwU3DZPVkp/lfr97OnKcSX3zMDW46RlTpERERE\nRIYzhTzJnH1rYPNv4LzboLA648VHEyb3v7yTeRMKuXhmacbLFxEREREZCRTyJDNME175D8gtz8qe\neAAv7YvTGIjylctnYBjqxRMRERER6Y9CnmTGnlfhnTVwwb+Cw5Px4ltCMf6wN84ls8qYV12U8fJF\nREREREYKhTw5daYJf7kH8qrgrOuyUsUja2qIJODLl03PSvkiIiIiIiOFQp6cup0vQd16uPBLWdky\nIRJP8sRr+zhzjI2pZf6Mly8iIiIiMpIo5MmpMU34y7eshVbmfCwrVTy3sZ7mUIxLq7UnnoiIiIjI\nsSjkyanZ+jwceAsuvANsmQ9hpmny8Kq9zCj3M7NIf1xFRERERI5FvzXLyUulYOW3oXgKnH51VqpY\nu6eZbQcCfGrxRK2oKSIiIiJyHBTy5OTtfAkat6R78exZqeLhVTUU+ZwsmzM2K+WLiIiIiIw0Cnly\n8tb9D/grYPYHs1J8TVOIV7Yd5OMLxuN22LJSh4iIiIjISKOQJyfn0A7Y/ReY9+mszMUDa9sEe47B\nxxdOyEr5IiIiIiIjkUKenJx1PwObE87+ZFaKD0TiPL2hlvefMZbSPHdW6hARERERGYkU8uTERTpg\n45Nw2ocgd0xWqvjjpgMEowk+vki9eCIiIiIiJ0IhT07cm7+EWBDm35i1Kp7fWM+EYi9zxxVkrQ4R\nERERkZFIIU9OTCplLbhSNR8qz8pKFYcCUVbvauL9Z4zVtgkiIiIiIidIIU9OzO5XoGUPLPiXrFXx\nh7cbSJlo2wQRERERkZOgkCcn5u//A7nlMHNZ1qp4fmM9M8r9TCvzZ60OEREREZGRSiFPjl/gAOx6\nGc66DuzOrFRR19bJ+n2tvP9M9eKJiIiIiJwMhTw5flufB0xrVc0seX5jPQDvP0MhT0RERETkZCjk\nyfHb8iyMmQGlM7JWxXNv1jNnXAHji71Zq0NEREREZCRTyJPjE2yEfath1hVZq2JXY5AtDR0s01BN\nEREREZGTppAnx2frc2CmYNYHslbFcxvryTHgfWdUZK0OEREREZGRLmshzzCMOYZhvGYYxpuGYaw3\nDGN++rphGMaPDMPYZRjGW4ZhZGezNcmsLc9C8VQonZmV4k3T5IWN9SycVExpnjsrdYiIiIiIjAbZ\n7Mm7F/iGaZpzgLvS7wEuB6amXzcC/53FZ5BMCB6CmlUw+wOQpc3J9zWH2dMU4j2nlWelfBERERGR\n0SKbIc8E8tLn+UB9+vwK4DHT8hpQYBiGxucNZduez/pQzTW7mwFYPKUka3WIiIiIiIwGhmma2SnY\nMGYCLwIGVpg81zTNfYZhvAB8xzTNVen7XgHuME1zfT9l3IjV20dZWdnZTz31VFae9UQEg0Fyc3MH\n+zEG1Bkb78IdOcS6+T/JWk/ef78ZYXtrih8s8WAcpY7R2PZDidp/cKn9B4/afnCp/QeP2n5wqf0H\n11Bt/6VLl24wTXPese6zn0olhmG8DPQ3vu5O4J+A20zTfMYwjKuBnwMXY4W+w/WbNE3T/BnwM4B5\n8+aZS5YsOZXHzYiVK1cyFJ5jwISa4f9tgvNuZcnSpVmpwjRN/nXVyyyZWcbSpXOPet+oa/shRu0/\nuNT+g0dtP7jU/oNHbT+41P6Da7i3/ymFPNM0Lz7aZ4ZhPAZ8Mf3218BD6fNaYFyvW6voGcopQ822\n58FMZnXrhJ2NQZqCMc6drKGaIiIiIiKnKptz8uqBC9PnFwE70+fPAdelV9lcCLSbptmQxeeQU7Hl\nOSicCOVnZK2Kten5eIsmF2etDhERERGR0eKUevKO4bPA/YZh2IEI6bl1wB+A9wK7gDBwQxafQU5F\nvNNaVfOcT2dtLh7Amt1NVBV6GFfkzVodIiIiIiKjRdZCXnphlbP7uW4CX8hWvZJB76yFZBQmZWcu\nHkAqZfLanhYum12WtTpEREREREaTbA7XlOFu96uQ44DqxVmrYktDB+2dcc3HExERERHJEIU8Obo9\nr8L4heD0Za0KzccTEREREckshTzpX7ARDrwNk5ZktZo1u5uYNMZHWZ47q/WIiIiIiIwWCnnSvz3/\nzzpOvihrVcSTKdbtbeFc9eKJiIiIiGSMQp70b8+r4CmEijOzVsXbde2EYknNxxMRERERySCFPDmS\naVqLrky8EHJsWaumaz7ewknqyRMRERERyRSFPDnSoe0QqM/qUE2w5uPNKPdT5HNmtR4RERERkdFE\nIU+OtOdV6zg5e/vjmabJW/vbOXtCYdbqEBEREREZjRTy5Ei7X4WiyVAwPmtV1LZ2EogmmD02P2t1\niIiIiIiMRgp50lciBjWrsj5Uc0tDBwAzK/xZrUdEREREZLRRyJO+atdBPJTVoZoAW+o7yDFgRnle\nVusRERERERltFPKkr92vgmGD6vOyWs3Whg6qS3x4nNlbvVNEREREZDRSyJO+3lkLY+eAO7tz5bY0\ndDCrQr14IiIiIiKZppAnPRIxqNsA4xZmtZr2zji1rZ3MVMgTEREREck4hTzpceBtSERg3PysVrMt\nvejKrLEKeSIiIiIimaaQJz32v2Ydxy3IajVbu0KeevJERERERDJOIU967P+7tTdeXkVWq9nS0EGx\nz0mp35XVekRERERERiOFPLGYJrzz96zPxwPY2hBgZkUehmFkvS4RERERkdFGIU8sbe9A8EDW5+Ml\nkim2HwxoPp6IiIiISJYo5Ill/9+t4/js9uTtaQoRS6SYWeHPaj0iIiIiIqOVQp5Y9v8dnH4onZXV\nanoWXcnuPnwiIiIiIqOVQp5Y3vk7VM2DHFtWq9lS34HTlsOkMb6s1iMiIiIiMlop5AlEOqBxc9aH\naoK1sua08lwcNv3RExERERHJBv2mLVC3HsxU1hddAWu45sxyLboiIiIiIpItCnliDdU0cqByXlar\naQxEaArGtLKmiIiIiEgWKeSJtehK6WxwZzd8bam3Fl2ZWaGQJyIiIiKSLQp5o10qCbXrYfyCrFe1\ntSEAKOSJiIiIiGSTQt5o17gFYgEYNxAhr4PKAg/5HkfW6xIRERERGa0U8ka7/eus4wAsurKrMcjU\nstys1yMiIiIiMpop5I12B94GdwEUTMhqNamUyZ6mIFPGKOSJiIiIiGSTQt5od3ATlJ0GhpHVaura\nOonEU0wuVcgTEREREckmhbzRLJWCg1ug/LSsV7XrUBCAKQp5IiIiIiJZpZA3mrXuhXgIymZnvard\njVbIm6zhmiIiIiIiWaWQN5od3Gwdy7Lfk7f7UJAin5MinzPrdYmIiIiIjGYKeaPZwU1g5EDpzKxX\ntbsxxOQxvqzXIyIiIiIy2inkjWYHN0PxFHB4sl7VrkNBzccTERERERkACnmj2YG3B2Q+XksoRkso\npvl4IiIiIiIDQCFvtIp0QNu+AZuPB2j7BBERERGRAaCQN1o1brGOAxHy0itraiN0EREREZHsU8gb\nrQ5uso4DsUdeYxCXPYfKguzP/RMRERERGe0U8karA5vAnQ95lVmvavehIJPG5JKTY2S9LhERERGR\n0U4hb7Q6uBnKTgcj+8Fr16Ggtk8QERERERkg9sF+ABkEqZQV8uZ+POtVReJJals7+dBZVVmvS0RE\nTo5pmpiYpMwUJiamaZ2nzBSAdU7Kus80SfH/27vz+LjO+t7j399s2mVJtqRgO7GdxE4cssfZymYo\nSYBS0kAD4dUWWtqbW16US8krlK2UXlpel9KWFkpLX4FA4UKb0psG6BJSQhApKYnjJbGdOsFKLMfy\nptFiWTMjabbn/jGLR9Ne4UYAACAASURBVLIUy5rlHI0+b5jXmTnro0cn4/PVc87zzFrmsjP3kV9n\nxrRk32amgAIKWEBmJpMV38vly5T/31BqSAfGD8jJKfd/VzxWKZPlts+/z78pvi9OS9YJBUIKB8IK\nBUIKBULFnyXjMrlpNnPq/axp4eefUY4Zb099cM7NPX+edc5mHyZTJBhRQ7BBDcEGBQNBpbPp4ivr\nssW6LdS5TKfqP1dJxfeFejSZxtPjiiaixc+lv6tCXRZ/dyX1W1ieyqQ0nZnWdGZaqWxKkUBEDaEG\nNQYbFQ6GT/2ezsJitimUqxbHWsxxgGog5C1HJwakVLwmz+O9EI3LOTF8AlBHnHPKuNzF7+yL4MLn\njMsom82eWs9llM6mlcwklcwkNZ2ZVjqbLl6sFi7gC++dXHGbwiuTzSjtTn12cspkM8XAsaDXAtad\nfQEdHY7quz/6bvHirfDzF6az95/JZk4dK5s9PTzNCkuFwDI7CL3keoWQ5TQjcAUtqIAFiq9C+Ur3\nXRrKSrf1te94XYBl7J+8LsAy9/X5FwUsoIACxWBdCOKF+YU/cpQuK65zhuXpbFqpbEqpbEqZbEaS\nTgv7pe9nLM//4WD2uoV1JJ12vDmXl/7hJr9O4TtQOvXHqRnzSv4IVDqvdP3Z80q3K/1uf1fHu7RV\nW8v8BXqHkLccHct3ulKDMfIKwycwEDpQnozLKJFKFANScZpNzphXeF/4y3nxfclf1JOZpJLZU9sU\nwlMmm1Eqm1I8FVcinVA8Fdd0enpGUMtkM6e1oPhF6QVP0IIzpgEL5N7nL2jmfeW3LxVPxRU/GZek\nU61Qhf3lj1G6j2AgqLCFTx27pMVkdqvV7AusudYrtIrMfj97P9KpVrXChUqhPKX7KqwftOCM/c4+\nZunF4FwXkaXHL6wzX5lntwDNDralrX2lP48kPbvvWV1yySUzLwbt1EWgdOoPA/kPp+bNvsgrmSdp\nxoVsOps+9Tu0oIKBYPF3O9+0oPScKS37fK06860zu9Ux/+Elt8u67Iz/vtPZ9IwWykLraCHQzw78\nsy+KS6fPPvesNm3adNofGgrHPe3zrH1EghFFghE1BhsVCoRmfD8lM8k56+alLPa7Z1HbLWqTypZv\nYGBA69evn3ubef4bKv3jzXy/19JW+PmWhwNhhYNhhSzXyl0o51y/98Ky+YLW7Bbp0mA2o4V+rjA2\naz+zw6E0R5gsCZjF5bM+Szrt8+x/D9rH28/q9+g3hLzl6PgzkgWk7s1VP1T/UExm0oZVPJOHpSPr\nssWLkKn01IwLk9mvGaEqk1La5S8aC+8zqeKFZDqbnnNe4SLztLCWPfU+4zLS35f3c4UD4eJtXZFg\nRJFA7gIsFAgpZCEFA0GFAiF1N3erOdSslnCLGkONuQvewsVt/sK3cBFcvCCe46K4dN3Cto3BxmIZ\nCuFj9l+BC0KBkIIWLN5KVyhnKBAq7rsY5Er+Aa+0vr4+bd26tSr7xpm1HWrT1vO3el2MZanvSJ+2\nXrTV62IsW30n+rT1yq1eF2PZ6uvr87oIZSHkLUfH90pdF0iR5qof6vloTOd2NqsxHKz6sVD/si6r\nyfSkYsmY4um4Eqlca1MsFSu+n0xPngpomZKAls4Hs3xwKn6eFdimMlNKZ9NllzVggeJf0s80DQVC\nagm3qLOhc2YIy78PB8I68uIRXXzhxQoHw8Vnb8LBsBoCDaetf9r7fJgrbXkAAAD1i5C3HB3fK62+\nqiaH6h+iZ83lKJ1NazI9qUQqoUQ6ccb3k+lJTaYnNZWZ0mQqN51KTxXnx1Px4i2ECxWy0Iyg0xjK\ntyAFGtQQalBrpFVdwa4ZLUulrxnbzJ4fbJzxvhCqZreKVVLfyT5tvXRrRfcJAADqEyFvuZk6KY0N\n1KRnzUzW6cBwXK/auKrqx0JlTWemNZGcmPHaGd+p6M+ip82f8UrlppPpyQUfK2ABNYWa1BhszE1D\njWoONasx1Kie5h41hhrVEm5Rc6hZrZFWtYRa1BzO3UrYGm4tvi+8mkJNagg2FJ8hAAAAWG64Clpu\nhvblpr3V71nz8NikptNZetb0UNZldXL6pMamx3Ri+oTGpsY0Pj2e+zx1ojj/xNQJnZg+UQxryew8\nD8QP5yYhC6kt0lZ8tUZa1d3cnfscblNLpKUYxppCTWoONaspnJuWvi8EMrqcBgAAqBxC3nITzYe8\nnkuqfih61qy8rMtqIjmhkakRjU6Oamx6TKOToxqdmvkamxrT6NSoxpPj83aPHglE1NnYqY6GDnU0\ndmhT8ya1N7SrLdKm9ki7WsOtxRDXHmnXvqf26edf+fNqDbeqKdREMAMAAPApQt5yM/SsFG6WVpxb\n9UMVQh4teWeWSCU0PDmsocSQopPR3DQRVXQyelp4y7jMnPtY0bBCXY1d6mrs0vkd5+uahmvU1dSV\nC3ENHeps6FRHY0fx89kGtRORE+pp7qnUjwwAAIAqIeQtN9F9UvdFUqD6vewdGI6rozmszpZI1Y/l\nV9OZ6WJYKwS3ocl8gMvPjyaimkhNnLZtQ7BBq5pWaWXTSq1uXa3LVl2mzsbOYpArvF/ZuFIdjR0K\nB8Ie/IQAAADwm6qFPDO7QtLfSmqVNCDpV5xzJ/PLPirpNyVlJP0v59xD1SoHZhl6VrrgdTU51MGR\nhNatrM+eNVOZVK7lLR/Y5mqBi05GNT49ftq2oUBIPU096m7u1gUdF+iGl92g7uZu9TT3aFXTquKy\n9kg7t0QCAADgrFWzJe8rku52zv3YzN4j6UOSPmFml0i6Q9LLJa2W9LCZbXJunnvQUDmTY1LsmNRz\ncU0Od3A0rqvO7azJsaohlUlpMDaogfEBHTx5UAMnBzRwMvd+eHL4tPVDFtLKppXqae7ReW3n6Zre\na9TT3KPuplyA627uVndTtzoaOghvAAAAqJpqhryLJD2af/8DSQ9J+oSkWyXd55yblnTAzPolXSfp\np1UsCyQp+lxu2l39kJdMZ3V4bFK3Xbmm6scqh3NO0cmoBsYHZoS4gfEBHY4dnvH8W1djl9a3r9cr\n17xSq1tXF1vcCkGus7GTwaYBAADgOXPOVWfHZv8l6U+cc981s7sk/W/nXJuZfVHS4865b+bXu1fS\ng865/zfHPu6UdKck9fb2XnPfffdVpaxnIxaLqbV1aXYk8rIjD+min/2NHr/+Hk019Vb1WMfiWX3k\nPyf1Py6L6BVrKvOsWDl1n8wmNZQe0vHU8eIrmo5qKDWkaTddXC9sYfWEetQTzr9Cp6bNweaK/BxL\n1VI+9+sB9e8d6t5b1L93qHtvUf/e8mv9v/a1r93hnNtypvXKaskzs4clnTPHoo9Leo+kL5jZH0j6\nnqTCwFtz3ac2Z9J0zt0j6R5J2rJli9u6dWs5xa2Ivr4++aEci/Lgg1K4RTfccnvVO1750XND0n8+\nqVtecY22rO+qyD4XUveT6UntH9uvZ0ef1QvjL+jA+AEdGD+go/GjxXVMptWtq7W+e71e0/4arWtf\np3Xt67RhxQb1NPfQGjePJX3u1wHq3zvUvbeof+9Q996i/r211Ou/rJDnnHv9GVa5WZLMbJOkX8jP\nG5RU2n//WklHyikHFmiodj1rHhyOS1JVO14ZmxrTvtF9em70ueJ04ORAcVy45lCz1q9Yr6t7r9aG\n9g3asGKD1q9Yr3Xt69QQbKhauQAAAAAvVbN3zR7n3JCZBST9vnI9bUq5Vr2/N7PPKdfxykZJ26pV\nDpSIPidd+PM1OdTASEItkaBWtVZm+ATnnKKpqB7Y/4B2Du3UjuM7dGjiUHH5OS3n6OKui3Xz+pt1\ncdfFurjrYq1uWU0HJwAAAFh2qtnxyjvN7H359/8s6WuS5Jx7xsy+Lem/JaUlvY+eNWug0LNm90U1\nOdyLowmdt7Jl0SHLOafnTzyvHcd3FF9Dk0PSkdyg39f0XKPbN92uzSs36+LOi9XR2FHhnwAAAABY\nmqoW8pxzn5f0+XmWfVrSp6t1bMxh6NnctHtzTQ43MBLXRb1tC17fOadDE4f0xLEntO3oNm07tk2j\nU6OSpO6mbm3p3aK2k2165yvfqfM7zue5OQAAAGAe1WzJg59E9+WmNRgjL5N1OjSa0M2XzNUnzynH\n48f1xLEn9MTRJ7Tt2DYdix/LFbGpRzeuvlHXnXOdru29Vmvb1srM1NfXpws7L6x6+QEAAICljJC3\nXESfkyKt0opzz7xumY6OTyqVcVq3cuaQA8lMUjuHduqxw4/pJ4d/ov4T/ZKkzoZObTlni37r0t/S\ndS+7Tuvb1/MsHQAAALBIhLzlYmiftGqTVIPwdHAkIUlat7JZhyYO6SeHf6LHDj+mbce2aTI9qXAg\nrKt7r9atF9yqG1ffqI2dG7n9EgAAAKgQQt5yEX1WuvBMI15UxtPHDiiysk+f2f0VHTiZa61b27pW\nt15wq1655pW69pxr1Rxe3gOLAwAAANVCyFsOEqNS7LjUXb3n8RKphL4/8H19p/872jW0Sw09UnvD\nFfrwtR/Wq9e+Wue1n1e1YwMAAAA4hZC3HESfy017KtuzpnNOe4f36v799+vBAw8qkU7o/BXn6zx7\nmxKjl+mb735bRY8HAAAA4MwIectBoWfNCo2RNz49rn994V91//77tX9sv5pCTbpl/S1628a36Yru\nK/TGz/+nzu9oqsixAAAAAJwdQt5yMPRsRXrW3D+2X1/b+zU9NPCQktmkLl15qf7gxj/QG9e/Ua2R\nVkm51r2DIwn93AWrKlFyAAAAAGeJkLccRPflWvEW2bPm3uG9umf3PfrRoR+pOdSst258q3550y/r\noq7TWwajE9OaTGW0fhUdqwAAAABeIOQtB9HnpAtvOqtNnHPafny77tl9jx4/+rjaI+167xXv1a9s\n/hWtaFgx73YD+eETzusi5AEAAABeIOTVu8kT+Z41Ny1odeecHh18VF/e82U9HX1aKxtX6q5r7tLb\nL3q7WsItZ9z+4EhckrR+5ZnXBQAAAFB5hLx6N34oN+1cf8ZVnzz2pD63/XPaO7JXq1tW6+PXf1y3\nbbxNDcGGBR/u4EhCwYBpTScdrwAAAABeIOTVu/HB3HTF2nlXef7E8/qLHX+hHw/+WL3NvfrUz31K\nb77gzQoHwmd9uIGRuNZ0NCkcDCy2xAAAAADKQMird8WQd3rPmhPJCX1x1xd133P3qTnUrA9c/QH9\n6uZfVWOocdGHe3E0oXUreR4PAAAA8Aohr96NH5KCDVLzqSENnHN66OBD+uy2z2p4clhvv+jtet+V\n71NnY2dZh3LO6cBwXL905ZpySw0AAABgkQh59W58UFqxRgrkbp88HDusP/rpH+mxI49pc9dmfeF1\nX9Clqy6tyKFOJFKamErTkgcAAAB4iJBX78YHpRVr5ZzT/fvv158++aeSpI9c9xHdcdEdCgaCFTvU\nwdHc8Anr6FkTAAAA8Awhr96ND+r4+hv1yR++V48dfkzXn3O9PvWKT2l16+qKH6owfAJj5AEAAADe\nIeTVs0xKT6RGdVf8KaUmg/rY9R/TOy56hwJWnZ4vB8cmJUlrGT4BAAAA8Awhr479896/0x/1rtL6\ncJv+8k1f17r2dVU93uDYpFa2RNTSwGkFAAAAeIWr8TqUdVn95c6/1Nf2fk0/NzmlP7vhbrVVOeBJ\n0uBYglY8AAAAwGOMWF1nUpmU7v7x3fra3q/pHauu0V8fj6pt5aaaHPvw2KTWdvI8HgAAAOAlQl4d\nSWVSuuvHd+kHB3+gu7fcrY+3XZprql1R/XHrslmnwROTtOQBAAAAHiPk1YlkJqm7+u5S36E+fez6\nj+ndL3+37ORhqalLilR/SINobFrJdJaQBwAAAHiMZ/LqQDKT1Af7PqhHBx/V71//+3rHxe/ILciP\nkVcLg2O5MfK4XRMAAADwFi15S1zWZfXhRz+sRwcf1Sdu+MSpgCflQ965NSlHYfiEc7toyQMAAAC8\nRMhb4u7dc68efvFh3b3lbr39orfPXDh+uIYtebmQt6aDljwAAADAS4S8Jeyxw4/pr3b9ld604U16\n1yXvmrlwalyaHq/p7ZqrWiNqigRrcjwAAAAAcyPkLVGDE4P68H9+WBd2XqhP3vhJmdnMFcYP56Y1\nbMlbw/N4AAAAgOcIeUvQZHpSH+z7oLIuq89v/byaw3OEq/HB3LRGz+QdGmUgdAAAAMAPCHlL0J9v\n/3M9O/qsPvOqz+jc9nlC3Pih3LQGLXnZrNNhxsgDAAAAfIGQt8TsGtqlf3zuH/Wrm39Vr1776vlX\nHB+UAmGptbfqZRqamFYq43Qut2sCAAAAniPkLSHJTFKf/K9PanXLar3/qve/9Mrjg1L7ailQ/V/x\nqTHyaMkDAAAAvMZg6EvIl/d8WQfGD+hLr//S3M/hlarpQOi54RMYCB0AAADwHi15S0T/WL++sucr\nevP5b9Yr17zyzBvUNOTRkgcAAAD4BSFvCchkM/rkTz+p1nCrPnTth868QTYjnazdQOiHRie1qrVB\njWHGyAMAAAC8RshbAv7lhX/R7uhu/d61v6euxq4zbzBxTHKZ2rXknUjo3C5a8QAAAAA/IOT5XCab\n0b177tXmrs168/lvXthGNR4jb3BskufxAAAAAJ8g5Pncjw79SAMnB/Sey94jM1vYRjUcIy+TdTrC\nGHkAAACAbxDyfMw5p3v33Kvz2s7TTefdtPANCy157WuqU7ASQxNTSmUcIQ8AAADwCUKej207tk17\nR/bqNy79DQUDZ9Gpyfig1LhCamyvXuHyGD4BAAAA8BdCno99Zc9X1N3Urbdc8Jaz23B8sGbP4x0a\nZfgEAAAAwE8IeT71zPAzevzo4/q1S35NkWDk7DY+WfuB0Nd0EPIAAAAAPyDk+dS9e+9VW7hNt2+6\n/ew3PnlEal9d+ULNYXAsoZ42xsgDAAAA/IKQ50ODE4N6+ODDuuPiO9QaaT27jTNpKTEqtfRUp3Cz\n5IZPoBUPAAAA8AtCng/98MUfysnpbZvedvYbJ0YkOallVcXLNRfGyAMAAAD8hZDnQ4+8+Ig2d23W\nmtZFDIEQH8pNW6vfkscYeQAAAID/EPJ8ZmRyRLuGdum15712cTuIR3PTlu7KFWoex09OKZ11WkPI\nAwAAAHyDkOczPx78sZycXnfu6xa3g/hwblqDZ/JGYklJUk9bY9WPBQAAAGBhCHk+88MXf6g1rWu0\nqXPT4nYQy9+uWYNn8kYTuZDX1RKu+rEAAAAALAwhz0fiqbgeP/K4Xnfe62Rmi9xJVApGpMYVlS3c\nHEbj05KkzuazHMcPAAAAQNUQ8nzkscOPKZlNLv5WTSkX8lq6pcWGxLMwGk9JkrpaCHkAAACAXxDy\nfOSRQ4+os6FTV/ZcufidxKM1Gz5hLJ5UMGBqb+R2TQAAAMAvygp5Zna7mT1jZlkz2zJr2UfNrN/M\nnjOzW0rmvyE/r9/MPlLO8etJKpvSo4ce1WvOfY1CgdDidxSP1mwg9NFEUp3NYQUC1W81BAAAALAw\n5bbk7ZX0VkmPls40s0sk3SHp5ZLeIOlvzCxoZkFJfy3pjZIukfTO/LrL3vZj2zWRmijvVk1JikVr\nMnyCJI3GkjyPBwAAAPhMGU1GknNun6S5Ogm5VdJ9zrlpSQfMrF/Sdfll/c65F/Lb3Zdf97/LKUc9\neOTFR9QUatKNq29c/E6cq+ntmqOJpDp5Hg8AAADwlbJC3ktYI+nxks+D+XmSdGjW/Ovn24mZ3Snp\nTknq7e1VX19fZUu5CLFYrOLlcM7p+4e/r42RjXr8J4+feYN5BNNxvSozrf7jExqsQV0NRhNa3RKo\n2e+lGnWPhaP+vUX9e4e69xb17x3q3lvUv7eWev2fMeSZ2cOSzplj0cedc9+db7M55jnNfXuom+/Y\nzrl7JN0jSVu2bHFbt2596cLWQF9fnypdjoHxAZ148YQ+cOUHtHVTGfseeV76iXTh5TfowivK2M8C\nJX/yA21af462br2s6seSqlP3WDjq31vUv3eoe29R/96h7r1F/Xtrqdf/GUOec+71i9jvoKRzSz6v\nlXQk/36++cvWrqFdkqSre68ub0fxaG5ag2fyslmnsURKXTyTBwAAAPhKtYZQ+J6kO8yswcw2SNoo\naZukJyVtNLMNZhZRrnOW71WpDEvGzqGd6mjo0Ib2DeXtKDaUm9Yg5J2cSimTdYyRBwAAAPhMWc/k\nmdltkv5KUrekfzOzp5xztzjnnjGzbyvXoUpa0vucc5n8Nr8j6SFJQUlfdc49U9ZPUAeeGnpKV/Zc\nOVcHNmenhi15o/GkJAZCBwAAAPym3N41H5D0wDzLPi3p03PM/3dJ/17OcevJyOSIBk4O6K0b31r+\nzoohr/q9axZCHr1rAgAAAP5Srds1sUBPDT0lSbqq56rydxaPSk2dUjBc/r7OoNiSxzN5AAAAgK8Q\n8jy2c2inIoGILllZgTHh41Gppaf8/SzAWCIf8loJeQAAAICfEPI8tmtoly5ddakiwQqEpVi0Js/j\nSdJoPCWJljwAAADAbwh5HppMT2rfyL7yh04oiEel1lqFvGk1hgNqigRrcjwAAAAAC0PI89De4b1K\nu3RlnseTpPhQTVvyaMUDAAAA/IeQ56Gdx3dKkq7ovqL8naWT0tR4zULeWCLJ83gAAACADxHyPLRr\naJcu7LhQKxpWlL+zxHBuWqOQNxJPqpOWPAAAAMB3CHkeyWQzejr6tK7uqdDzeLGh3LRWLXnxJAOh\nAwAAAD5EyPNI/4l+xVIxXdlzZWV2GM+35LXWaAgFWvIAAAAAXyLkeWTnUO55vMr1rFloyVtVmf29\nhGQ6q4nptFbSkgcAAAD4DiHPI7uO71JPc49Wt6yuzA7j0dy0BrdrFgZC7yTkAQAAAL5DyPPIU9Gn\ndFXPVTKzyuwwHpVCTVKktTL7ewmj8VzI45k8AAAAwH8IeR4YSgzpaPxoZYZOKIhFc614lQqNL2GM\nkAcAAAD4FiHPA3uieyRJl3dfXrmdxqNSa40GQk8Q8gAAAAC/IuR54OnhpxUOhLW5a3Pldhofqtnw\nCYXbNeldEwAAAPAfQp4Hdkd3a3PXZkWCFQxJ8eGa9KwpnQp5Hc3hmhwPAAAAwMIR8mosnU3rmeFn\nKnurpnO52zVbajdG3oqmsMJBTh8AAADAb7hKr7H9Y/s1lZmqbMibHJOy6ZrdrjkST/I8HgAAAOBT\nhLwa2x3dLanSna4M56atNWrJSyTVya2aAAAAgC8R8mps9/BurWxcWblB0KVcpytSDZ/JS9GSBwAA\nAPgUIa/Gdkd36/Luyys3CLqUex5PqtntmmPcrgkAAAD4FiGvhk5MndDAyYHK3qopnbpdswYdrzjn\nNBpPqpOQBwAAAPgSIa+G9gznBkG/ovuKyu44NiRZQGruqux+5xBPZpTMZNXFGHkAAACALxHyamj3\n8G4FLKCXr3x5ZXccj0rNK6VAsLL7ncNYYSB0WvIAAAAAXyLk1dDu6G5t7Nio5nBzZXccj9Z0+ARJ\nWknIAwAAAHyJkFcjWZfVnuieyj+PJ0ljB6UVayu/37kORUseAAAA4GuEvBoZGB/QRGqi8iEvm5VG\n9kurNlV2v/MYzYc8nskDAAAA/ImQVyNPR5+WVOFB0CVp/JCUnpJWbazsfucxlqAlDwAAAPAzQl6N\nPB19Wm2RNq1vX1/ZHY/sz01r1JI3Ek8qFDC1N4ZqcjwAAAAAZ4eQVyM7ju/Qld1XKmAVrvLh2oa8\nsfwYeRUdzB0AAABAxRDyamB4clgDJwd07TnXVmHnP5OaOnNDKNTAaDzJ83gAAACAjxHyamD7se2S\nVKWQt19auVGqUcvaWCKpLp7HAwAAAHyLkFcDTx57Ui3hFl3cdXHldz78s5rdqinlnskj5AEAAAD+\nRcirgSePP6mre65WKFDhzkqmxqXY8Zr1rCnlbtfsbAnX7HgAAAAAzg4hr8qGJ4d1YPyAtpyzpQo7\n789Na9SSd+TEpE4kUtqwqrUmxwMAAABw9gh5Vbb9eP55vN4qdboi1SzkPXFgRJJ0/YaumhwPAAAA\nwNkj5FXZ9mPb1Rxq1uaVmyu/8+GfSYGQ1Lmu8vuewxMvjKqtMaTNL2uvyfEAAAAAnD1CXpVtP7Zd\nV/VeVfnn8aRcyOs6XwrW5hm5Jw6M6voNXQoGGCMPAAAA8CtCXhWNTI7o+fHnq3OrpiSN9NfsVs2h\nk1M6MBzX9RtqMx4fAAAAgMUh5FVR8Xm8aoyPl0lLI8/XrGfNxw+MSpKuP5/n8QAAAAA/I+RV0ZPH\nnlRTqKk6z+OdOChlU7XrdOWFEbU2hHQJz+MBAAAAvkbIq6Idx3fo6p6rFQ5U4Zm5Qs+aK2vTkvfE\ngVFtWd+pUJBTBgAAAPAzrtirZGRyRP0n+qszPp5UMnzChdXZf+mhYtPqH4rxPB4AAACwBBDyqmTH\n8R2SqvQ8npQLeS09UlNndfZfYhvP4wEAAABLBiGvSh459IjaIm26ZOUl1TnAcO161nzihRE1R4K6\nbM2KmhwPAAAAwOIR8qrgZPKkHj74sN604U3VeR5PyrXk1ahnzScOjOqadZ0K8zweAAAA4HtctVfB\n9w98X9OZad124W3VOUB8RJocrUnIG4sn9eyxCV2/gVs1AQAAgKWAkFcF3+n/jjZ2bqzirZqFTleq\nf7vmtoHC83h0ugIAAAAsBSGvC1Bv+sf6tWd4jz605UNSelrJVErpdFLpVErpVFKZTErpVEqZVFLO\nZeWck3NOpqxc1slJcs5Jys13WSeTy/3POck5tR18WL2S9qV6NX3oRG69/PGdU35b5fdV2J9mrSMV\nt3LzL/vX3UfVEAro8rU8jwcAAAAsBYS8Chk5MqAj33qvvt14RME2p5vuv1uWfb8ikiJVON6Ea9Iv\nfOOgsjpUhb3P9OpN3WoIBat+HAAAAADlI+RVyMCOB3V5/L/0yMp1ujzZrhdWvUrPN66QBcOyYEgK\n5Ka5V0SBYEgWyAUnJ5OZSZafKv9ekswkBSRTfl5u2VTLufpyx0aZKT8vt0puEyusLpPlp4WFhYmp\nuHvN3Hb2/I09ThrujwAADutJREFUbdWpNAAAAAAVR8irkPT4MT3a3KSTQaffvOn/6BXnvsbrIgEA\nAABYhuh4pUIsdkz3t7ZrVdMqvWLNK7wuDgAAAIBlqqyQZ2a3m9kzZpY1sy0l81ea2Y/MLGZmX5y1\nzTVmtsfM+s3sC1a4P3CJi08e1mPNEf3iBb+oUIAGUgAAAADeKLclb6+kt0p6dNb8KUmfkHT3HNt8\nSdKdkjbmX28oswy+8KIbUtZMN513k9dFAQAAALCMlRXynHP7nHPPzTE/7pz7iXJhr8jMXiap3Tn3\nU5fr1/8bkn6pnDL4hpuQJHU2dnpcEAAAAADLWa3vK1wjabDk82B+3pzM7E7lWv3U29urvr6+qhZu\nIWKx2OnlcE5SXNIKPbXtKfUH+z0oWf2bs+5RM9S/t6h/71D33qL+vUPde4v699ZSr/8zhjwze1jS\nOXMs+rhz7rtneby5nr9zc8zLLXDuHkn3SNKWLVvc1q1bz/JwldfX16fZ5cjEx/Szp3I/xs1bb1Yk\nWI2R8TBX3aN2qH9vUf/eoe69Rf17h7r3FvXvraVe/2cMec6511fweIOS1pZ8XivpSAX374kTQwcV\nD5hCChDwAAAAAHiqpkMoOOeOSpowsxvyvWq+S9LZtgb6zkT0kOKBgBoDjV4XBQAAAMAyV+4QCreZ\n2aCkGyX9m5k9VLJsQNLnJP26mQ2a2SX5Re+V9BVJ/ZKel/RgOWXwg6nRI4oHAmoKtXhdFAAAAADL\nXFkdrzjnHpD0wDzL1s8zf7ukS8s5rt+kThxRzExtDe1eFwUAAADAMlfT2zXr1sRRnQyE1NZIyAMA\nAADgLUJeBYTixzUeCKs90up1UQAAAAAsc4S8CmicGlI8EFRLmGfyAAAAAHiLkFcBralhJQJGyAMA\nAADgOUJeubJZdWRGNRVwhDwAAAAAniPklWtyVAGllbQsIQ8AAACA58oaQgFS8sRhTZtJEiEPAAAA\ngOcIeWU6OXRI6UCuQZSQBwAAAMBrhLwyJUYGlQrkWvJawwyhAAAAAMBbPJNXptTYEcXzLXnN4WaP\nSwMAAABguSPklSk7cVRHLRfuaMkDAAAA4DVCXpmCsWM6am2SeCYPAAAAgPcIeWWKTA4pGsyFO0Ie\nAAAAAK8R8srUkhzWeIiQBwAAAMAfCHnlyGbUnhlVLNIkiZAHAAAAwHuEvHLEhxVUVpORRoUDYUWC\nEa9LBAAAAGCZI+SVY+KoJCkZjtCKBwAAAMAXCHllmBo9LElKRoKEPAAAAAC+QMgrQ2x4UJKUDgUI\neQAAAAB8gZBXhuRYriUvHcoyEDoAAAAAXyDklSE9fkRR166MptUcbva6OAAAAABAyCtHIH5MQ65T\nyWyCljwAAAAAvkDIK0M4MaQh16mpzCTP5AEAAADwBUJeGZqnoxoPrVIsFSPkAQAAAPAFQt5iZVJq\nSY8p1rBKk2la8gAAAAD4AyFvsWJDCsgp1tQlSYQ8AAAAAL5AyFusYER/F/xlRTsulETIAwAAAOAP\nhLxFci2r9OmptynRtU4SIQ8AAACAPxDyFml8MqVUxqmlKS2JkAcAAADAHwh5i3QikVJbQ0jNjYQ8\nAAAAAP5ByFuk9atatOd/36LL1jZIEoOhAwAAAPAFQl6ZEumEJKk53OxxSQAAAACAkFe2WComiZY8\nAAAAAP5AyCtTIpVryeOZPAAAAAB+QMgrUywVUzgQViQY8booAAAAAEDIK1c8FacVDwAAAIBvEPLK\nlEglCHkAAAAAfIOQV6ZYKkbIAwAAAOAbhLwyJVIJetYEAAAA4BuEvDLFUjHGyAMAAADgG4S8MtHx\nCgAAAAA/IeSVKZ6Kc7smAAAAAN8g5JUpnopzuyYAAAAA3yDklSHrskqk6XgFAAAAgH8Q8sqQSCUk\niWfyAAAAAPgGIa8M8VRcEiEPAAAAgH8Q8spAyAMAAADgN4S8MhDyAAAAAPgNIa8MsVRMEiEPAAAA\ngH8Q8spQ6HiF3jUBAAAA+AUhrwyFljzGyQMAAADgF4S8MvBMHgAAAAC/IeSVoRDyuF0TAAAAgF+U\nFfLM7HYze8bMsma2pWT+TWa2w8z25KevK1l2TX5+v5l9wcysnDJ4KZ6KKxQIKRKMeF0UAAAAAJBU\nfkveXklvlfTorPnDkn7ROXeZpHdL+r8ly74k6U5JG/OvN5RZBs/EUjFa8QAAAAD4SqicjZ1z+yRp\ndmOcc25XycdnJDWaWYOkLkntzrmf5rf7hqRfkvRgOeXwSiKV4Hk8AAAAAL5SVshboLdJ2uWcmzaz\nNZIGS5YNSloz34ZmdqdyrX7q7e1VX19fNcu5ILFYrFiOg0MH5dLOF+VaDkrrHrVH/XuL+vcOde8t\n6t871L23qH9vLfX6P2PIM7OHJZ0zx6KPO+e+e4ZtXy7pTyTdXJg1x2puvu2dc/dIukeStmzZ4rZu\n3Xqm4lZdX1+fCuX45kPfVG+2V34o13JQWveoPerfW9S/d6h7b1H/3qHuvUX9e2up1/8ZQ55z7vWL\n2bGZrZX0gKR3Oeeez88elLS2ZLW1ko4sZv9+EE/F1dHY4XUxAAAAAKCoKkMomFmHpH+T9FHn3GOF\n+c65o5ImzOyGfK+a75L0kq2BfhZLxXgmDwAAAICvlDuEwm1mNijpRkn/ZmYP5Rf9jqQLJX3CzJ7K\nv3ryy94r6SuS+iU9ryXa6YqU63iF3jUBAAAA+Em5vWs+oNwtmbPn/7GkP55nm+2SLi3nuH4RS8XU\nHG72uhgAAAAAUFSV2zWXg6zLKpGmJQ8AAACAvxDyFimRSkgSz+QBAAAA8BVC3iLFU3FJ4nZNAAAA\nAL5CyFskJ6fLuy/XOc1zDSEIAAAAAN4oq+OV5eyclnP0rTd9y+tiAAAAAMAMtOQBAAAAQB0h5AEA\nAABAHSHkAQAAAEAdIeQBAAAAQB0h5AEAAABAHSHkAQAAAEAdIeQBAAAAQB0h5AEAAABAHSHkAQAA\nAEAdIeQBAAAAQB0h5AEAAABAHSHkAQAAAEAdIeQBAAAAQB0h5AEAAABAHSHkAQAAAEAdIeQBAAAA\nQB0h5AEAAABAHSHkAQAAAEAdMeec12VYEDOLSjrodTkkrZI07HUhlinq3lvUv7eof+9Q996i/r1D\n3XuL+veWX+t/nXOu+0wrLZmQ5xdmtt05t8XrcixH1L23qH9vUf/eoe69Rf17h7r3FvXvraVe/9yu\nCQAAAAB1hJAHAAAAAHWEkHf27vG6AMsYde8t6t9b1L93qHtvUf/eoe69Rf17a0nXP8/kAQAAAEAd\noSUPAAAAAOoIIQ8AAAAA6gghb4HM7A1m9pyZ9ZvZR7wuT70zs3PN7Edmts/MnjGzD+Tn/6GZHTaz\np/KvN3ld1npkZgNmtidfx9vz87rM7Admtj8/7fS6nPXIzC4qOb+fMrOTZva7nPvVY2ZfNbMhM9tb\nMm/O891yvpD/t2C3mV3tXcmXvnnq/k/N7Nl8/T5gZh35+evNbLLkv4G/9a7k9WGe+p/3u8bMPpo/\n958zs1u8KXX9mKf+/7Gk7gfM7Kn8fM7/CnqJ68y6+e7nmbwFMLOgpJ9JuknSoKQnJb3TOfffnhas\njpnZyyS9zDm308zaJO2Q9EuS3i4p5pz7M08LWOfMbEDSFufccMm8z0oadc59Jv+Hjk7n3Ie9KuNy\nkP/uOSzpekm/Ic79qjCzV0uKSfqGc+7S/Lw5z/f8Be/7Jb1Jud/L551z13tV9qVunrq/WdIjzrm0\nmf2JJOXrfr2kfy2sh/LNU/9/qDm+a8zsEkn/IOk6SaslPSxpk3MuU9NC15G56n/W8j+XNO6c+xTn\nf2W9xHXmr6tOvvtpyVuY6yT1O+decM4lJd0n6VaPy1TXnHNHnXM78+8nJO2TtMbbUi17t0r6ev79\n15X7MkR1/byk551zB70uSD1zzj0qaXTW7PnO91uVuyBzzrnHJXXkLxawCHPVvXPuP5xz6fzHxyWt\nrXnBlol5zv353CrpPufctHPugKR+5a6PsEgvVf9mZsr9YfsfalqoZeIlrjPr5rufkLcwayQdKvk8\nKAJHzeT/enWVpCfys34n31T+VW4ZrBon6T/MbIeZ3Zmf1+ucOyrlvhwl9XhWuuXjDs38B55zv3bm\nO9/596C23iPpwZLPG8xsl5n92Mxe5VWhloG5vms492vrVZKOO+f2l8zj/K+CWdeZdfPdT8hbGJtj\nHve51oCZtUq6X9LvOudOSvqSpAskXSnpqKQ/97B49ewVzrmrJb1R0vvyt5SghswsIuktkv4pP4tz\n3x/496BGzOzjktKSvpWfdVTSec65qyTdJenvzazdq/LVsfm+azj3a+udmvlHPs7/KpjjOnPeVeeY\n5+vzn5C3MIOSzi35vFbSEY/KsmyYWVi5//C+5Zz7Z0lyzh13zmWcc1lJXxa3ilSFc+5Ifjok6QHl\n6vl44daE/HTIuxIuC2+UtNM5d1zi3PfAfOc7/x7UgJm9W9KbJf2Ky3cekL9NcCT/foek5yVt8q6U\n9eklvms492vEzEKS3irpHwvzOP8rb67rTNXRdz8hb2GelLTRzDbk/7p+h6TveVymupa/F/1eSfuc\nc58rmV96//NtkvbO3hblMbOW/EPIMrMWSTcrV8/fk/Tu/GrvlvRdb0q4bMz4Ky7nfs3Nd75/T9K7\n8j2t3aBcpwhHvShgvTKzN0j6sKS3OOcSJfO7850RyczOl7RR0gvelLJ+vcR3zfck3WFmDWa2Qbn6\n31br8i0Tr5f0rHNusDCD87+y5rvOVB1994e8LsBSkO/h63ckPSQpKOmrzrlnPC5WvXuFpF+TtKfQ\nfbCkj0l6p5ldqVwT+YCk/+lN8epar6QHct9/Ckn6e+fc983sSUnfNrPflPSipNs9LGNdM7Nm5Xrz\nLT2/P8u5Xx1m9g+StkpaZWaDkj4p6TOa+3z/d+V6V+uXlFCu11Ms0jx1/1FJDZJ+kP8eetw599uS\nXi3pU2aWlpSR9NvOuYV2GoI5zFP/W+f6rnHOPWNm35b038rdRvs+etYsz1z175y7V6c/jy1x/lfa\nfNeZdfPdzxAKAAAAAFBHuF0TAAAAAOoIIQ8AAAAA6gghDwAAAADqCCEPAAAAAOoIIQ8AAAAA6ggh\nDwAAAADqCCEPAAAAAOrI/we7BDTPkhBzAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc068ae2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for opt_mode in opt_modes:\n",
    "    plt.plot(range(1, num_epochs+1), -np.array(train_losses[opt_mode]))\n",
    "plt.grid(True)\n",
    "plt.legend(opt_modes)\n",
    "#plt.plot(test_losses, 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final performance:\n",
      "rebar_0.1: -58.12\n",
      "reparam_0.1: -57.67\n",
      "no_baseline: -88.05\n"
     ]
    }
   ],
   "source": [
    "print('Final performance:')\n",
    "for opt_mode in opt_modes:\n",
    "    print('{}: {:.2f}'.format(opt_mode, -train_losses[opt_mode][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 layers linear model:\n",
    "\n",
    "##### 800 epochs corresponds to 2000 thousands steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fcc6853c898>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3kAAAHVCAYAAABMsTJpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsnXV4VNfWh98zFnf3BJJAcHdrgUIp\npVBvqbv7vbVbu/VLeyu33q8uUIFSSksFCVAo7hIggbjbRCczmTnfHyskBCjSAgmw3+fJk8yZI/us\nI9m/vdZeS9N1HYVCoVAoFAqFQqFQnBoY2roBCoVCoVAoFAqFQqE4diiRp1AoFAqFQqFQKBSnEErk\nKRQKhUKhUCgUCsUphBJ5CoVCoVAoFAqFQnEKoUSeQqFQKBQKhUKhUJxCKJGnUCgUCoVCoVAoFKcQ\nSuQpFAqFQqFQKBQKxSmEEnkKhUKhUCgUCoVCcQqhRJ5CoVAoFAqFQqFQnEKY2roBR0pwcLAeHx/f\n1s1oRW1tLV5eXm3djNMSZfu2Q9m+7VC2b1uU/dsOZfu2Q9m+7VC2b1vaq/3Xrl1bqut6yOHWO2lE\nXnx8PGvWrGnrZrQiNTWVUaNGtXUzTkuU7dsOZfu2Q9m+bVH2bzuU7dsOZfu2Q9m+bWmv9tc0LetI\n1lPhmgqFQqFQKBQKhUJxCqFEnkKhUCgUCoVCoVCcQiiRp1AoFAqFQqFQKBSnEErkKRQKhUKhUCgU\nCsUphBJ5CoVCoVAoFAqFQnEKoUSeQqFQKBQKhUKhUJxCKJGnUCgUCoVCoVAoFKcQSuQpFAqFQqFQ\nKBQKxSmEEnkKhUKhUCgUCoVCcQqhRJ5CoVAoFAqFQqFQnEIokadQKBQKhUKhUCgUpxBK5CkUCoVC\noVAoFArFKYQSeQqFQqFQKBQKhUJxCqFEnkKhUCgUCoVCoVCcQiiRp1AoFAqFQqFQKBSnEErkKRQK\nhUKhUCgUCsUphBJ5CoVCoVAoFArFkeBytXULFIojQok8hUKhUCgUCsWxo3w3/P4K7JjX1i05Msoy\n5GcvldlQXXTgepu+gRdiYf3nJ65tCsVfxNTWDVAoFAqFQtGOsddKZz15HLj5nLjjupyg62A8gV0V\nlwtsleAZePh1dV1+a9rxbVN7oaYYZt4AHgFQXQgVeyB+GJz1DDjqmz6PgF2/wLfXg7NBtrvyO+h4\nZtu2/VAseh4WvwCaAXpeBtUFkLEITO5wxsMw6DbQjLDoGVj6siyf9xB0GAV+0W3d+uOLywWZSyBm\nIJg9Dr++rkPBRnlPBHX88/UaG2DrbEg+C6oKZN+BCceu3QpAiTyFQqFQKBQHQ9chZyWs+Qg2zQCP\nQDj3VehyHpTuEm9N8rjjc+ydv8DsWyFxLJz/7qHXdTmhaCs0VEPaj9D3GghOgsyl4HRA4ug/37a6\nEOb9U4Ssuz+k/wY2KySdBeNfOLCj2tgAdeWQsRAWvwihXaDrZOn4J44+sSJ4f4q2QX05xA0V4VmV\nL+1y84U5d4BnEAy9GzyDpf1xg8Hi1XofTgesfAd2/Qpo0FCNKeF+WPcZzH8C7HWADt6h0OEM2D4H\nsldAVZ5sH9pFPGLh3eH89+CzKfDjA3D2ixDVV+xTlgFrPoCsPyCqD4x9CizekLMKwrqIiDwaNs6A\nkjToNVWu+5GQtxYWPgO6C/Ysga7ni83S5oJvtNipdBf89jikvgC+kVCWDn2uhiF3wdtDRByOfgwc\ndRDY4ejafDJQWwazb5F7IWmc2DZvHUx+q0WQuVxyLfPWgtEC6QugKldE8fjnYeDNrffpqJfnrSwD\nspaBwQwuh3zX41K59sPvB++Q43dO276T5zh2sBwvYyGU7pT2p82V95xnIBgteHudCYw6Pm05ASiR\np1AoFIrTm8It0rGPGwKVWeDud/QdzbbG5QKDASqyYMG/xcPS5yowGA9c114Hc+4E/1gY84Qsq8yW\nznhdqXhm4oZI5+3H++X7npdLR/rrq2D4A/JdfQWc8S85jk/YwdtVmQ0fnwMBCTDiHxDdH/LXQ+yg\ng3vAGu0w/0lY8aZ83jQDxj2Lm60Ylv5XvEm6E1ImQcJwacPs22HHjy37WPGmCJm6UulE3rYCjGbp\nVFZkikirLYbcNXLddV06sAUbIXm8eGdW/R+8OwKu+wXCu8GepbD1O+nwWnPkOEFJsHOe/AAY3WDA\njbBtDvS8RNqaci64GqUT2e962d7dFxLHHP6aNjbA/KfE7iMfhNiBLd/lb4Dlr8PYp6E8A5a9Jh1s\ndBHGXSaJt0nTIH64tFEzwKav5N7Y+p2IwU5nw5aZMOl/sOs3WPi0CB83XzmOo55e1kegLke8OWf/\nB4ISxZ5GM+yYDNMvg84T5ZxWvCXnPGGadJQnvS5evS8uFCHnFSzXwGCS46//XK5LY4PY1SdChEHi\nWPHu/HA3RPSEM/91cE9S5u8yGKC7YPkbIvAH397aK1SRBRunixDrPFE8jjOmyuCAbyRE9oZzX5Pr\nsi+6LjZNnw9FW2DgLdD/BrFp/xvkPtvQFLY5/H4487Ej8+rufVZPFFu/gzUfyrM3+A6w5kLBBnlu\n92fnL2Crknv+i4ugpkgGdbZ9L2JI0+DXf8Eln4vtf7xP7m2zlzyXyeOgw/2w81f4+SEo3CyDIHvv\n943TYd2n8vfgO+T5jRkoAwWbZsg9uv5z6HyOCO2wLq3bV5kj24R1a7Gh0yH7bKiCATeDxbP1NrVl\nsOo9qCmEHT/L7/2xeIO9Rmxkcpdn12nH4DHs79m+jdH0veEG7Zx+/frpa9asaetmtCI1NZVRo0a1\ndTNOS5Tt2w5l+7bjtLa90wFoB4bu1RRL5+9oPCgul3QILN6w4ClY/j9Ah/AeULhJvDhTv5GOipu3\njPhqWvu1/9bZMOcuGPGAdEj3LAF0OY++10JtiXToNE0E1vd3QtFm2fb+HSJC3jsDGm1iE6MZJv5X\nOufBydB1CvS7Trb//ALxkPnHSad59yLwDofbVxwojHVdBMCexTI6XpUr69RXwJR3oeelLetWZIm4\n2zEPGuthwE3imXlvJAy7D8eKdzE31or4cDnBUSvXq3yPdM6G3Ake/tBlsnRIy9Ll+0XPynk57S3H\ncvcXARLeQzxZfa+FmP6t216ZAx+MFdt0PFMEUEO1CJw+V8q5J48XT5bFSzqGv78qnkDNIKJjf/xi\nwZotf095r8Ue7v6yr307p7WlInDS5ooHDg1uWgQlOyCsK3x5sXSgLd7iSfKJhB4XgVeIeJ9cjdJh\n9QmH7T+I12388yKI8teLwMpZJV4UgxnMnvJMdDwTUiZC76b7ZdevNH59HSbvILh1mQyA7I81T8TZ\nnwkXex3krBD7WHNh2D1y/KCOkLkMpl8qYmvInbD6A8hfJ9t5hYjNG20w5km5tpu+Ett4BMCoh+Ct\nQXKuV8yExdNg6yzxMg5uGsTIWCCe6L3eor2eI4sPXPsTRPQ4eJsPR105/PywiKHi7bDhC+h9JUx8\nVd5RjXa5Lz0D5R794w2oK4OCTeIB7z0Vzn394IMwLqeIsg1fUGOtxLv3FBj9OGz4Up7vPlfB5m/k\nWRj3nITFzr1PxL5vpIiylPPAXg2pL4oY9YsRb6ubr1zX+gq5Bz0CZADAmidhyjkrW9ph8Yar50Bk\nH1ke0kkGPxY9A25+8gwGxMMZj8qgi6sRzO6ybUO1vFPKdoFXKNzwmwisP94Um1z/K5jcWp93o12e\n2xVvwtbv5Zmd9D955px2ebaWvSbH6XIejH5CrsPOeRJGCzDhJRlosVWJJzayN3x2ngzSuPnIPXXB\n+3K/Zv8hHvzIPnIdGxsOaFN7fedrmrZW1/V+h11Piby/Tnu9+KcDyvZth7J923FK2H7LLBFlcUOk\no3W4Ee26chFim76WDsrg28Bhk060zSqjvmYPCSFKGgvFaSJCksdJJ+9gfHerdJL8Y6TD1fda6Qz8\n9rh0dAD+sRumNYVgRfWFKe+x+8dX6dCxo4RsHWrOVn2ltG//dXQddvwkotEzUDoYWculc523Tjxd\n1YXSoTKYpG0uh4io8gzoNOHA0MOSHdLRtfhAg1WWndPU4fn5kZZ5URG9pHNXskNExZA74JdHZL5R\n9h9Qmi4dr7pS+ORc2cYnAq6aAyHJLcez10pYYGRvETOZSyUkL6ijiMFeU6VDaTCIuPjqCvE2DbhR\nOvBZy6QjV1cGCSNEfJSlw9pPpPPW6zIZxd87h+vjiXIMgBsXSXifwwZrPxavQHg3GHir/D4YaT+K\nQAtNEQ9WcKcjn+OXvwFSn5ewQmcD3LxEOrp/RmODCJnOE+R6JoyQQQOPAFj0nNi5z9VyLzfWt97W\nJxImvylejY0zxIPXUAXjnhWv1nujpN02a8s2ox6WkEzPQPGuunnL8ry1UFchNjQY5JnwjRRPla6L\nZzA4WfZVmQUmD1gyTb4/65kDQjiX/TqboUOGHpsQOl0/0Ntls4rINJrlc1WBdNpXvy+d9l2/ynOi\nGVvucYBh90pylws/gm7ny7Kc1fDR2S2iTjOKKBp+v5zr9rni5et+0ZHNuzzSc1r0HCz5D3QcLZ7M\nP94QQZs4RoSZrou32zdahNHGL0WEj/23vAubbVElQmjxCxDZh4o6OwGVW+Cc/0p4aX1562MHJUmY\nYfFWiBsm74zqfPHe5q2VAYABN8t1LdslwrQkTQYOirfJPiw+EBgv+0keL8/k+k/led5/LqWzETZ/\nLfs2mOQe9PA/uF0aG2RA4cN9Qro9g+CC/zv8HM3aUhH/uatbL+95uXiDl7/eennXKfIOM1lg3PPw\n1VQZ3PKPlWiCCS+JJ13TjmoObXv9n6tE3gmgvV780wFl+7ZD2b7tSE1NZdTIkTJC3JZzf/4qZRnw\nRn8J6wERAz0vlQ6nyU3ER/xw6Zi6nBI+99vj0jnueZmEEtUWN+1Mk1Hw4E7yT7t4m3Sw0ucDugjC\nCS9Bj4vl+70hUpu+hlk3QvQAGXXuew10u0B2aauSDuXM62HMUzIHqdME8YwZzTL6DTLCrRkkoYR3\naGsxaauSDnldGVzwASQ1hSnpuoRIrv9M2owu3qJ9O/sega07cZpBzlN3yjEbbTKin79e7NT3Gph9\nm3iu7t4g7fQOhYSRcs6VOWLD3ani4fCPk47ZpV/IerNuEs8IwKVfirgC8RBVZEpnb69wOBQbvhTR\ntdcLENYdQjuLJ9Q/Bm5KbenAg4RJzrlLrmVtiXhX4oZIaF9A/IH3zDvDKPHrScgdPx++LccDW5WI\n/z8bNDgSiraJaDnrGZnjtf4zuX+8QkTkzntQrpe7n3TSYweLVyi0s2y/5kOYe68IlpAUEdVJZ52Q\npC9t8s7XdQmrDEgQ4fLLo/K8j3tWnu2XO4vwDusGNy9tPVhUsEnut7J0mSN4qAQgx5JV78v7ylEn\n93FkHwmLjOwDZz0tQnsv6z4VL1tVrswHdNTJM7k3lLHHJTDlXVJTFzEq43nIXSXLp34rA0GegfJ7\n12+yjz5Xy0CKywlLXoLU5yQxzOgnZGBkX/YmF0qbK+/cTme3fj6PNRu+lLDPpLPEC32kOB0yKGav\nk3e1T6SELLtcIqjd/cSjXpUnNlz/Ofz6qIhW71CxR/oCEaGT3/lLCZzaa39HibwTQHu9+KcDyvZt\nh7L9MWDrd9KB73SO/N7bQSnZId4Td1+Z7xDRq1UnOzU1lVHGdeLZGvtvGaF1NYoIOFgY1bGiaKu0\n66+MfK96X4RG7yvlH3PWcul4OOrkHDMWAvv8H5r0P+nIzr1P5n0BnPcm9L5Cwp4qsyCks3jK3P3F\ni2evhV8eln/oyePkWL88IuKw6/kQP1Q6iWYPmfgf2Ruunnvwf/q2KvhPAniHSefhznUiDBe/QFlg\nX4IumCbnlLGoZW5H3FAJmyrfLd6l9PnSySvfDcPuk7Y37YMuk6VzFd5DvDaJYyRMr7ZUwkZTzpVw\nOc0gndmGKmioEYHx2RTIWyNCzdUoI+9Ou8wVOvvFQ1+Hg3lQGhtEOIR3h0G3Hv213Z+CjTK3Ztnr\n0r64wTDqkdaewP2PX5EpHXmT5c/3a81lyZqtjBh9nJK8nGh0Xe7DfcMzrXnwzjAZ7JjyrngB971e\nzR64Tid2Phft9J3//R0y9/HGBUeebOVE0FAj3tWgxMNfJ3utJO9Z/oa88+ubvK++UfJ+9wwU2/dO\nFM+u7pSBoyMR9mUZ8lyd4HulTWmokYE5a66EJh+DZDjt8t5HibwTQnu9+KcDyvZth7L938DpkHCZ\n1e9LGJFflPweeIuMSs9/UkK7Bt0mCRBCu8JlXzZ7NxYvXMDItbe0eLPc/GQ7vyZviaa1DrVyuaSz\nbbJIyMpP/5C5CVd82zpECKQTWVsi/yCtuTLiqhlkZHr7HPG2XTGzxZux1+sVO1jWy1goo8/7Cqdt\nc+DrK/c5iCZiZN+Ma3Xl0rlx1EsmN4dNRM7vr4g4ShonwudoPRYup+wj9XmxQVRfCW2y5sBFnxw6\n9OyjCRJWaLTAIwUiSOc9yEq3YQycMFXWyfpDQsqi+8Hi/7R4J9Fg4iviefz+dtg2W66xs0E8bFfO\nlpAzd/+jPyddF1Hk4S+hjzarXJceFx84v6UtOQ6lBU6L905VgXgs2lnSn3Zpe6dDIhrama3+Ek6H\nvENzVkkI5z7v0HZp+9OI9mr/IxV5KrumQqFQHCsc9RJuE9RRQtJWvisekhH/kLk5398uoXCDbhNv\njr1OMvn9/KBsHz9cOvELn5aQk6pcmbx+7TwI6URQ2SoReJd8IR6+LTMlUUXZLni5k3iorvpeMp7l\nb5CsZ446mQdiszaJQE8Re2OekvlFHv4yByj1BZmPtReLT0sCgQE3w7pP4NXuIrxih8iIaW2JrLs3\nmUHeWklkUFMsoVWLnoOofnDJZ+Lh8Y+D6L6tbeYZ2OIhHHYvfHtdi8Cb+Npfr5FmMEoiko5nSmjc\nqEeOfE5R4mgReUGJcnyjL0x5m/rU1JZ14gZD3Lfyt1+MCOEBN4rd9mZBHPtvmZfmESDeyJj+MrL+\nVzummtaSNXDEA39tHyeC06Vu3LHGN6KtW3DyYDSfGgIPWkIl4wa3bTsUpxxK5CkUitMTXRcvkmeg\niJL1n4pnLLK3zHfbOxfmUFhzJcFCVF+ZW/Pj/ZJlbS9BSZLdz2aVDG/uvpJ6OuVcEX4gxy/LkPlW\nISkyR2r2LeKdGXy7TFr/eALoLpKcmgiP5PEiPjqMEo/VG/0kNDBzKXxztQiLuKGSBMMrRESg2UMy\nzpVsh6+vhi8uaH0uCSNlTpZfjLTz2+sADW5cKGEvg24R79Efb8rch/AeMs+hYIN44mqKWsIr95I8\nHs5/X/a3NzHCoeh6vmRi8wj480QaR0tUnwPnpByOxDFShiD4T8IM96f3VPnZH7+opnl7YRCceHRt\nUCgUCoXib6BEnkKhOD1otIuHwWgW0TX9csj6XcRNRabM9dqLwSRzsQLiDr6vLbNk7tWu3wBdQm00\no3izht4jIsHVKNn83h4qmdbCusmk+b2j9fvOb9s3MUCPi2WuV49LZKL++e/L/BOLF26lO+Ds91t7\ntwxGCaOsypd6ZNt/kAxkU94+eNtDkuHerXLOpTvFFiZ3qfu0735v+V3OyStIPgd2kKQH/a6T+WOR\nvSUMdG9iEZdLshx6+MtcsrqyIxPK+6JpUvusrQnrLl7V5PF/f1/xQ//+PhQKhUKhOEqUyFMoFK2x\n14kA2L8I6cmAo16SefiESzKJvWQsEu+VwSDFcBuqIXu5pFTe/oOkdb5+voTz5awWT9qKt1ons1j1\nPlQXSFbGb68Tj9eweyVt/54l4omLGSjCYN9wtclvSXaxMU8cWXIUg1H2u5eOZ8B9W6GxgdU/T6f/\nwYooB3aQn/EvitAcdNuhj+EXJT+HEiDeoQdfHtTx4NnqDIbWoZjHIt16W2EwwDVz27oVCoVCoVD8\nZZTIUyhOV7JXSsrzsK6SKr2xXlKq7/pNkkTsTaleVy5hgJ0nti7cWl0IaFL751jjsEnCjq7nS92s\nxgapi7NtjmRPNLpB4UbxKBVtkxpYU96Gr66SIs+aUQqedrsAvrtFvG4hnSGipxSOtldLseUJ06To\n874ExEsSkTUfSu0ml0OKGP/ysHjnQATebctbyhjsn8RkX6L7yc/fxeRGrXf8odcZdMvfP45CoVAo\nFIqTHiXyFIrTkQ1fSn2tvanrI3pKMdG0uVIYes8SmZOUNE4SbKz7VFJ6D7qNmOx5UBAA746QTIt3\nbZAsg2ZPqYMTnPTXEy+4nPKT+rxkbsxdIzXAirdKdsjQLlK0F2RumkcAdD0P1n0Gbw6SsMnz/w9W\nvg0//bOp6Ox0CTEc85TMDXPYJA199IA/b8e4Z6X49O//bUlTb3SDqV/J3Le4ISdnnTqFQqFQKBSn\nBUrkKRTtlZoSmPdPCZvre62EIHr4y3eFWyQVfFCSFIGuyJSsi0PugqItUvx44K0HZmvTdZnfteFz\nmXN04YdSW2zuvVKHx90PznlZMjZ+NRW+uwl2NBUg3rME9iyhI8C7n8iyymz4/ALYvUg+//qopNQP\n6wqJY6Utfa4SobbmIxj5T8ngmPajrN/natnWMwjOfEySjOStlRposYOlzlnWMgmDPPs/UrS1ulAE\npbtvy3lZvCUZyGUzJATR7CHt/+gcMHtJXba965vdZa7cofAMhGt/loKx7v6STMXi1TL/TKFQKBQK\nhaIdc9xEnqZpXwGdmj76A5W6rvdq+u5h4HrACdyl6/ovx6sdCsVJQfYKSfMOYPKAoXfBxxMlmYbL\nASvfkWQWY56QMMvNXx+4D80g2Q8ddfJ52WuSPv7yb1oSaqT9KAJv8B0ifEwWCYfMXCpCJmGEhGSm\nTIRRD4tHDSSxR+FmSF/AVs9BdI32k8yO758pIm3UI9DlPPl7yTTJOLn6/2Tb5a9Lcg+Lt2R+BCno\nW1/e8hnAMxhyV0uIZvJ4CbXcOU+8d/vOAfMJP/Dcxz0Hox8XcQcyTw4kBHXUwy3i+GgwGFqSo/S5\n8tDrKhQKhUKhOO40NDqxGA1ox7FUi8Pp4v+W7iHOcXLUEv8zjpvI03X9kr1/a5r2MmBt+rsLcCnQ\nFYgE5mualqzrzZVkFYpTF12XgqcVmSJi9tYhm32bhAEazRIauFfEXf+LzImryofN30iKfs0AIx8U\nAVe4WVLZByfJPtd+JAKq45ni2VrxptQ3c9rFK5axSETTmKdaZ1Lse42IvH2Teox6SMI4s1dAwij5\nbti9lKSmwpBRss6456Q9/a+Xz6GdpbC3zSrp9N18pf7amKckZHLPYghIEE+frRJKdsg6bw+WOW8B\n8ZJNcm/bUs49MrtqWovAAykMfcnnYK+VLJUKhUKhUCj+NrquU1hlY2FaMd5uJjbnWtlZXMPjE7uQ\nGOr9t/Ztb3Tx3992sj67gofO7kzv2JZaiLqusynXynUfrybEx42XLupJt6iDJzOzOZykFVYT7utO\nqI8bBsPhBWGVzYFB0/B2MzF9VTYv/pzG3X3cmPC3zqhtOe7hmppI7YuBM5sWnQfM0HW9AdijaVo6\nMAD443i3RaE4oVQXgkegeMtABN5vj8Hy/8nnoi0yr8tokflfl38jmRQ/mgClO+DK2a3re/W8VDxr\nCSNExAHEDmr53jOw9frjnoWCjfDzQyLy3P0hspcUZd6/wHTMAKmHFt6z9fJOZ8vPnzHgxgOXaZp4\nzobfL5/739AyR29f0eYR0NL+vtdIWw/Wtr/KkQpEhUKhUCj2QdfFg6NpGnX2RtxMRoxNQsHp0lmW\nXkqgl4Wc8joWphWzPqeSu0cncW7PyCPaf7XNwYacSjblWsksreXqIfHNgsXl0luJkvzKet5dnIFL\nh5tGdODXbUWE+LgxsXsE367NJTnch14x/s3b/ri5gBHJIfh5mA845urMcnLK69mWX8W9Y5MJ93Nv\ntc7WfCu6DnFBnvi4t94e4Octhdw5fR26Do2uvTYCb4uJS99bwdJ/noGHpSVBm9OlM3NtLlU2B/3j\nA1mbVUGvWH/6xAZgb3SRuqOYwiobFbUOBnUI5Jkft7M5z4qfh5nz317OdUMTOK9XJP/8dhP5lfVU\nNzQS6edBZZ2Dqf+3kuk3DqJLpC+6rqNpWvM+H561mbJaOwARfu68NbVPK8G4L8VVNtZlV3D3jA00\nNLqI8HOnqt7B4A5B9AqpP6Lr2V7R9t7Ix+0AmjYC+K+u6/2aPr8BrNB1/fOmzx8A83Rd//Yg294E\n3AQQFhbWd8aMGce1rUdLTU0N3t5/b9RC8dc4JrbXXRid9TiNnn+eKETX8ajPo94z+rC7i8r9AV0z\nkR85nvjM6cRlfUNR2AjSOt9FTM4c3G1FROXPIy/ybLxrMvGr2t68bXlALzb1eBI0DYPThtFpx2Hx\n/fODHSFmeyVJu97D4LKzteuD6IYDX9pHi7rv2w5l+7ZF2b/tULY/tui6TmWDToC74bDr/l3b7yh3\nsrnUyeREM6Yj8KgcDS5dZ0luI5lVLnqFGOkVeuSDhA2NOla7ToiHhsMFdie4AIsB/rPaRmWDjr+b\nRmaVCz+LRkd/A/m1LoyaRk61q3k/ZgMEe2gU1Oqc29GMrkOVXadLoJE/Chopt+lc2snCHquTigad\ncE8D36XbqWtK1mwxgNkId/V2J7/GxfQddkI9NBL9jaRXOHDoBspsOi4dmnQVGpAUYGBnhQsvMwS4\nadhdEOKhsbXMRUqggVBPA4W1Li5MthDpbeCVtTbSK13N27sZId7PQGGtjlPX8XcztDqvAeFGxsWb\n+S3LQWm9jtkAmVUuAt01eoaYGBppQtPAYoSyep3nV9m4rLOFsXEmDJqGw6Xz+roGNpceGKgX6C73\nQbmttQbxMsN13dzoEmTkmx12FuaIkQLcNLqHGAl01zgzxkyDU47ncOqMjDGzINtBBz8D28tduHSI\n9zVwdoKZWofOvD0OrHadqZ0tuJs0Ev0NBHkYKKp18d6mBjKscs7R3hoDI0zk17oor9e5sosb/lpd\nu3zvnHHGGWv36qpD8bdEnqZp84GDTJDhUV3Xv29a520gXdf1l5s+vwn8sZ/I+0nX9ZmHOla/fv30\nNWvW/OW2Hg9SU1MZNWpUWzfjtOSY2P7zCyB9PoQ0pd+P7N36+5pimDEVclfBJV/IPC+TmyREyVwC\nnc+V8Mr6Clj8H8noCFJce88GS+SrAAAgAElEQVRiyf5Ylg5D7mzx3nW/SMIR89fDL49IUpW0n+Cm\nVAjv9vfO5wSh7vu2Q9m+bVH2bzuU7f8e2WV1fLhsD0MTg/nw9z3UO5xsyKnknSv6Mr7bwbpxLcz9\ndRFDhw4lwMtyyPUcThdLdpbgZjIypGMQBoOGtc7B6P8uprSmgTEpofz3kl747uchOtwcq+0FVXyz\nJpd7xibh42Yiu7yOHYXVVNTZ+WJlNptyrXhZjNQ5nDw4vjNjUsLQdZ1HZ29hUEIgDU4XX63O4bkp\n3RmTEsZnK7KYviqb0poGKuschPi4UVLdgKaByaAR6uNOgbWeoYnBOJwuekb7k1FSS3pxNdEBnuRb\n67mobwxRAR7EBXrSKdwHo0Hjls/WsiCtGKNBw8tipMrWiNGgEerjRoHVBoC72YDN4SIx1Jsnzu1C\nj2h/quodXPnBSjLLZD79gPhArPUOdhRV42uBukaNL24YiJvZyNqsCrpH+fHQrE2U1di5Zkg8Hy7b\nQ5CXhfhgL1J3lNAlwpdtBVV4WYx4upkoq2lA0zRcus6/zulCUqg3cUGePDlnK1nldfSPC8Ro1Egr\nqCIlwpee0f6kFVbz4bI9APi4m+ge5Ye90YXZaOC587uTEOzV6hrpus6Ut5azIaeS+CBP7jgziR82\n5rN4ZwnPTO7GmJQwFu0oplO4D1vyrKzLqqDa1sjF/WPoFeOPtd7Byj3lnNsjAn9PS/M+31yUTl6l\njYfGd8bPs/V9k1lay7Ufr2ZPaS3JYd6kF9cwuXcU3SL9uGxAbLNHsbjaxkXv/EFWk30BOgR7kW+t\nx81k5LZRHYkO8GRYUvAB3s/2+t7RNO34i7wjaIQJyAP66rqe27TsYQBd159v+vwL8KSu64cM11Qi\nT7EvqampjIoFgpPB90/CIwq3SFbHwbdJaOC+5KyGD8ZIko/sPySs8tZl4tEr2CTZHb+9Fqx5UjPO\nK1TE3KiHJHNl5lKpxeYZCGiS2bLP1WDNleyQ/W+AoXfDW4OhKlfmmk16Q7JEmvb5R6nrUFvy54Wn\n2yHqvm87lO3bFmX/v87ecKq/SlvY3unSm0P0jgR7o4sPft9DQrAXZ3YOxWI6uJfM4XRhrXcQ7O0G\nwOcrsnC6dK4eEo/NIYJn33A9e6OL7QVVdIvyo9Hlkk5tqA+aBtUNjRRU2sgpr2NMlwNrln6/IY+s\nsjreWZxBnV08KhajgXA/d7LL6xgQH8iLF/Yg3Ne9VZjd7pIaSqob2FZQxbM/bsNgMHD5gFhGdgph\nfVYF9Q4nY1LCGNghiHq7k/8t3MWiHSVsL6gCoGeMPwMTAskoriF1ZwnXDonno+WZAHiYjXi7icfN\n1ujEWu+ga6QvFqOBoqoGzu4Wzn1nJdPgcPHq/J3MWpdHdUMjfeMC0IA1WRXN7Qz2duPxc7swNiWM\nO6evY/724ubvLEYDdqcLTZP1amyNuJsNVNQ56BsXQHSAB9EBHqQVVNM1yg+TQaO81k5uRT0X9o0+\nrPjdH6dLJ6Okhkh/DzzMRjbkVOLjbiI20JOPlmUS5G3h/N5RZJTUEhvo2cre1TYHX63OwWIycHG/\nGIwGjYJKG2kbVpLSeyAxgZ6tjlVnb8SgabibjZTX2vFyM+JmMlJgrSfMx531ORV0Cvel3u7ksz8y\ncekwvlv4n85hOxibc63sLKpmeFIwob7uh12/pLqBuZvy+Xh5JllldbibDTx6TheuHBR3xMc8WnRd\np8BqI9zXHbvThbvZeND1iqttpBfX4ONmZnVmOQvTign2tvCP8Z2J8vc46DbQft/57UXkjQce1nV9\n5D7LugJfIvPwIoEFQNLhEq8okadoxuUi6+MbiMueKXXarv9NxFhIJ3Brcqtnr4RPzhWBFpAA1/3S\nUrRb1+GzKeJNu3crbP0O5twBV8+VYtefTZb13P1g6rdSYmDxC5L9sa5Uvht4q3jxirdLNsvxz0uS\nkv0py4DZt8Kw+6DT+ONvmxOAuu/bDmX7tkXZ/6/x0+YCHv9+Cy9d1JNRnY5uQGtZeinF1TYspbs4\nZ+wZB3xfWWdvHvnfF5dLb+70ffj7HnYWVePjbiIuyIvLB8RS73DyzI/bObdnBEM6BrfadntBFf/4\ndiOZpXXMvn0IiaEH1sR0OF38+4dtLNlVQr+4QAYmBDJzXS4r95QD4v3wdjPx5tQ+dA734Z3UDGau\ny+OiftEs2VnC1qY5Uf4eZv41ewuaBrNvH8pNn64l2NvC+1f1I9RXPEpT3lxOYZWNMzuHsi67gso6\nB53Dfega6cfMdblomvxbu/2MjozqFEpsoCdfr86hoMrGlyuzAegS4cu/zknhwVmbuHVkIpcPjOXt\n1Axe/DkNEA/ThG4RZJTUEB/sxc9bCnE4XRgNGp38DXRNiGTmulwam4SvyaDR0OhiVKcQTAaNBWnF\ndArz4ZaRHamzO/l4+R4yS+uwO108eW4XrhmawMacSn7dVki93UVFnR0N8HQz4mUxMW9LIX4eZsJ8\n3VmQVkTncF/sjU5yyusZ2SmEXjH+vJOaQZC3hakD4xiQEEigl4UwX/dWYnptVgW5FXUUWm2MTgml\n3u4i1NcNh9PFw7M2E+LjxqSekYxMDjmu2RmPFSfjO8fhdLGrqIZQX7fmgYyTlfZq//Yi8j5G5t+9\ns9/yR4HrgEbgHl3X5x1uX0rknQbounjIsleIcIofBh3OlFT2+/L9HVJuoMtk2PWbJC+pKRQxN+Ud\nqeeWNlfCKs95Gb69TlLw95oKva+QLJI/PwRnT4OBN4GjHl7pJrXX7DXgFQydJkhWxrAukt1yxVsi\n7ErSJElK7yv/esHvkxx137cdyvZtS3u3v67rZJfXERfkhculU1RtI8LvwFFqXddZnlGGn4f5iEb2\nrXUOft1WyHm9og7wTum6TmWdAz8PMwVVNixGAyE+0rErtNqYsTqbV+fvAqBDiBc9o/0ZkRzMpJ5R\nzFyby5JdJTx3fvcDQvgACqz1jJyWir3RRbCHxle3jaBjiAzk1dudPPPjNr5Ymc1n1w/Ax93M8z9t\np1eMP9cMjefR77awcncZF/eP4dM/spq9ck6XzoCEQBxOF+uzK/HzMNM/PoCEYC++35DPOT0i+Glz\nAboODY0ukkK9+frmwa08a+uzK3jx5zRW7C5nRHIIy9NLaXTpBHia+ce4zkT4ufPrtkIWbC9G08Ba\n78DmcJEc5s3OohosRgMdQrxIK6wGwNvNRL3Didmo4dIlZDA+yIsPr+nPUz9sZUFaMWd1CWPupgK6\nRflyYZ9o3liUTmmNnbFdwugS4cv2gip+3VbUyn6aBp3DfXl7ah+iAjwwGw2tPKrVNgdvpWYQG+jJ\nDxvzWZ5RRkqEL2U1DQzuGMSGnEpKqht4boiFyePPpNBqI6+yjg7B3nhYjHyyPJN3FmdQUefg7tFJ\n3Ds2udXxcyskrHJ0yoEexkOxMK2IR2ZtwdNi5OnJ3RiaGHz4jU5R2vs751Snvdq/XYi8Y4kSee0Y\nXZfsjaZ9RmyWvgxrP4Guk2Hsv6G2VEIZw7tLHbaDseh58ZgBGEziVQvtIuUCovuBX7R41T4/n+yY\n84m97kPIWABfXgoJw6FoK9Ts80/u3Ncka+P2H+CXR6EyS0IsdSckjZPC2XsFZN5amH4Z+MfB5Lek\nJIHioKj7vu1Qtm9b2pP97Y0u7py+DjeTvE9vGJ7A6wt2MX97Mf+5oAfzthSwaEcJozqFMO3Cns3C\n68Wf0/h8RRbVtkbcTAZeuKA7wxJDuPHTNfSK8WdUpxD6x0t9SIvJgMPp4rqPV7Nidzl9Yv3pGulH\n/4RATAaN8V3DufHTNSxIK8agtSSFOKd7BMlhPryxaBcOp87EHuIte+S7zVhMBuyNLvw9zVTWOQAY\nlhjM21f04eVfdzJrXS6dwn0Y3DGY7QVVpO4o5r8X9+KRb9cTFeRDQ6OrOdyx2tbYvL3D6WJznpWG\nRhfOpoYMTAhk5Z5yfN1NzLtnBAGeZuZuKuDpH7bhZjZw/bAO/N/S3RgNGsXVDUT6uZNvtREd4MH/\nXd2PrXlV3P/NRv59XleuGhyPyyVzhF6Zv5NALwv3n9WJywbEUmCtp8HhIjbQs5UY/HVrITd/vpZz\nukdw5aA4BnYIorwp45+fh5kCaz055fX4uJtYll7K6sxyLu0fi8EA13+yhr3ds3vHJHP7GR2Zv72Y\nEcnBeFpM5JTXkbqjmMsGxGJqEm+5FfVsybNSXN1A37gAQnzc8LQYD5olcX+cLp0Caz3RAS1hgcXV\nNqx1DvK2r/3T+97p0imulnC5k8EzdrLRnt45pyPt1f5K5J0A2uvFP+Esngapz0kdtYs/ldptH5wF\nfjFgzZai2XuWirhKmQQXfCB14Oy1YM2BwXeKAPtwnNSOm/iqiLy0ufDbEzKnzeItCUt+ewxcThZ3\nn8bIM5sKXteWypy6ku1SR27gzVJQPOms1l7AvHVSDNwzEAbcfGCqfmfjsUvffwqj7vu242S2faPT\nhUHTjqheUXuk0enisc8WkGHzRkf+b57TPYKrBscDHNF51dudLNpRTFGVjZnrcukdI/OCzusVdUAq\nc2udg4zSGhJDvZu9XOuzK/D1MNMxxJvPVmTx2OwtBHlZROxoIvyCvd0orWnAZNC4qF8M363PxdvN\nzNDEIKptjSxMK+aMTiGMTgnj6zU5bMq1YjRoaLSkRI8L8iS3oh5d17GYJFHE+b2j+GN3GRV1dmwO\nyUbXOdyHtMJqrhgUS4CnhUAvC6U1DbyzeDdOl85ZXcK4Z0wyKRE+6Dos3llC/4RAfttWyI+bChnX\nNQxdh4dmbSLcVwRW//gAnC6d9TmVgAicu0Yn8ewXv/H+ZjuBXhaGJQbj5WZkcq8o1mRVMO2XHQA8\nPrELQxKDSN1RQtdIX4YnhZBWWNXU1pZsxQ6nCw0wGeX/g67rbM6zkhLhi7XeQZCXBU3T0HWdqz9a\nzdrMchbcP4p/zd7C/O1FTO4VyTNTujfPKzsU1TbHEYms/VmdWc7mXCudI3wY3CGoTQXUyfzeOdlR\ntm9b2qv9lcg7AbTXi3/ccNhg2WtSG81TRnop3ALvjYSwblCwQTJLFm4CsxfcslTmxVXlQ++p4HTA\nynfANwqq8lr2GzdUPusuuGUZuO9TOsBeK/XTfnwAirfKsqu+JzWb08v27YjT7r5vR5ystm9odHLx\nuyuotzfyv8v60Cn8wDlO+/PbtiLeWLiLly/u9bcL7JbVNJBZVkefWP/mzvvRdJpzyut4KzWd6aty\n6Bbli7ebiZqGRrbkVZEY6k2NrZEf7xqGSwdrvf2AOVyPf7+FvIp61mRVYK0X71VCsBfZ5XU4XTru\nZgOvXtKL3aW1TOgWQVphNfd9vYE6u5NwX3d+uns4Hy/P5PUFu/AwG/nPhT14eu42YgM9+eaWwcxa\nl8f932zkikGxjEgK4Y4v1/Pihd2Z0juaLXlWpv2yg51F1VhMBqIDPPjomgFYTAacLp1ftxayZFcJ\nY1LCCPN1Z2u+lce+38qYlFASQ7yx1juY1CuKvnGSvKq81s7ukhpWZZbz/fp8+icE8PR53VrZM6dc\nstjtnyziz1i1p5zHZm+h1t7Iz/eMwNvNRH5lPQZNaxa/CxctYjsxjEgKoXt0S4ipzeHkg9/3UFRl\n4+GzU1olszgWrM0q54K3/yDY243KOjv/OieFq4fEn1Zeq5P1vXMqoGzftrRX+yuRdwJorxf/uLH+\nc/j+duh3vSQ46X0lzLxeRNztq2DtR7D0FQl1vPADCOwAjQ2AJhklnQ6ZT1dfAX2uhOgBsHMe/HC3\niMIrZ7Uu7r0vDTVSCNwrBIbdc/rZvh2hbN92tCfbL9lZwivzd3LvmGRGJIcA8PuuUt5bupue0X7c\nMyaZuZvy+XlLIeW1dlbuKW8WR/3jA/B2M3F+n+gDigc3NDqZsSqHl37ZQXVDIxF+7jw5qSs7C6u5\ndVTHZu8LiGfs/aW7+WlzAZqmMbpzKDeN7ICvu5kdhdW8/OsOCqw2tjQV+H3grGS25leRuqOEST0j\neeq8rs3Z2JZnlOJmMtA3LpDFO0tw6TqDOwTxwDcbmbupAIDx8SbeuWUcIN6fJ+ds5ctV2bh0OKNT\nKFvzrZTV2hmYEMjGnErGdQ3n4v4xXPTOH4T7utM3LoCpA2MJ83MnPsirOUTu0vdWNKdYt5gMBHia\n8fMwc/OIjjw8azOdwn3YnGdlUs9IMkpq2JpfhabBrFuH0Ds2AF3XJZwyzh83kxGbw/mnWeaOhL+7\n/V9B13UaXTrmfa7vvrTVva/rOiOnpZJdXsf9Y5O5c/TpF8rfnt47pxvK9m1Le7X/kYo8FZumaE3J\nTkl6EtFTZm3vWSpZK71DZY4dwJoP5Pey1+T3RR+LZ2/4/fKzL/vO0zOa4fx3W3/f9xqIGQT+MWBp\nXXelFW7eMO7Zv3NmCoXiGLE2q5xrPlqFpmnc8MkaLugbRVyQF/9bsAt3s5ElO0vIKKlhwfZi3EwG\nArwsPHx2Z6b0iWLOhnzeX7qbyjoHK3aXs2J3GVEBHmSX1WE2GiitaWDelkI6hflw79hk7pqxnps/\nWwtAWmE1/7mwB15uMofpn99uIq+ynsEdgjAaNN5MTWdZRilTekfx3E/b8bSY6Bzuw92jk1ibVcFL\nv+7EZNAY2yWMr9bkkG+t55nJ3Zj2yw7mbipA02BK7yhmr8/DpUNsoCfZ5XXcPKIDE7pHUJ6+vtkG\nmqbx5KSuPHh2Z95YmM5bqRlN2f7cWLWnnJHJIXyzNpffthfh52Fm4QMj8bS0/pdrNGjEBXnx8sU9\nef6nNO4encQ/Z26iqKqBxyZ2YWKPSFxN9b7Cfd157vzu2BxOrvxgFaM7h9I7NqC5LYM7BjXv9+8K\ntBMt8EDOwWxsf94xTdO4ekg801dlc/3whLZujkKhUBwxSuQpJHHK5m+grgyWTJPffa+FqD4w506Z\nWzf6CSkKHjsEspdLHTivEIjqK0XC/w6hnY/NeSgUpziFtS7+t2AXN47ocEBH/GhCEBemFfHa/F00\nNLp4dko3+sYF4nLpPD9vOzuLanj54p6tUl+/v2Q37hYjvu4mkkJ9eHjWZiL8PPjq5kG8On8Xs9fn\nU+9wkhLhy4fX9OPjZZm8u2Q34b7u/HDnsOakHwA3DO/ADcM7UGCtZ+LrvzN7fR61did+HmYanS5q\n7U5uP6Mj/xgn74Xnp3Tnq9U5DOwQyBuL0lmYVszI5BB+Ty8l1NeNr24axMAOInB+3lLArV+sY312\nJQMTAvnfZb2b6zvVNDSyKK2YvnEBRPp78PWaHB6cuYmR01KxGA3cMyaJoqoGpq/KJibQg/N6RvHG\nonT6xgXw0Nmd0TSN1IzW9tU0DU+LiX+O78zVQ+LxdTdjczipdziJ8HPn9QXpzN9exMX9Yw4QePsy\npGMwP9w5DIBXTb34YWM+47tKja6L+sU0Zxf0dpO0/D/dNey0Chdsa64flsD1w5TAUygUJxdK5J3O\nNNphxZuweSYUbZZlmgG6TpHQy7UfiagrSYNZTaLu8q8gZyV0OEMlKVGc1NgcTmaty+Oc7hH4ebYk\nRjjaAsiHI6OkhpzyOkYkhVBYZUNHajnlVdSzo7CK0ho7t43qyJD90oTrus6sdXksSCviofEpBPtY\neG2djYLanazcU86H1/THYjKQX1nPXdPFw9Ql0pdALwtJoT50jfQlPri1dzy9uIZ/fLuR9dmVdAzx\nwu50cfn7K3lyUlc+XpbJjqJqTAaN899azr/OSaF/fCD51nqe/Wl7q/2YDBofXNOf6ABPXrqoJy+c\n353KfYo7PzwhhdvPTMRiNPypVyjCz4OVj4zGaNAoq7UT4GlpTms/ICGweb0L+kZzQd9oAEYmhzBz\nXR4zVmdjMRr48Or+rc5xfLcIFt4/iqp6B92i/FpdR283U6vQ0Iv7xeDjZmJDbiVTB8QRGyTzx87r\nFUmknwcxgR5E+LszPPHI6mmFNYlJD4uRgKZld49J4u4xRxfeNyI5pDn8dS+R+xXrVQJPoVAoFIdD\n9dJPZ+bcCZtmQOxgGPu01Itz94N+10ptOP9YmDBNShN8eTGMeUqSovxdz51C0cbYG13c+vlaFu0o\nYea6XD64uh++7mae+XE732/IY+atQw4QSEdLgbWeR2ZtZtGOEkBSplvrHc2Fi0EKEPt7WLhrxgaG\nJwVzdrdwzmry4ExflcMj321G02B7QTVmo0Zhrc41Q+L5eHkmj363mUm9Irl7xgYaHE5sjS7WZFU0\nHz85zJsofw8q6hy4mw0EebvxR0YZBg0enZDClYPjsNY7GP3yYh6etZmEYC9euqgnHUO8uOGTNdz0\n2Vqi/D1IDvPG283E/y7rjZebiR835XN29wgGdWgJDzQZDQcUvT1Y3bP92Tu/bu+2RoOxVdjh/vSL\nD6RffCDju4Xj0vWDXqOEo7huZ3eP4OzuEa2W7XteUwfGHfG+FAqFQqFoTyiRd7pQUwLeIdBQDcVp\nUrJg0wwY/gCMfuzA9a+e0/J3dD94IP3AouQKRTuiqMpGenENu0trya2o45oh8QcUgq62OXjgm40U\nWG1syrVycb9oZq7LY9RLqYR4u7GruAajQePO6eu5/YxExnUN+0teE13XeeAb8ZjdMyaJEB83Vu8p\np0e0P5V1dnTggj7ReLoZySmv44K3/+C79Xks2VlCkLeFFbvLeWtROkMTg7h1ZCIPztyEQTNwb183\n7prUFV8PM68v2MU3a3NJCvXmnSv7UtiUuKO0poG0wmreTs0gs6yOAfGBNDQ62ZxrpXuUH49NTGnO\n/uhuNvLYxBQ+/D2Tj67t3+wx+u2+kSzZWcJ9X28gr7KeB8d35ozOoQCtvGxtxcj9PF0KhUKhUCha\no0Te6cDGr+C7m6DfdZA+HyqzZXlkHxj5zyPbhxJ4ihOIy6VjMGhkl9UR4GX+0zpT1noHqTuKAXjq\nh23NhYY1DeZuLOC3+0ag67Auu4L4IC+enLOV1J0l+LqbeOLcLlw7NIFrhiTwVmo6eZX1vHxRTywm\nA4/M2swtn69laGIQF/WNYXRKKGajAaNB49bP1xIT6MmE7hGsyChjaXopI5NDuHlEB2aty+O9pbvp\nFunLsvQynp7cjSsHiTfoz7xCoT7uPDWpK/ZGF8/+tJ0L3v4DgKGJQUy7sCeR/h4se+hMQDJ9Adw3\nNpnYQE+25Vdx/1nJeLmZ6BjSUmZgkq43ZYoMYHjSoQXRJf1juaR/bKtlgV4WJveOwmjQMBsNjO8W\nfsh9KBQKhUKhaF8okXeqsDf+a1+vg65DbYkUEDdaYM2HEJwME16S5CpD7mqd/VKhOM7ous7W/CpK\nahroGe2Pr7sJk9GAruu8lZpBRa2d3rEBPPfTdjqEeLFidxkmg4FRnULYXlDFo+d0wWIyMLRjECaj\ngafnbuPbtbkAdArz4Ylzu+BlMeHjbuKS91bw7x+2sWJ3GZlldc1tePq8rlzZVMAaZB7bG5f3adXO\nCd0j+GjZHt5fupt7vtqAxWTAoIHZYKC6oRGAj5ZlAlI4etovO/hoWSalNQ34uJtIL65hSu8opg5o\nLZ7+jKuHSHu6RvpSZXPQI9r/gHlY+3Nh32joe/DvNE3jnjHJR3TsQ7F/eQOFQqFQKBQnB0rkney4\nnFCWDl9fBZ0ntoReZq+AGVMlPFPT4Oq54LTL/DuVMEXxN9lVVM2iHcXEBnoyrms4mqaRXlxDVlkt\nAxICD+p5sze6eGjWJmaty2telhTqzRPnduWjZXtYkFYs89V+34Ofh5mlu0qJDvBgaMdgft1WiEuH\nGz+VWpnn9YpEA77fmM9FfaM5r1cUgzsGtUq0ce3QeD5alommwbQLe7AsvZShicFc1C/msOdnNGjc\nMLwD1w1NYH1OBfM2F9LQ6GJhWjEDEgLpExeAr4eZST0i8fM089PmAl6bv4ubR3Rg6qBY/sgoY2Ry\nCIajTOCyf/IVhUKhUCgUir+C6u2f7HxxEWQskL8rsmDgLbDuE/j9VfAKhq6TpRxCeLe2bafipMFa\n7+CXrYVM7hWFxWRgc66Vx+dsod4uKfLnb6ml+uclzetf0CeaYB8L7y3Zja7Dpf1jGN8tnPTiGr7f\nkE+dvRFN0yivtVNea+f2MzoyqEMQ67IqeWX+Tq74YCVBXhbuHp3E5QNjya2oo1O4L0t2ltA10pe4\nIC9epAfb8qu47Yu1BHm78f2GfAI8zfSM9ueRCSkEeFkOOI9/ndMFDY2oAA8u6hdzROJufwwGjb5x\ngfSNk3loT7rEY75/9s0J3SOYsE8Cj9EpYUd9LIVCoVAoFIpjhRJ5JzN15bB7kXjwel4GX02Fd4ZC\nTREkj5fMmP5HFi6mOL0prrZxz4wNnNk5lK/X5LCzqIYiq40L+0Vz82drcOo6ug7frc9jUISRkT2T\nmNI7ii9XZfP6gl0AXDYglnp7I1+tyWHG6hwAukX50jncFx0dd7ORyb2imtPDD08KoaLOzrL0Ur64\nYWBzPbO9qegn7Jf1sEukL6n/OAObw8lv24oYnRJ6yNpjRoPG4+d2OaZ2OpalFRQKhUKhUCiOF0rk\nnaxsnQ2r/w90Fwy9G2IGwLmvweoPYPAdMPSutm6hoh2zNquCMF83ogOkNtjTc7ezPKOM5RllBHia\n6RsXwCvzd/LK/J2YDAa+vXUw4b7u5FbWU7V7I6NGdQQkAUjHEC8CvSwMTwphT2ktczcVcEZKKI9P\n7EJ0gMchs1M+0STCjiaDpbvZqOaKKRQKhUKhUBwCJfJONnb+AtvmSPkDlySAILIpaUTfa+RHodgH\nh9OFw+lq9nqVVDdw2XsrCPK28N1tQ/lyVTY/bMznjjMSSQrzZkRSCI0unbdTM/DzMDO5dyRxQVJ7\nLNTXndTdrfd/Xq+o5r8Tgr1Y9MAowv3cMRsPn5FVFXVWKBQKhUKhOPYokdeeKd0lc+vG/hu8gqDR\nDj/cDdUF4BcLKRPBJ1wlUjlN+GJlFglBXgxJDKa2oREvt0Nf99yKOjbmWPng993kVNTzxQ0Dqap3\n8PmKLBwuF5V1DkZOWwgKCI0AACAASURBVERDo4uL+kZz79jkVuGIfzXUMSbQ8y9tp1AoFAqFQqE4\nNih10J5Z9BxsnQXF2yBmIBRsFIF3yRfQYRS4eR9uD4qTHF3XeeqHbbh0nU//yELTYHTnUFJ3lHBJ\n/xiemtSVtVkV9IkLOMBz9uScrczfLjXkfN1NnPVKS7KU8V3DuWdsEs//lMbwpGCuH5agvGoKhUKh\nUCgUpwhK5LUXdB22zYbEMVCyA9Z/DtvnQHR/KMsQoReUCL2ugM7ntK6Hp/jb6LqOtd6Bm8mItd5B\nqI9bc/p7XdfZkFNJj2j/AxJvZJbW8nZqBv6eZnIq6sivtDHtwh4EelnYVVxDvcPJxpxKJveKIj7Y\nq3m7Ams9H/6+h0k9o+ge7XfQNr0wL43f00vYklcFgI+7ifN7RzF9dQ4dQ7z5YmU2q/aUs6u4hqGJ\nQTw4vjNB3m4s3F7ExB6RLN5ZQscQLx44qxM9Y/yZtS4XPw8zQxKDifL3wN1s5JPrBhwniyoUCoVC\noVAo2gol8toLmUvhm2sgsjfkrwezF3iHwYUfSoZMXVfC7jjxzZocXp2/i7zK+uZlD5yVzB1nJgHw\n4+YC7vhyPQnBXvh7muka6cvozmF0i/Lj8vdXUFTdgLMptb7FaGDym8tw6jo2h6t5fwvTirlpRAfO\n7ByKxWjgrunrWZ1ZwYfLMvn2lsEEe7vhZjYQ6uOOzeGkuKqBdxZnADAmJQyDBiM7hTB1YByPnJOC\nxWjghZ/TeHfxboYmBrE2q4JJbywjyMtCWa2dz1Zk4XDqvHxxL3rF+AM0n49CoVAoFAqF4tRGibz2\nwsav5Hf+eojqC1d9D24+Ld8rgXdM0XWddxbvZku+lR83FdAn1p9rh8ZjczhJ3VHCu0t24+VmYkrv\nKL7fkA9IVkezwcDs9fl8viKbuCBPyuvszLx1CP/8diN1didf3DCQ+77eSKCXhasHx/8/e/cdHld5\npn/8e6ZrNKPeiyW5yR13GxuIjQkEwqZAsiEkuySQACH5pbBppG1CCqmbJZvCQhKyJLQlkIUQejHG\nptm44iLLTbJ6L6ORpp3z+2PswcI2GI/kEdb9ua5c08458+hIV+I77/s+L26njT1tAW54YBufu2sT\nK6vzGYzEWH+gm++9bya/fnYPH/nvlwjH4oHw3TMK6RuM8PL+LgD+8fmzmFGcMWwqpdthB+Dr75nG\n+88opbrIz0A4yk2P7ORvmxq5cFYRT+5o5f1zSzjjOKOEIiIiInL6UsgbCwY6YMeDMOMDkDcVFlwx\nPODJiLIsi189vefQ9gAGCyuyufPTSxLhaUV1Af/067V87+87eLamnZf2dnLVWVV8++J4I5JQNMaH\nb3mRrQ29/Oby+cwtz+L+zywjHDXJ9bm5/zPLhn3fwopsctJdbKrv4Zbn9uJzO/jZh+bw4YXlFPjd\n/PTxGj62ZALdwTC/eXZv4ry55VnMLDl+SDMMgxklGQBkeJzcdMkcvvu+mbgddiIx84S6W4qIiIjI\n6UchL9VME+6/CmJhOOcrUDQr1RWdVmKmxWAkxt62AOv2dvDxpRX86qlafr92P5fMK+WHH5yNw24M\nC0SzSjN58kvn8PDWZv7zqVo8ThsfXliW+NztsPOnTy6mtrWfJRNzAfB7nMetwTAMLphZxPkzCllR\nnc/MkozE8RfOLubCIzb99rmd7Gju42cfmpOYAvp2HA6qCngiIiIi45dCXqptvQf2rYaL/1MB7whP\n7WjlnvX1XPuuSSyszDnq80DY4rsPbeeM8kw+MLf0qM6QoWiMXz5Zy/+8cIBQNIbdZhCJWdy6Zh89\nwQj/srSCG98/87gdJScX+Pl/5/qYVpTB/IosCvyeYZ/npLsSAe9EGYbB0rc45zOHNhkXERERETlZ\nCnmpZMbg6RuhdCHMvyLV1YwZgVCUG/62jfb+EGv3dPDSDato6RsizWnHsuD2dfu5b32QYPQAAH9c\ne4Dvvm8GCypeD4Pff3gHf3mpnvfPLaEkK42eYJiL55Twm2f3MBCK8s33Tn/LLQPsNoP3zCoazR9V\nRERERGTEKeSlUuv2+L53530PbJpeB7DhQBfX/PlVOgfC/PiS2Xz9gW3MvfFJAPL9bmwGdAcjzM+3\n860PncnG+m5uXbOPT96+nt9fsYi/vFSH3+PgzpfrufqciXzjounDrr98cl4qfiwRERERkVNGIS+V\n6l6IP1YuT20dKRAzLfa0BZiYn47dMHhiRwuvNfbx8v5O7DaDO65czDlT8/nTCwfY1dLPRxdP4O5X\n6gH467VnEjiwlVmlmcwqzWRldQEf+M06PnLri1iHlrH90xklfPn86hT+hCIiIiIiqaGQlwqH97yr\nfwEyJ0Bm2VufcxrpHghzye9eYH/HANOLM8hNd7F2T0fi869cUM05U/MB+MMnFnGwK8jSibmku+wY\nBiyszGH1gdevV57j5T8vm8snb1/PVy+Mn1td6H/L6ZgiIiIiIqcjhbxTLRqGP38AvLmw/zmYemGq\nKxoVlmXxX8/sId3t4MrllextD5Dv8/DQlkbW1HZQ1znAVy6o5v6NDWyq7+bbF88gz+fijhfruGxR\neeI6pVlplGalAfCtQ1sYHMvZU/LZ/O/n43PrT1pERERExjf9i/hUsixY/SOoWxd/7c6E5V9IbU0j\nKBoziZoWMdPi50/UcPu6AzjtBo9vb+GV/V24HTZC0fim3x9dPIHPrpzMZ1dOxrKsxKjb++eWnvT3\nK+CJiIiIiCjknVoPfxFe/ROccTlMPR9yJkLh8Uen3ik21nfzn0/VsrO5j77BCH6Pk45AiPedUcIj\n25p5ZX8XXzxvCmtrOzhrSh7nTM1nRnFG4nxNqxQRERERGTkKeadKy2vxgLf4anjPT96x3TTrOge4\n+o5XMYz4ernSrDR+9I+d7G7t56wpebgddjoHwnxh1WQWVOSwuCoHj9POhxaU8cXzpqa6fBERERGR\n055C3qny3E/i0zNXfuMdG/AAfv7Ebuq6BghHTe5+uZ6FldlsqOvmu/80g08srzrq+I8vrUhBlSIi\nIiIi45dC3qnQuRd2/h3Ovh7SslNdzUnb1tDL37c08dmVk9jR1Mevn92D024wMS+dfz6iWYqIiIiI\niKTOO3dI6Z3kxV+D3QmLr0l1JW9LJGby++f3UdPST0N3kG/93zbyfG6uPmcSn1hehd1msKK6gPuu\nPROvS/9/gYiIiIjIWKB/mY+2gQ7YfBeccRn4C1NdzQnb2tDDjx7ZyUv7usjz7aV3MELUtPjVZfPI\nTHPyrqn51Hz/PTjs+v8JRERERETGEoW80bb+9xAdgjM/l+pKjisaM3HYbQRCUWwG1HcF+fAtL5Lm\nsnPdikn8/vn9LKrM4SeXzqE8x5s4TwFPRERERGTsUcgbTeEgvHIrTH0P5FenupphQtEYHYEwP3l0\nFzub+7hkfhm/erqWkiwPMdMiI83JPz5/FgV+D1eeVUW214Xdpq0ORERERETGOoW80bT1Hgh2wrLP\np7qSYdYf6OIbD2yjti2QeO8nj+1icWUOG+u7cdgN7vzUEgr8HgDyfO5UlSoiIiIiIm+TQt5o2v5/\nkFcNFctSXQnr9nRw58t1tPeHWH+gm3y/my+eNwW3w86ulj52Nvdx+ycXsbWhF6/LzhnlWakuWURE\nREREToJC3mgJ9UPdC3DmdWCkdprjY6+1cO1fXiXP5yIzzcm33judy5dMSHTEtCyLmGnhsNs4c1Ju\nSmsVEREREZHkKOSNln2rwYzAlPNP6ddalsUtz+1jKBLjssXlrNndzk8eq2F2aSb3XXsmHqf9qHMM\nw8Bh13o7EREREZHTgULeaNn3HLh8UL7klH7t6t3t/OSxXQD87rm9hKMmE/PT+eVHzjhmwBMRERER\nkdOLQt5oaVgPpfPjm6CfIo9vb+EXT9RQkunh5o/O42v3b+WKMyv51zMrMFI8ZVRERERERE4NhbzR\nEA5C62uw/Auj/lWWZfHjx3bR2jvE/21uwu928ONL57CoModn/m3FqH+/iIiIiIiMLQp5o6F5C5hR\nKFs06l/1l5fq+O/n9gEwtzyLe69ZituhaZkiIiIiIuOVQt5oaNwQfyxdOCqXX7eng8buQS6ZX8rN\nT9eybFIuP7l0DjnpLgU8EREREZFxTiFvNLTuAF8h+PJH/NK9wQifvWsjPcEIu1v76QiE+cEHKinP\n8Y74d4mIiIiIyDuPLdUFnJbad0L+tBG/rGVZ/OAfO+gdjFCalcbv1+4HYEX1yIdJERERERF5Z9JI\n3kgzTWivgflXjOhl1+3p4MeP7mJbYy+fXTmJK5ZV8ttn9zIpP11bI4iIiIiISIJC3kjrrYdIEApG\nbiSvJxjmC/dswuO08+Xzp3LdisnYbAbffd/MEfsOERERERE5PSjkjbS2+Ebk5E8fsUv+4B876Q5G\neOhzi5lZkjli1xURERERkdOP1uSNtL1Pg90FBSMT8p7b3c5fX23gmnMmKuCJiIiIiMhbUsgbSUN9\nsPkumHkJeDKSvlxr3xBfunczUwp8fH7VlBEoUERERERETnearjmSah6FcAAWfWpELvdfz9QSGIry\nv9ecqeYqIiIiIiJyQjSSN5I6asDmgJJ5SV+qrX+I+zY08MF5pUwu8I1AcSIiIiIiMh4o5I2kzj2Q\nXQn25AZIB8MxPv0/G7AsuOZdE0emNhERERERGRc0XXMkde6F3MlJX+bvW5vY0tDLbz82n4n5GsUT\nEREREZETp5G8kWKa8ZCXMynpSz2zs42iDA8XzioagcJERERERGQ8UcgbKf3NEB2E3ORCXiga4/na\nds6dXoBhGCNUnIiIiIiIjBearjlSOvfEH09iuqZlWdy+7gAdgRAFfjcD4RjnTS8Y4QJFRERERGQ8\nUMgbKd0H4o85VW/71O1Nfdz48I7E66q8dN41VSFPRERERETePk3XHCk9dfHtE/wlb/vU1TVtAHzv\nfTMxDPj8qsnYbZqqKSIiIiIib59G8kZKTz1klJ7U9gmra9qZXZrJFcsqed8ZJWSnu0ahQBERERER\nGQ80kjdSeuoha8LbPm1/xwAb67tZWZ0PoIAnIiIiIiJJ0UjeSOmugynnva1TfvFEDU/uaCXNaefj\nZ1aMUmEiIiIiIjKeKOSNhMgQBFog68SD2o6mPv7rmXhHzm9fPIMCv2e0qhMRERERkXFEIW8k9DbE\nH9/GdM27X6nH5bDxyjdWkeXVFE0RERERERkZWpM3Enrr44+Z5Sd0eDAc5f82NfLe2cUKeCIiIiIi\nMqIU8kZCoD3+6Cs8ocMf3tJMfyjK5UvefqMWERERERGRN6OQNxIGDoW89LwTOvzOV+qZXOBjYUX2\nKBYlIiIiIiLjkULeSAh2gM0Jnsy3PHR7Uy9bDvZw+eIJGIY2PBcRERERkZGlkDcSBtrjo3gnENru\neKEOt8PGJfNLT0FhIiIiIiIy3ijkjYSBjhOaqvnb1Xu4d8NBLltUroYrIiIiIiIyKhTyRsJAB6Tn\nv+Vh921o4MyJuXznn2aegqJERERERGQ8UsgbCQPt4H3zkbxgOMqBzgGWTszFbtNaPBERERERGR0K\neSPhBEbydrcGsCyoLvKfoqJERERERGQ8UshLVjgIkYG3XJNX09IHwPRihTwRERERERk9CnnJCnbE\nH98i5O1s7sfrslOe7T0FRYmIiIiIyHilkJesgUMh7y3W5G062MP04gxsWo8nIiIiIiKjSCEvWaH4\nNMw32wi9IxBia0MP50x56w6cIiIiIiIiyVDIS1Z4IP7o9h33kNU17VgWrJpecIqKEhERERGR8Uoh\nL1mhQPzRdfyQ9+yuNgr8bmaWZJyiokREREREZLxSyEtW+HDISz/mx5GYyZrd7aysLsAwtB5PRERE\nRERG16iFPMMw5hqG8ZJhGJsNw9hgGMbiQ+8bhmH8yjCMPYZhbDUMY/5o1XBKHJ6ueZyRvA0HuukP\nRVk5TVM1RURERERk9I3mSN5Pge9ZljUX+M6h1wAXAlMO/edq4HejWMPoOzyS5zz21ghP72zFaTc4\na8qbd98UEREREREZCaMZ8izg8CK0TKDp0PP3A3dYcS8BWYZhFI9iHaMrPADOdLAdfStjpsVDW5o4\nZ0o+PrcjBcWJiIiIiMh4Y1iWNToXNozpwOOAQTxMLrMsq84wjIeBH1uWtfbQcU8DX7Msa8MxrnE1\n8dE+CgsLF9xzzz2jUuvJCgQCzG+8g9zOV3hx2Z+O+nxbe5RfvBris3PdLCpSyBtJgUAAn+/4zW5k\n9Ojep47ufWrp/qeO7n3q6N6nju59ao3V+79y5cpXLcta+FbHJZU8DMN4Cig6xkffBFYBX7Is637D\nMP4Z+ANwHvHQ90bHTJqWZd0K3AqwcOFCa8WKFcmUO+JWr15NSa4fQtkcq7YH7t5EZlo7n//QStwO\n+6kv8DS2evXqY95zGX2696mje59auv+po3ufOrr3qaN7n1rv9PufVMizLOu8431mGMYdwBcOvbwP\n+P2h5w1A+RGHlvH6VM53nvDAMTtr9g9FeHx7Cx9eWKaAJyIiIiIip8xorslrAt516Pm5QO2h5w8B\n/3qoy+ZSoNeyrOZRrGN0hQPg8h/19qPbWghFTS6ZX5aCokREREREZLwazYVinwZuNgzDAQxxaG0d\n8AhwEbAHCAKfHMUaRl84AN6jO2e+tL+TPJ+beeVZKShKRERERETGq1ELeYcaqyw4xvsW8NnR+t5T\nLjwAWRVHvb29sY/ZpRnaAF1ERERERE6p0ZyuOT6EAuAe3nlnMByjtq2fWaWZKSpKRERERETGK4W8\nZIUHwDU85O1q6cO0UMgTEREREZFTTiEvGZZ1qPHK8O6arzX1AQp5IiIiIiJy6inkJcFmhsGKHTWS\nt72xl2yvk5JMT4oqExERERGR8UohLwn22FD8yRtC3mtNvcwqzVTTFREREREROeUU8pLwesh7fbpm\nOGpS09LPzBJN1RQRERERkVNPIS8Jr4c8b+K93a39RGIWs0ozUlSViIiIiIiMZwp5STCsWPyJzZl4\nb3tTLwCzNJInIiIiIiIpoJCXhNdDnj3x3muNffjdDibkeI9zloiIiIiIyOhRyEuKGX8wjgh5Tb3M\nKMnAZlPTFREREREROfUU8pJgWNahJ/HbGI2Z7Gzu0/54IiIiIiKSMgp5STCsQyN5tvht3NcxwFDE\nVNMVERERERFJGYW8pAyfrrmjqQ9A2yeIiIiIiEjKKOQl4fWRvHjIq+sMAqjpioiIiIiIpIxCXhIS\nIe/QSF5Dd5DCDDcep/1NzhIRERERERk9CnlJeONI3sHuIGXZGsUTEREREZHUUchLyhtH8gYpz05L\nYT0iIiIiIjLeKeQl4fXN0G1EYybNvUMayRMRERERkZRSyEvCkWvymnuHiJkWZRrJExERERGRFFLI\nS8rrm6E3dA8CUK7OmiIiIiIikkIKeUk4svFKa98QAEWZnhRWJCIiIiIi451CXhKOnK7ZNRAGIDfd\nlcKKRERERERkvFPIS8KRI3ldA2HsNoMMjzO1RYmIiIiIyLimkJeUwyN5NrqCYbK9Tmw2I7UliYiI\niIjIuKaQl4QjR/K6B8JkezVVU0REREREUkshLwlHrsnrHAiTrfV4IiIiIiKSYgp5SXh9M/T4SJ6a\nroiIiIiISKop5CXl9ZG87qBG8kREREREJPUU8pJgWPHN0E0MuoMRcrQmT0REREREUkwhLwmH1+T1\nh01ipkWORvJERERERCTFFPKSEg95XYPxtXkKeSIiIiIikmoKeUk4PJLXHYyHPK3JExERERGRVFPI\nS8LhkNczFH/MSnOmshwRERERERGFvGQcDnl94fhIXqZCnoiIiIiIpJhCXlLiIa93KN5l0+9xpLIY\nERERERERhbxkHN4MvW8o/uj3aCRPRERERERSSyEvCYZlgmGnPxQlzWnH5dDtFBERERGR1FIqSYoF\nho2+wYimaoqIiIiIyJigkJcEwzLBZqdvKEKGmq6IiIiIiMgYoJCXhMR0zaEoGRrJExERERGRMUAh\nLwmJkbzBiJquiIiIiIjImKCQlxQzviZvKKrpmiIiIiIiMiYo5CXh8Ehe/1BE0zVFRERERGRMUMhL\ngmGZWIadvkGN5ImIiIiIyNigkJcEw4qBYSccM7WFgoiIiIiIjAkKeUmxMI34LcxQ4xURERERERkD\nFPKSYFgmJgaApmuKiIiIiMiYoJCXhHjIi99CTdcUEREREZGxQCEvKa+HPK/TnuJaREREREREFPKS\ncuRIXppLIU9ERERERFJPIS8JhmUSO9R4JU0jeSIiIiIiMgYo5CXBsExMK34LPQp5IiIiIiIyBijk\nJcUkpumaIiIiIiIyhijkJcGwjgh5GskTEREREZExQCEvCfHpmvF98jRdU0RERERExgKFvKSYRLHh\nctiw24xUFyMiIiIiIqKQlwzDMolZNk3VFBERERGRMUMhLwmGZRK1DIU8EREREREZMxTykmBY8ema\nHqduo4iIiIiIjA1KJ0kxiVmGmq6IiIiIiMiYoZCXBMMyiViG9sgTEREREZExQyEvCfE1eWq8IiIi\nIiIiY4dCXhIMyyRiqvGKiIiIiIiMHQp5STGJWuDRdE0RERERERkjFPKSEB/J03RNEREREREZOxTy\nkpBovKKQJyIiIiIiY4RCXlJMwjF11xQRERERkbFDIS8JhmUS1j55IiIiIiIyhijkJcMyMbHhceo2\nioiIiIjI2KB0kgzLJKZ98kREREREZAxRyEuGZRJDjVdERERERGTsUMhLgmHFMLGp8YqIiIiIiIwZ\nCnnJsCxMbLjsuo0iIiIiIjI2KJ0kwcAkhg27zUh1KSIiIiIiIoBCXlKMQ901bYZCnoiIiIiIjA0K\neUnQSJ6IiIiIiIw1CnlJODySp4E8EREREREZKxTykmA7tIXC6TyS1xRo4srHr+TuXXfz191/pWOw\nA8uy2Nez721f6/fbfs/G1o2jUKWIiIiIiBzmSHUB72SJ6Zqn2VDeEwee4N6ae+kN9dIQaGAgMsD6\nlvUA/G7L77ig8gL+vOPP3PruW1lavJSuoS78Lj8uu+u41zzQe4CbN97MlOwp3P9P92OcZvdMRERE\nRGSsUMg7WZaFgXVouuY7P7CsbVzLYHSQrsEufvDyD6jMqKQyo5JZebP48NQPs7ZxLaX+Un654Zf8\necefAfjN5t/wx9f+yEvNL5HlzuLDUz9M+2A7X174Ze7edTd1fXXEzBhZniwGIgMA1HbX8mTdk5xf\neX4qf1wRERERkdOWQt7JskwAYtY7v/FKIBzg689/nagZxcDgzOIz+c2q3+C0OxPHzMybCcCM3Bn8\nbvPvCMfCPHPwGdx2N9edcR33197PbdtuA+DhvQ8TtaIUpBXgsDnoHOokFAuxsHAh3UPdfGXNV9jW\nsY2h6BCXTLmE6bnTU/Jzi4iIiIicjhTyTpYZiz9g452wF3rEjLCpdRPzCubhtDsZjA7SHGimKL2I\nn67/Kb2h3sSxV8+5eljAO9LEzIn87F0/oynQhNfp5eo5V1OVWcXFEy9mc/tmBqODrG9Zz8emf4y5\nBXMB6A/3s6ZhDbPzZpOblsuPXv4Rf9r+JwD+tudvXD79cj41+1P4nD7q++qpzKwc7dshIiIiInLa\nUsg7WdbrIW8sT9dsGWihwFvAv6/7d/6+7+9UZFRw27tv48vPfZmtHVvJdGfSG+rlY9M/xtrGtRgY\nLChc8JbXLfGVcNPZNyVel2eUU55RDsA/V//zsGP9Lj/vnfjexOsfnvVDrpp9FS6bi19t+hX/s/1/\n+Me+f7C0eCkP7X2ICyov4IbFN7ClfQuVmZVMzJw4QndDREREROT0p5B3sg6N5MUwxmTjlZgZ4/sv\nfZ/7a+9ngn8C9f31XFR1EY/sf4TLH7mc7qFuLp54MZ2DnVw39zrmFsylrq8O4JSE1sPB7afn/JQr\nZlzB5575HA/tfYjq7GoeP/A4zx18jqHYEE6bkzsuvIPJWZPxODxEzAgbWjbQEemgY7CDre1bmV8w\nnyxP1qjXLCIiIiLyTjBqIc8wjDOAWwAfcAD4mGVZfYc+uwG4CogBn7cs6/HRqmPUWIdD3thck/e3\nPX/j/tr7WVG2gpdbXubz8z7Pp2Z/itZgK6+2vsrHp3+cry3+2rBzKjIqUlLrzLyZ3HLeLfx5x5/5\nt4X/xj0193DPrnu4cfmN/OClH/DRf3yUDFcG31zyTf7w2h/Y3b0bl+HiR3/9EREzwvkV5/OLFb9I\nSe0iIiIiImPNaI7k/R74smVZzxmGcSXwFeDbhmHMAC4DZgIlwFOGYUy1rEOp6Z3CPHK6ZopreYPu\noW5+venXzCuYx6/O/RUWFjYjvnDw2jOu5TebfsO1Z1yb4iqHq86p5gdn/QCAz5zxGa6dcy2GYZDp\nyuSFphdY07iGrz3/NTx2Dzcuu5F7N93LtLJp2Awb9+2+j0seugSf08f0nOm80vIKMSvG/IL55Hvz\ncdvdOG1ONrZu5MKJF7JqwiqctmOvORQREREReacbzZBXDaw59PxJ4HHg28D7gXssywoB+w3D2AMs\nBl4cxVpG3uHummNoJC9qRukY7OCG52+gP9zPDYtvwDAMDF6vb2nxUpYWL01hlSfm8JTRZaXLWFa6\njP83//+xoWUDpb5SKjMryW7MZsWyFfSF+1jfsp4MVwaRWIS7dt3F/IL5+F1+njjwBP2R/sQ1/S4/\nzxx8hgJvAedXnI/D5qAovYhLplxCmiNt2Pfv69nH1o6tNAeauXjSxZT7y9+y5pgZ43svfo+mgSaq\nMqrwu/zMzJvJOaXnHLeRDcSb4vSH+8nx5Jzk3RIREREReZ1hWdboXNgwXgB+YlnWg4ZhXA98z7Is\nv2EYvwZesizrL4eO+wPwqGVZfz3GNa4GrgYoLCxccM8994xKrSfDFepm2Yuf4FuRTzL9zPdR6ktt\ni82gGeTnzT+nPdqOHTsfy/0Yi3yLUlrTaAoEAvh8vqPej1gRnMbrgcq0TDqiHTSFm5jtnc2OwR2s\n6V/D3tBeTMskhyUiIQAAIABJREFURowcew6rMldhx05juJF+s5/Nwc2Ja9iw4bP7WOFfQXe0myhR\n/DY/TZEmMuwZDJlDdMe66Yx20hfro8BRQMAMMGgOYmFR4CjgA9kfIGyFaQg3sMS3hKZwEx3RDoJm\nkFcHXmXAHOBf8/6VDFsGEz1ju9HM8e69jD7d+9TS/U8d3fvU0b1PHd371Bqr93/lypWvWpa18K2O\nSyrkGYbxFFB0jI++CdQAvwJygYeIr73LNQzjN8CLbwh5j1iWdf+bfdfChQutDRs2nHStI66vCf5j\nOjdEruKqL9zI5ILU/hF894Xv8rc9f+O6M67j3RXvZmLW2A4KyVq9ejUrVqw46fPNQyOxr7a+yo0v\n3siBvgMApDvTcdvdXFR1ER+p/ghOu5N7a+5lQ8sGtnVsI92Zjg0b/ZF+ynxl9Ef68Tv9+Fw+yv3l\nzC+Yz8dnfByIj9A93/A8//HqfySa2ryR3bCzpHgJe3r20BZsw8Dgk7M+ydz8uZxVelZij8EyXxl2\nm33YuTEzRkuwha7BLvK9+axvWY/b7uaZg89w+bTLmZM/56Tvz5s52Xs/FB1iU9smYlaMmbkzaR5o\n5mD/Qc4uPRuv0wtAOBbm7l13MzFzIvML57OlfQvTc6aT7cnGsqzjNgUKRoIAieucrpL9u5fk6P6n\nju596ujep47ufWqN1ftvGMYJhbykpmtalnXeWxxy/qFipgKHe+g3AEfOfSsDmpKpIyXG0HTNf+z7\nB/fX3s+Vs67kmjOuSWkt7xSH1yguKlrEQx94iLZgG6ZlUuAtOCpMXb/geiKxCDXdNUzNngpAT6iH\nAm/Bm36H0+bk3AnnclbpWTxd/zTF6cX4nD5u3XorF0+6mIWFC3HYHLjsLmq6aniu4TnWNq7lj6/9\nESCxvQXAGflncP2C67llyy1sbt9MmiONvnAfUTN6zJ/tsf2P8ek5nyYUDbGvdx8tAy0sLFrIvIJ5\n5HhyyHRnJn6WU2FT2yY+/8zn6Qn1HPVZujOdbHc2NsNG2AzTMtCCzbDhsrkYig2R68nl/ZPfz301\n97GkeAktAy1U51Szs2snVZlVDIQHWN2wGpfNxbTcaeR58vjm0m/ic/rwODyJ37WIiIjIeDGa3TUL\nLMtqMwzDBnyLeKdNiI/q3WUYxn8Qb7wyBXhltOoYNYcar1gp2kKhMdBI12AXpf5SfvjSD5lfMJ/P\nzfvcKa/jdGAYBoXphW96jNPuZFberMTrtwp4R3LZXVxYdWHi9U/f9dOjjqnOqaY6p5pPzf4UHYMd\n/Hbzb2keaOa8ivPoC/Vx88abueKxK8jx5PCByR8gHAuT5c6i3F+O1+llV9cuFhQuYF/PPi6edDHX\nPXUdt2y5BbthJ92ZzqSsSTxQ+wB37rwz8Z1Z7ixMy8Rhc7CoaBFVmVVMy57GpKxJVGRU0DnUScdg\nB8FIkGxPNrlpufid/hP6mS3LYlfXLgYiA+Sk5fDl1V8mw5XBj876ES67i11du3DanEzKmsTf9/6d\n3nAv4VgYwzC4YfENPHbgMbwOL8tLl/OHbX/gj6/9kcqMSp45+AwT/BO4v/Z+5uTP4ZXmVwhEAlw5\n60p6Q73U9tSytnEtq+5bBUBJeglz8udQ6C3ExGRT6ybOKjuLKVlT8Dg85HpywYCp2VOHNeNpHWjF\nbrOTl5Z3wr9nERERkbFiNBuvfNQwjM8eev4AcDuAZVnbDcP4X2AHEAU++47rrAlgd1HnmUFbOPuU\nd9d8qu4pvrbma4TNMF6Hl1AsxHfO/I46Rp4GbIaNAm8B31323WHvzy2YS+tAK8tLl5PpzjzqvMMh\n8pyycwC47fzb2N29m7kFczEwcNgcmJbJ2sa1RM0o7cF2arprsBt2gtEg6xrX8cSBJ7CIT9/O8eTQ\nNdR1zBpLnCVE66LUdteS581jZu5MHqh9gDRHGtmebJ6ue5pQLERNd03iHL/Tz2/P+y3VOdUALCle\nkvjsyOeHnTvh3MTz8yacR8tAC/nefGyGLT7iFwvjsruwLAvTMoeNvu7q2sULTS9gWRYvNr/Izq6d\nPF3/NAYGFZkV3LLllqO+L9udzYVVF/KF+V/gtm238fttv8dhc3DplEvJ8eTQ0N9AY6CR3lAvHoeH\nyVmTmZg1ka7BLqJWlCcOPIHL7qIio4KqzCry0vK4a+dd5KXlsWrCKubkz2FJ8RJsho2ByABD0SF2\ndO6gIdDAkuIliX0jRUREREbCqIU8y7JuBm4+zmc/BH44Wt99SmQU86fSG3muJ3zKp2v+YdsfKPOX\n8YmZn+CxA48xr2Aek7ImndIa5NRaULjgbR2f6c5kUdHwxjs2w5YIgccSjoXZ1bWLnZ072dC6gVl5\nsyj1lZLmSKMn1EPnYCc9oR7+/Nqf+dLqLw0712VzYVomUSvKlOwppDvSuX7B9VRkVPBax2t8cMoH\nT6hD6bEYhkGxr3j499ldic/sxvDptdNypjEtZxoAV82+CoBILILNsGG32dncthmn3UnUjNI12MVQ\nbIhn6p/hnpp7WNOwhoZAA++d+F5M0+SB2geImBGy3FlMzprMhIwJDEWHWNe0jgf3PojL5iJmxVhc\ntJgsdxb1/fXcv/t+hmJDzM2fC8CvN/8aiP9OstxZtAfbCUaDw2peXrKcUCxEzIrxkeqPJH6+mq6a\nxNrKQDhAT7iHjsEOAuEAlZmVJ3U/RURE5PQ3miN5p73DLWtOZcgLhAPs6NrBp2d/mg9O+SAfnPLB\nU/bdcnpz2V3MyZ/DnPw5fGTaR457XGlXKUXTi5hXMI/d3btpCbYwL38ePpcvMY30yAYpR47KpcqR\nW1jMLZh71OcXVl3IeQfO40+v/YkV5Su4fsH1iXMON6d6Y9OX3lAvXqcXu2Eftu6vZ6iHl1te5twJ\n5+K0OekL97G2YS2vtMSnli4oXEBxejGZ7kzOKTuHh/c+zH2778Pv8mNZFl9//utv+rPc9L83AfHt\nUDoGO8hwZVCYXkhNVw1l/jK+vPDLbG7bTEuwBZ/Tx4LCBUzPmY5hGMTM2FFrTkVEROT0o5CXBPNQ\nyjsV0zUP9h/k15t+zYtNL2Ja5lGjNCKnSq4jl+Wly4GjA1O6Mz0VJY2ICyov4ILKC456/3gdPY81\nbRYgy5M17DoZrgwumngRF0286JjHX3PGNYmGSeFYmD/v+DPVOdX4XX4q/BXs6NyBzxVvIvO3dX8j\nvzKfxv5GXmh6ganZU2kLtrG1fSuVGZVsaNnA+/7vfUd9R2VGZXwEMBJggn8C6c50FhYtpHWglX29\n+yjzlTE1ZyrV2dUMRAaYnDUZj8NDW7CNWXmzyHRn0jLQQqY786g9JY/FsiyiVlRTyEVERFJEIS8J\nh0PeqWi88oOXfsCmtk0MRgeBeLdFETm9uOyuxBTTw5aVLks8X+JbwopZK457fluwjUf2PUK5v5x3\nlb+LnlAPT9U9xTP1z7CwaCHZ7mwO9B2ga6iLO3feSX5aPlOzp9IQaOD5xueJHWN5dI4nh7y0PHZ3\n7ybDlYHH4eG9E9/Leyrfg8Pm4JXmV3h438NMyprEgsIFxKwYd+64k75wHx+a+iEe3f8odsNOlieL\neQXzKE4vJs2RRudgJ22DbVxUdRGz8mYRioXY1bWLzW2bKUwvZGrWVCZkTMBu2Ima0WGjsSIiIvLm\nFPKScHiLwdGerlnTVcMLTS/whflfYE7eHNoH2/E4PKP6nSLyzlPgLeATsz6ReJ2Xlsdl0y7jsmmX\nHXWsaZnDppl2D3XTNNBEhiuDtY1ricQiTM6azK3bbiVmxvjSgi9R01VDb6iX21+7ndtfuz1xbnV2\nNWsa1vDQ3oeAeLfSnlAPv9vyO+bkz6EgrYDOoU7+sO0PieY+EN9m5O6dd+Nz+Y65vYbT5sTn9BGI\nBFhctJgJGRPoGOygJ9TDeRPOoz/cT8SMMCtvFunOdDa3bWYoNsSiokWJbVHOnXAuzYFmarprmJk7\nk4mZE487OjsSIrEIUSt6QiOeIiIio0UhLwnmocfR/AeDZVn8cuMv8Tl9fHjqh487RUxE5O144/6B\n2Z5ssj3ZAHx02kcT7x85knjY9o7ttARbiJgRJvgnMD1nOhYW9X31BKNBpudM54HaB1jXtI6bzr4J\nt90NwMG+g0SsCIPRQXLcOXidXv57638TjoXJTculKrOKBQUL6BzqpLa7ltqeWrqHunHb3Wxp38LG\nto3YDBvZ7mxueuUmDAwMw8C0zERtNsPGrVtvTbz+7gvfHTZC6ba78Tg8VPgrGIgM4Ha48bv89IX6\naAw0srR4KV6nF7fdTW13LcFoEK/Dy9LipbzS/gr3PHUPQ9EhXDYXH6n+CB6Hh2A0SMyMsa93H/ft\nvg+33c2Pz/4xuZ5cnHYn+Wn5WgspIiKnlEJeEsxTMJL3eN3jrGtcx1cXfVUBT0TGhJl5M5nJzGHv\nGRjDOn5eOvVSLp166bBjyjOO7rD61UVfPeq9fG9+okPqkcKxMKZl4ra76RjswO1w47F72Ni2EdM0\nmZE7A5fdxZqGNVRlVjEYHeTR/Y8yLWcaM3JnsL1zO3t79tIT6qEx0EiZp4xQLMS+nn1gwKoJq3iy\n7klsho1QLERFRgUlvhJaB1r57Zbf4rf5qRiqwOPwsL9vP19c/cWj7sHiosVs69jGvzz6L4n35+TN\n4YsLvsjW9q2sPriaWXmzqMqsoinQRPNAM5nuTJYULSFmxegJ9eC0OanKrKIh0ECGKwO/y89LTS8B\nMDFrInPy5pDvzcdu2DEMA8uy2NOzBwuLDFcGme5MNrVuYl/vPs6dcC5RM8qEjAlv/Ys9gmmZ9IZ6\nj2qkJCIi7wwKeUk43HVvtNbk7e/dz3fWfYc5+XOOOd1KRGQ8Oby1BMSD4GFLi5cOO+49Ve9JPD+y\nOdDhfRrfyLTMxKjgt8/8Njbi+zEeGW6aAk3sXL+TVStXATAUHWJj20a8Di9epxeHzUG2Oz4aurdn\nLzu7dhKMBGkLtnHr1lu58vErAZicNZm7d91NzIrhsDko9BbSNdTF3bvuftOf3SBei4VFmiMNy7LI\nTctlQeECdnfvZlfXrmOe95P1P0l8b9SMJrZEyfHkUOYvo2WghbZgG+X+cvrD/WS5syj1l/LEgSfo\nC/fhd/mZnjOd6TnTmZw9mTJfGTNyZ9AT6qHEVwLEO80ahpGYotoUaCIYCeK2u9ndvZvpudPZ072H\nCRkTqO2uZWPbRiZlTaJ5oJnZebPpHurmgsoLGIwOsqNzB06bkyXFS4b9vg+zLIvtndtx2pwYhsHk\nrMn0hfp4qv4pQrEQl0659LjLGQajg9gN+zGvKyJyulHIS8Jod9d8uv5pBqOD/OJdv1CXOhGRUXLk\n1NXj/Xdtia+E3cbuxGuPw8OykqOnsgJMypo0bO/Ss8vOpmeohxm5M8j35tMX7iMYCZKXlofD5mAo\nOsSurl14nV4yXZl0DXXREGhgUtYkekO9DEQGmJI1BbvNTnOgmbt23YXL7qI92M66xnWU+kv5xpJv\nkJeWl9jTcmr2VHI8Obzc/DJRK8qWti34XD5CsRBTsqdwoPcAu7p2UeQtYn7hfGq6asj2ZNMd6mZD\n6wbOKj2LBYULqO+rZ0fnDu7edTdhMwzEu+gORAbI8eQQjAQJm2Fshg2H4SAUCw1bd3ksDsNB1IoO\ne+/7L31/+DGHAnBvqJcJGRMYDAzyx0f/SMdgBwf7D77+e0kvoTvUnWhKdsf2OyjwFtAd6iZmxij1\nl1LuL6d1oJWXml/CbtiZVzCPgegA6Y50fC4fnYOdRK1oIkj7XX6umXMNjYFG2oPteJ1eWoOt7O7a\nTSgWSuz7OSFjAu3BdmJWjG3t2zAxsWFjWu40mgPNhGKhxN9JzIzhc/kSdVuWRdNAE4FwgIqM+Ohw\nzIwxEB0gGAmS68nFbotvzxIxI/o3gIi8bQp5STi8CmS0pmvu6NxBub+covSiUbm+iIiMvjd2Q85w\nZZDhyki89jg8w0YcC9MLmZ47/ZjXykvL46b8m074u4+1L+RbsSzrqCmaETNCc6CZJ+ue5JWWV5hb\nMJfG/kYy3ZmkO9MZjA4SMSP4nD4KvAXkpuUSjAQpSi9ifct6puVMo2uoi4mZE5mZN5P6vnqy3FnU\ndtfidXrZ0LoBv9NPdU41feE+Xm19lbZgG2mONLa2b8WyLJw2J5MyJ3HVrKvwuXz0h/t59uCzFKcX\nc+mUS2kfbOeeXfcQjoWZkTMDDGjsb+TpuqdJd6Zz2bTLMC2TV1pewef00RvupTXYSrYnG5/Dl5id\ns6Nzx7DpthAfSc1NywXgq2uOnmL8ZuyGHdMyOav0LILRIOnOdLZ3bKdzqDNxbbfdzVBsKHGO0+bE\ntEwKvAW0DLSwasIqpuVMo6a7huZAM4uKFxGJRdjUtgkLixsW30AgEiDbnc3MvPhU6u0d28lwZxCO\nhdnXu490Zzqz8maR4cogakap66ujMdBIcXoxHocHp82J3bDTFmyL/z5cft436egtWUTknUEhLwmH\nu2vaRmkob0fnDmbmznzrA0VEREbIsdbgOW1OJmRM4KrZVx21zcdbOda+rlOypwCvT7t9Yxg9p+yc\nYa9Xr17NihUrjrrOh6Z+KPF8OtOPOu9kNAeaeXDvg5xdejZl/jICkQAl6fGpqaFYiLq+Our66mge\naCbbk43dsDMxcyLZnmxCsRAbWzdSmVlJljuL5kAzzzc+z2B0kLWNaylML6Qp0MTy0uXMzptNljuL\n/b374w1+nF7SHel4HB4a+hvAgPq+epYUL+HhfQ/zVP1TlPvLyfHkcPtrt+O2u5mVN4t9PfuGhdKp\n2VPpD/fTPNCMx+4ZNrpqN+wUpRfRHmxPjMy+mdu23oYRNrj5wZupzKikrr+OmBmj0FtIblou9X31\n2Awbs/Nn0znYSV1fHW67m4HIAL3hXnpDvbjsLublz2MoNoTL7sJtd9MebKcn1IPD5mBi5kTOKTuH\nsBlmT/ceqjKrKPGVEIlFyEnLoaG/gR2dOzi79GyqMqt4te1VFhQsSIyKZ7gyCEaDtAfbmeCfcMzt\nVg6PhgbCAdIcaWqEJOOCQl4SzETIG/lr94Z6aQw0DvsfMBERERldxb5irj3j2sTrI5ueeRweqnOq\nj7u+E6AioyLxvCqz6pgdat+uby75ZuL7AaJmNNF4pzHQyEtNLzEhYwJrGtawq2sXU7OnMjlrMpvb\nN1OcXswlUy6hJ9TD+pb11PfVU5RexNTsqYl1meFYmJgVI2pGSXems6R4CVvatnDf7vto7WylwFvA\n/t79FKUXkeZIoy3Yxv6+/ZT6SrEsi7t23kVeWh4TMycSMSMU+4qZ5ppGpjuTtmAbtd21+Fw+ekO9\nhGIhstxZTMuZRjgWZmPbRp6oewKId78NxUJH/fx2w85fdv4Fp81JxIwA4LK5CJthStJLCEaD9IR6\nyHZns7BoIb2hXoai8ZHR5oFm2gfbKU4vpnmgORF0FxYuZF7BPMJmmN3du7Ebdi6ovICH9z1MXV8d\nVZlVBMIByv3l9IZ6GYwOkuHOYFHhItKcaXQNdXHH9js4q/QsWoOtBCNBziw5k3RnOvX99axtWMtg\nbJAzi8+kc6iTmbkzmZQ1idruWgBm582mxFfCswefpa6vjslZk7EbdrxOL/V99fSGetnWvo3arbX0\nR/op85UxKWsSPqePqBmlzF/GQGQAmxFfQ5zryaV5oJmi9CIcNgcRM8Lenr24bC5ebnmZgcgAS4uX\nYjNsVGRUkO5MB+JrkgORAF5HfG3xG0XN6FHvD0WHsNvs9If7SXem0zPUQ5ozjQO9B2gLtuG0Ocl0\nZ1KZUUmWJyvpv385OQp5STCteMAbjc5j2zq2ATAjd8aIX1tERETeOd7YTObIf3SX+koTnWyPNWp6\npDc2KXozqypWsapi1XFHUY90rCBwokzLTEzbLfOV0RBooGuoC5fNRcdgB7lpuUzKmsQ9u+7hxeYX\nuXLmlezs2knHYAeF3kLu2nUXWe4srl9wPeua1lHTVUOGOwOfKz4Fd1nJMvK9+ezv3c8Hp3yQSCzC\ngb4DPHvwWR7c+yAQn0IdjoW5t+Ze7Iad6pxqnql/Bo/dw+MHHifNkUa2J5uuoS7u3HlnovYsdxa3\nbbuNXE8uDpuDp+qfAuJTcCdlTcJu2Ll7191ku7P5x75/HPceHCvcOmwOPHjYuGkjDpuDqBk9ztlx\nh0Pv3Py5VGZW8uzBZ+kN9Q475mZuTjzPS8ujKrOK1oFW6vvrSXems6BwAaW+UgLhAIXphTzX8Bx7\nuveQ5kijwFtAgbeAodgQW9u3JgK3x+4ZNtX4jTWV+cswLTMR+J5veJ6ZeTPxOX3s7t7NgsIFLC9Z\njmmZmJjkenJpC7bRGmylZaCF/nA/PpePMl8ZbcE2mgeacdqc7O/dz9yCuVxQeQGvdbxGY6AxMTiS\n6c6kOrsap83Jwf6DxKwYXoeXwehgYrugg30HSXOmkZeWd8zag5FgYgr3O5VCXhIsRm+q5l92/oUs\ndxZz89/+egoRERGRU+VkAx7EGx8dOTJa7i+n3H/0ditXzLyCK2ZeAcDi4sWJ9y+bdhkW8TWbH5zy\nwRP+3pgZoyXYgsNwUOAtoDfUy9aOrZSklzA5e3LiuI7BjkQX3YgZYXPbZgD6w/0sL13OQGSAbHd8\nj9GGQAPhWJhSX2kimB8OCs81PEfEjLC4aDGmZbKhdQNtwTYWFS1ictZkDvYfxGbY6Av1UZVZhdPu\n5PnnnmfBsgWkO9PpGOzghaYXGIwO4nV4E1NVLSwisUhi3eWdO+9kX+8+zi47m+UlyxmMxkcTnXYn\nW9u3YhgGB3oP0BhoZEv7FtKd6Vy/4Hoa+htY37qezW2b8Tg8tAXbmJo9lU/N/hSD0UFag620BdsI\nRUNcNesqomaUDHcG7cF2KjIqGIoNMTlrMoXeQkKxEH3hPl5sepG2YBsAtT21vNr6KmcUnEFtdy0x\nK0ZVRhUP7nmQe2vuPebvyOvwkuHOoC/URzAaxGlzUuIrYSg6RIG3gLt33c1fdv4FiAdKn8vHswef\nHfa6a6hr2DUdhoPctFxag63YDBsF3gIchgObYWNS1iS2d2ynzF/Gzq6dfCbvMyf89zQWKeQlwbTA\nNgpzNdc0rGFd4zq+MP8LeJ3eEb++iIiIyOngZAOm3Wan1FeaeJ3lyTrmms4jR3qcNudRo6Vuuzvx\n/Fjh9PBsrxXlK4a9/+6Kdw97nZjm63/9PZthS0wXLkov4pIpl7zJTxR33dzrElN53+jtNPI7PBXz\nyO7Db9eJrJENRoLUdNeQ5kgjZsXoHuqmwFtAUXoRfqc/sRdo11AXXqc3sVULQOtAK5vaNjErbxal\nvtLE2le7YWdj20bagm0sK1mGx+FhMDpImiONnZ3xUeAZuTPoDffSMtBCxIwQiobY3L6Z6uxqWoOt\nXFR1EWkDaW9S+dinkJcE0xr5PfJqumr4t9X/xvSc6Vw+7fIRvbaIiIiInL6SGVU9kt/lf+uDRoDX\n6WVewbw3PcYwXu9ue6TC9MJh+6J6nV7OrzwfiE83PpYLqy484dpWr159wseORScfzwXLska06Uok\nFuGGtTeQ7kznt+f9VqN4IiIiIiLytmkkLwkmIztd84WmF6jtruXn7/r5cReCioiIiIiIvBmN5CXB\ntEZ2I/TnGp7D6/CysnzliF1TRERERETGF4W8JFjWyHXXtCyL5xqeY1nJMlx214hcU0RERERExh+F\nvCSYIxjy7tp1F23BNs6dcO6IXE9ERERERMYnhbwkmIB9BO5gU6CJn63/GSvLV/Leie9N/oIiIiIi\nIjJuKeQlYaSmaz6490FiVoyvLf5aUvuRiIiIiIiIKFEkYSSma1qWxUN7HmJJ0ZJhm3KKiIiIiIic\nDIW8JJhYSXfXbAw00hBo4N0V7x6hqkREREREZDxTyEtCfLpmcteo6aoBYEbujBGoSERERERExjuF\nvCSYVvKboe/s2onNsDE5e/IIVSUiIiIiIuOZQl4STAvsSa7Jq+mqoTKjkjRH2ghVJSIiIiIi45lC\nXhIskm+8sqt7F9Nypo1MQSIiIiIiMu4p5CUh2ema+3r20TLQwpz8OSNYlYiIiIiIjGcKeUkwreQ2\nQ39k/yPYDBvnV5w/ckWJiIiIiMi4ppCXhGQ2Q7csi0f3P8qiwkXke/NHuDIRERERERmvFPKSkMxm\n6Ds6d1DfX8+FVReOcFUiIiIiIjKeKeQlwUpiM/RH9j+Cw+bgvIrzRrgqEREREREZzxTykmAmsRn6\nM/XPsLxkOZnuzJEtSkRERERExjWFvCSc7HTNUCxEY6CRmbkzR6EqEREREREZzxTyknCy++Q1BZqw\nsCjzl418USIiIiIiMq4p5CUhvoXC2w95Df0NAAp5IiIiIiIy4hTyknCym6E3BA6FPJ9CnoiIiIiI\njCyFvCRYJ9l4paG/AbfdTV5a3sgXJSIiIiIi45pCXhJMwH4Sa/Ia+hso85VhnOQeeyIiIiIiIsej\nkJeEk52uWddXR6m/dBQqEhERERGR8U4hLwmWZb3t6Zr7e/ezt3cvi4sWj05RIiIiIiIyrinkJeFk\nums+vO9hbIaNC6suHKWqRERERERkPFPIS4LJ298n7/EDj7OoaBEF3oLRKUpERERERMY1hbwkxLtr\nnnjIq+uro66vjpXlK0exKhERERGR/9/evUdXWd/5Hn//CCHhLnITiSUgtirKACJXL2gr1J4ZnLpE\nZDwDteM4cywqerqKytLSi+PUOeOlaqdnxmutClOsh2o7xyMds6yoRanaAayCNtQAFeSShMRk5/I7\nf2QnRQm37J39hOT9Wou19/PbT579zTdx44ff73kedWWGvAwc6XLNF8teBOCconPaqyRJkiRJXZwh\nLwONRziTt3rLakb2H8kJfU9ox6okSZIkdWWGvAxEDv9m6DFGfvvRb5kwZEK71iRJkiSpazPkZeBI\nlmuWVZZRmarktEGntXNVkiRJkroyQ14GjuRm6Ot2rgMw5EmSJElqV4a8DBzJzdDXf7SegrwCTjzm\nxPYtSpLmPgqHAAAfBUlEQVQkSVKXZsjLQCOQdxgXXvm4/mOe2/wcpw86nfxu+e1fmCRJkqQuy5CX\ngcNdrvnYhsf4Y9UfWTh+YQ6qkiRJktSVGfIycLg3Q1+9ZTVjB4/ljKFn5KAqSZIkSV2ZIS8Dh3N1\nzRgj75W/x0nHnJSjqiRJkiR1ZYa8DDRy6Jm8nTU7Ka8tZ/Qxo3NTlCRJkqQuzZCXgablmgff5/09\n7wMw6phROahIkiRJUldnyMvA4SzX3LRnE4AzeZIkSZJywpDXRjFGIodervn78t/TJ78Pg3sOzk1h\nkiRJkro0Q14bNcamx0OFvF01uxjUcxDhMK7CKUmSJEmZMuS1UUM65eUdooMVqQr6FfTLQUWSJEmS\nZMhrs8bYFPIONUNXkaqgXw9DniRJkqTcMOS1UXPIO9SFVypqDXmSJEmScseQ10YtyzWdyZMkSZLU\ngRjy2qj5wisHy3iNsZHKVKXn5EmSJEnKGUNeGzU2Hnq55t66vUSiM3mSJEmScsaQ10aHc05eRW0F\ngCFPkiRJUs4Y8tqo4TCurlmRSoc8l2tKkiRJyhFDXhs1NjY9HuzCK5WpSsCZPEmSJEm5Y8hroz8t\n1zzwPi0zeYY8SZIkSTliyGuj5lsoHHS5ZvqcvP4F/XNSkyRJkiQZ8jLQJx8K8/MO+LozeZIkSZJy\nrXvSBRytTji2F/d9vjcz/uz4A+5TkaogL+TRs3vPHFYmSZIkqStzJq8dba/ezsCeAw+6pFOSJEmS\nssmQ1442V2ymuF9x0mVIkiRJ6kIMee1oc8VmRvQbkXQZkiRJkroQQ1472VOzhz21ewx5kiRJknLK\nkNdONlduBnC5piRJkqScMuS1k80VTSHPmTxJkiRJuWTIayd/qPgD3UI3hvcdnnQpkiRJkroQQ147\n2V69nUGFg8jvlp90KZIkSZK6EENeO9n+8XYG9xqcdBmSJEmSuhhDXjvZUb3DkCdJkiQp5wx57WRH\n9Q6G9BySdBmSJEmSupiMQl4IYU4IYX0IoTGEMPFTr90UQtgUQngnhDBrn/Evpsc2hRBuzOT9O6pU\nQ4rdtbudyZMkSZKUc5nO5K0DLgZe3HcwhHAqcBkwBvgi8IMQQl4IIQ+4H7gQOBWYl963U9nx8Q4A\nhvRyJk+SJElSbnXP5ItjjG8DhBA+/dJFwLIYYy3w+xDCJmBS+rVNMcb301+3LL3vhkzq6Gh2VDeF\nvME9ncmTJEmSlFsZhbyDGA68us92WXoM4INPjU8+0EFCCFcBVwEMHTqUkpKS7FaZob1797Za0xtV\nbwCwecNmGjY15LiqruFAvVf7s/fJsffJsv/JsffJsffJsffJOtr7f8iQF0JYBRzXyktLYowrD/Rl\nrYxFWl8eGg/03jHGfwX+FWDixIlxxowZBy82x0pKSmitpi1vb4GP4MKzL2Rgz4G5L6wLOFDv1f7s\nfXLsfbLsf3LsfXLsfXLsfbKO9v4fMuTFGL/QhuOWASfss10EbE0/P9B4p7Hz453khTwGFA5IuhRJ\nkiRJXUx73ULhZ8BlIYSCEMJI4CRgDfAacFIIYWQIoQdNF2f5WTvVkJhdNbvoX9CfbsE7VEiSJEnK\nrYzOyQshfBm4FxgM/DyE8GaMcVaMcX0I4d9puqBKPfC1GGND+msWAs8BecBDMcb1GX0HHdDumt0c\nW3hs0mVIkiRJ6oIyvbrm08DTB3jtNuC2VsZ/Afwik/ft6HbX7nappiRJkqREuJ6wHeyu2c2AAkOe\nJEmSpNwz5LWDXTW7nMmTJEmSlAhDXpbVNdZRkarwnDxJkiRJiTDkZVl5bTmAM3mSJEmSEmHIy7Jd\nNbsAQ54kSZKkZBjysmx3zW4Aji1wuaYkSZKk3DPkZVlzyHMmT5IkSVISDHlZtrNmJ2DIkyRJkpQM\nQ16W7ajeQffQ3atrSpIkSUqEIS/LtldvZ1CvQXQLtlaSJElS7plEsmx79XaG9BqSdBmSJEmSuihD\nXpZt/3g7Q3sNTboMSZIkSV2UIS/LnMmTJEmSlCRDXhZV1VVRVVdlyJMkSZKUGENeFn1Y/SGAIU+S\nJElSYgx5WbS9ejsAQ3oa8iRJkiQlw5CXRTuqdwAwuNfghCuRJEmS1FUZ8rKoIlUBwICCAQlXIkmS\nJKmrMuRlUXPI69OjT8KVSJIkSeqqDHlZVJmqpFf3XnTv1j3pUiRJkiR1UYa8LKpMVdK3R9+ky5Ak\nSZLUhRnyssiQJ0mSJClphrwsqkxV0q9Hv6TLkCRJktSFGfKyqCJV4UyeJEmSpEQZ8rLI5ZqSJEmS\nkmbIyyJn8iRJkiQlzZCXJY2xkb2pvZ6TJ0mSJClRhrwsqaqrIhKdyZMkSZKUKENellSmKgGcyZMk\nSZKUKENeljSHPGfyJEmSJCXJkJclFakKwJAnSZIkKVmGvCxpDnl9evRJuBJJkiRJXZkhL0uq6qoA\n6JvvTJ4kSZKk5BjysqQ55PXK75VwJZIkSZK6MkNeljSHvN75vROuRJIkSVJXZsjLkuq6arqFbhTm\nFSZdiiRJkqQuzJCXJVV1VfTu3psQQtKlSJIkSerCDHlZUlVX5fl4kiRJkhJnyMuS6vpqz8eTJEmS\nlDhDXpZU1VUZ8iRJkiQlzpCXJS7XlCRJktQRGPKypPnCK5IkSZKUJENellTXVdOnR5+ky5AkSZLU\nxRnysqSqvope3V2uKUmSJClZhrwsiDFSlfLCK5IkSZKSZ8jLglRjivpYb8iTJEmSlDhDXhZU1VUB\neHVNSZIkSYkz5GVBc8hzJk+SJElS0gx5WVBdVw0Y8iRJkiQlz5CXBS0zed4nT5IkSVLCDHlZUF3f\nNJPnOXmSJEmSkmbIy4LahloACvIKEq5EkiRJUldnyMuCVEMKgILuhjxJkiRJyTLkZUFNfQ3gTJ4k\nSZKk5BnysqBlJs+QJ0mSJClhhrwsaD4nr0dej4QrkSRJktTVGfKyINXYNJNXmFeYcCWSJEmSurru\nSRfQGTSfk5ffLT/hSiRJkqS2qauro6ysjJqamqRLSVz//v15++23E3v/wsJCioqKyM9vW74w5GVB\nqiFFQV4BIYSkS5EkSZLapKysjL59+1JcXNzl/7+2srKSvn37JvLeMUZ27txJWVkZI0eObNMxXK6Z\nBbUNtZ6PJ0mSpKNaTU0NAwcO7PIBL2khBAYOHJjRjKohLwtqG2o9H0+SJElHPQNex5Dpz8GQlwWp\nhpQzeZIkSZI6BENeFtQ01HiPPEmSJEkdgiEvC5ovvCJJkiSp/RUXF/PRRx9l/bi33347o0ePZsKE\nCTz33HOt7nPfffcxevRoQgjtUkM2GPKyoLah1pAnSZIkZVGMkcbGxqwft76+vtXxDRs2sGzZMtav\nX89Pf/pTrr76ahoaGvbbb/r06axatYoRI0ZkvbZs8RYKWeBMniRJkjqTbz2zng1bK7J6zFOP78c3\n/2LMQfcpLS3lwgsv5LzzzuOVV15h0aJF/PCHP6S2tpYTTzyRhx9+mD59+gDwT//0T7zwwgsAPPHE\nE4wePZpnnnmG7373u6RSKQYOHMjjjz/O0KFDWbp0KVu3bqW0tJRBgwbxxBNP7PfeK1eu5LLLLqOg\noIDi4mJGjx7NmjVrmDp16if2Gz9+fJY60n6cycuCmoYaL7wiSZIkZcE777zD/Pnzef7553nwwQdZ\ntWoVv/nNb5g4cSJ33nlny379+vVjzZo1LFy4kEWLFgFw1lln8eqrr/LGG29w2WWXcccdd7Tsv3bt\nWlauXNlqwAPYsmULJ5xwQst2UVERW7Zsaafvsn05k5cFqYYUhd29hYIkSZI6h0PNuLWnESNGMGXK\nFJ599lk2bNjA9OnTAUilUp+YVZs3b17L4/XXXw803dB97ty5bNu2jVQq9Ymbic+ePZuePXse8H1j\njPuNHa23lDDkZYE3Q5ckSZKyo3fv3kBT6Lrgggt48sknW91v3wDW/Pyaa67hhhtuYPbs2ZSUlLB0\n6dL9jnsgRUVFfPDBBy3bZWVlHH/88W39NhLlcs0s8MIrkiRJUnZNmTKF1atXs2nTJgCqq6t59913\nW15fvnx5y2PzDF95eTnDhw8H4NFHHz2i95s9ezbLli2jtraW0tJSNm7cyKRJk7LxreScIS8Lahtq\n6dHNmTxJkiQpWwYPHswjjzzCvHnzGDt2LFOmTOF3v/tdy+u1tbVMnjyZe+65h7vuuguApUuXMmfO\nHM4++2wGDRp0RO83ZswYLr30Uk499VQuvvhi7r//fvLy8gD40pe+xNatWwH4/ve/T1FREWVlZYwd\nO5Yrr7wyS99x9rhcMws8J0+SJEnKXHFxMevWrWvZPv/883nttdf226+0tBSAb37zm58Yv+iii7jo\noov223/fZZsHs2TJEpYsWUJlZSV9+/ZtGf/FL37R8vzaa6/l2muvPazjJcWZvAzFGD0nT5IkSVKH\n4UxehupjPY2x0XPyJEmSpKPAc889x+LFiz8xNnLkSJ5++umEKso+Q16GUg0pAEOeJEmSdBSYNWsW\ns2bNSrqMduVyzQzV1NcAhjxJkiRJHYMhL0PO5EmSJEnqSAx5GaptqAXwwiuSJEmSOgRDXoaaQ54z\neZIkSZI6AkNehpzJkyRJklRbW8vcuXMZPXo0kydPbrmX36d99atfZciQIZx22mntVotX18zQzo93\nAjCgYEDClUiSJElZ8h83wh//K7vHPO50uPAfD3v3GCMxRrp1y+68VH19Pd27Zz8GPfjggwwYMIBN\nmzaxbNkyFi9ezPLly/fb7ytf+QoLFy5k/vz5Wa+hmTN5GdpatRWAYX2GJVyJJEmSdHQrLS3llFNO\n4eqrr2bChAk89thjTJ06lQkTJjBnzhz27t0LQHFxMYsXL2bSpElMmjSJTZs2AfDMM88wefJkxo8f\nzxe+8AU+/PBDAJYuXcpVV13FzJkzmT9/PqWlpZx99tlMmDCBCRMm8PLLLwNQUlLCueeey4IFC/js\nZz/LjTfeyOOPP86kSZM4/fTTee+99w5Y+8qVK1mwYAEAl1xyCb/85S+JMe633znnnMOxxx6b1b59\nmjN5Gdq2dxsFeQUMLByYdCmSJElSdhzBjFu2vfPOOzz88MN8+9vf5uKLL2bVqlX07t2b733ve9x5\n553ceuutAPTr1481a9bwox/9iEWLFvHss89y1lln8eqrrxJC4IEHHuCOO+7gn//5nwFYu3YtL730\nEj179qS6uprnn3+ewsJCNm7cyLx583j99dcBeOutt3jttdf4zGc+w6hRo7jyyitZs2YN99xzD/fe\ney933313q3Vv2bKFE044AYDu3bvTv39/du7cyaBBg3LQtU/KKOSFEOYAS4FTgEkxxtfT4wOBFcCZ\nwCMxxoX7fM0ZwCNAT+AXwHWxtYh7lNhatZVhvYcRQki6FEmSJOmoN2LECKZMmcKzzz7Lhg0bmD59\nOgCpVIqpU6e27Ddv3ryWx+uvvx6AsrIy5s6dy7Zt20ilUowcObJl/9mzZ9OzZ08A6urqWLhwIW++\n+SZ5eXm8++67LfudeeaZHHfccRQUFHDiiScyc+ZMAE4//XReeOGFA9bdWqRJKiNkOpO3DrgY+N+f\nGq8BbgFOS//Z178AVwGv0hTyvgj8R4Z1JGbb3m0c3+f4pMuQJEmSOoXevXsDTaHpggsu4Mknn2x1\nv30DVPPza665hhtuuIHZs2dTUlLC0qVL9zsuwF133cXQoUN56623aGxspLCwsOW1goI/XTW/W7du\nLdvdunWjvr7+gHUXFRXxwQcfUFRURH19PeXl5e2+LPNAMjonL8b4dozxnVbGq2KML9EU9lqEEIYB\n/WKMr6Rn734E/GUmNSSteSZPkiRJUvZMmTKF1atXt5xvV11d/YkZt+aLmixfvrxlhq+8vJzhw4cD\n8Oijjx7w2OXl5QwbNoxu3brx2GOP0dDQkHG9s2fPbnnPFStWcP755x+1M3lHajhQts92WXqsVSGE\nq2ia9WPo0KGUlJS0a3FHalflLnbV7KJ2R22Hq62z27t3rz1PiL1Pjr1Plv1Pjr1Pjr1PThK979+/\nP5WVlTl9z0/bu3cvjY2NVFZWUlhYyA9+8AMuvfRSUqkUALfccgvDhg0jxkhFRQUTJ06ksbGRhx56\niMrKShYvXswll1zCsGHDOPPMM2loaKCyspLa2lry8/Nbvr/58+fz13/91yxbtoxzzjmH3r17U1lZ\nSXV1NfX19S1f19DQQFVV1SdeO1CPLr30UlatWsWoUaMYMGAADz/8MJWVlWzbto2FCxfy1FNPAXDF\nFVfw0ksvsXPnToYPH87NN9/c6pU2a2pq2vw7EA51OlwIYRVwXCsvLYkxrkzvUwJ8vfmcvH2+9ivA\nxOZz8kIIZwK3xxi/kN4+G/hGjPEvDlXoxIkTY/PJkB3FsueXcdvW2/iHs/6BvzjxkN+CsqikpIQZ\nM2YkXUaXZO+TY++TZf+TY++TY++Tk0Tv3377bU455ZScvmdbFRcX8/rrr7fbRU0qKyvp27dvuxz7\ncLX28wghrI0xTjzU1x5yJq85kGVJGVC0z3YRsDWLx8+pbaltAIw6ZlTClUiSJElSk5wu14wxbgsh\nVIYQpgC/BuYD9+ayhmzaWreVbqEbJ/Y/MelSJEmSpC6jtLQ0sfe+7bbb+MlPfvKJsTlz5rBkyZKE\nKtpfprdQ+DJNIW0w8PMQwpsxxlnp10qBfkCPEMJfAjNjjBuA/8GfbqHwHxzFV9bcktpCcb9iCrsX\nHnpnSZIkSUe9JUuWdKhA15qMQl6M8Wng6QO8VnyA8dfZ/7YKR6WtdVs5c+iZSZchSZIkSS0yuoVC\nV7Y3tZed9Tv57IDPJl2KJEmSJLUw5LXRnto9jCwYyZiBY5IuRZIkSZJaGPLaqKhvETccdwPThk9L\nuhRJkiRJamHIkyRJktRpzJgxg/a8v3ZxcTEfffQRANOmdcwJn5zeQkGSJElSx/e9Nd/jd7t+l9Vj\nnnzsySyetDirx0zayy+/nHQJrXImT5IkSVKHUFpayimnnMLf/u3fMmbMGGbOnMnHH3/Mm2++yZQp\nUxg7dixf/vKX2b1790GP8+Mf/5hp06Zx2mmnsWbNGgDWrFnDtGnTGD9+PNOmTeOdd94BYP369Uya\nNIlx48YxduxYNm7c2HKM5vG/+7u/o6GhYb/36dOnDwAlJSXMmDGDSy65hJNPPpnLL7+cGCMAa9eu\n5dxzz+WMM85g1qxZbNu2LWv9OhBn8iRJkiR9QpIzbhs3buTJJ5/k3/7t37j00kt56qmnuOOOO7j3\n3ns599xzufXWW/nWt77F3XfffcBjVFVV8fLLL/Piiy/y1a9+lXXr1nHyySfz4osv0r17d1atWsXN\nN9/MU089xQ9/+EOuu+46Lr/8clKpFA0NDaxfv57ly5ezevVq8vPzufrqq3n88ceZP3/+Ad/zjTfe\nYP369Rx//PFMnz6d1atXM3nyZK655hpWrlzJ4MGDWb58OUuWLOGhhx5qj9a1MORJkiRJ6jBGjhzJ\nuHHjADjjjDN477332LNnD+eeey4ACxYsYM6cOQc9xrx58wA455xzqKioYM+ePVRWVrJgwQI2btxI\nCIG6ujoApk6dym233UZZWRkXX3wxJ510EiUlJaxdu5Yzz2y6J/bHH3/MkCFDDvqekyZNoqioCIBx\n48ZRWlrKMcccw7p167jgggsAaGhoYNiwYW3szOEz5EmSJEnqMAoKClqe5+XlsWfPniM+Rghhv+1b\nbrmF8847j6effprS0lJmzJgBwF/91V8xefJkfv7znzNr1iweeOABYowsWLCA22+/vc1119fXE2Nk\nzJgxvPLKK0f8PWTCc/IkSZIkdVj9+/dnwIAB/OpXvwLgsccea5nVO5Dly5cD8NJLL9G/f3/69+9P\neXk5w4cPB+CRRx5p2ff9999n1KhRXHvttcyePZvf/va3zJgxgxUrVrB9+3YAdu3axebNm4+49s99\n7nPs2LGjJeTV1dWxfv36Iz7OkXImT5IkSVKH9uijj/L3f//3VFdXM2rUKB5++OGD7j9gwACmTZtG\nRUVFy/lv3/jGN1iwYAF33nkn559/fsu+y5cv58c//jH5+fkcd9xx3HrrreTn5/Pd736XmTNn0tjY\nSH5+Pvfffz8jRow4orp79OjBihUruPbaaykvL6e+vp5FixYxZsyYI2/CETDkSZIkSeoQiouLWbdu\nXcv217/+9Zbnr7766mEdo6SkpNXxqVOn8u6777Zsf+c73wHgpptu4qabbvrEvpWVlcydO5e5c+fu\nd5zS0tKW53v37gWa7s3XvPwT4L777mt5Pm7cOF588cXDqj1bXK4pSZIkSZ2IM3mSJEmSjjpf+9rX\nWL169SfGrrvuOq644oqEKuo4DHmSJEmSAIgx7ndlyo7q/vvvT7qEdtN8I/W2crmmJEmSJAoLC9m5\nc2fGAUOZiTGyc+dOCgsL23wMZ/IkSZIkUVRURFlZGTt27Ei6lMTV1NRkFLIyVVhY2HJj9bYw5EmS\nJEkiPz+fkSNHJl1Gh1BSUsL48eOTLqPNXK4pSZIkSZ2IIU+SJEmSOhFDniRJkiR1IuFouXpOCGEH\nsDnpOj5lEPBR0kV0UfY+OfY+OfY+WfY/OfY+OfY+OfY+WR21/yNijIMPtdNRE/I6ohDC6zHGiUnX\n0RXZ++TY++TY+2TZ/+TY++TY++TY+2Qd7f13uaYkSZIkdSKGPEmSJEnqRAx5mfnXpAvowux9cux9\ncux9sux/cux9cux9cux9so7q/ntOniRJkiR1Is7kSZIkSVInYsiTJEmSpE7EkNcGIYQvhhDeCSFs\nCiHcmHQ9nVEI4aEQwvYQwrp9xo4NITwfQtiYfhyQHg8hhO+nfx6/DSFMSK7yo1sI4YQQwgshhLdD\nCOtDCNelx+19DoQQCkMIa0IIb6X7/630+MgQwq/T/V8eQuiRHi9Ib29Kv16cZP2dQQghL4TwRgjh\n2fS2vc+BEEJpCOG/QghvhhBeT4/5uZMDIYRjQggrQgi/S3/2T7X3uRFC+Fz6d775T0UIYZH9z40Q\nwvXpv2vXhRCeTP8d3Gk+8w15RyiEkAfcD1wInArMCyGcmmxVndIjwBc/NXYj8MsY40nAL9Pb0PSz\nOCn95yrgX3JUY2dUD/zPGOMpwBTga+nfb3ufG7XA+THGPwPGAV8MIUwBvgfcle7/buBv0vv/DbA7\nxjgauCu9nzJzHfD2Ptv2PnfOizGO2+e+VH7u5MY9wP+NMZ4M/BlNv//2PgdijO+kf+fHAWcA1cDT\n2P92F0IYDlwLTIwxngbkAZfRiT7zDXlHbhKwKcb4fowxBSwDLkq4pk4nxvgisOtTwxcBj6afPwr8\n5T7jP4pNXgWOCSEMy02lnUuMcVuM8Tfp55U0/WU/HHufE+k+7k1v5qf/ROB8YEV6/NP9b/65rAA+\nH0IIOSq30wkhFAH/DXggvR2w90nyc6edhRD6AecADwLEGFMxxj3Y+yR8HngvxrgZ+58r3YGeIYTu\nQC9gG53oM9+Qd+SGAx/ss12WHlP7Gxpj3AZNYQQYkh73Z9IO0ksRxgO/xt7nTHq54JvAduB54D1g\nT4yxPr3Lvj1u6X/69XJgYG4r7lTuBr4BNKa3B2LvcyUC/y+EsDaEcFV6zM+d9jcK2AE8nF6m/EAI\noTf2PgmXAU+mn9v/dhZj3AL8L+APNIW7cmAtnegz35B35FpL7d6HIln+TLIshNAHeApYFGOsONiu\nrYzZ+wzEGBvSS3eKaFo5cEpru6Uf7X+WhBD+HNgeY1y773Aru9r79jE9xjiBpuVoXwshnHOQfe19\n9nQHJgD/EmMcD1Txp6WBrbH37SB93tds4CeH2rWVMfvfBunzHC8CRgLHA71p+vz5tKP2M9+Qd+TK\ngBP22S4CtiZUS1fzYfOyhPTj9vS4P5MsCiHk0xTwHo8x/jQ9bO9zLL1kqoSmcyOPSS8ngU/2uKX/\n6df7s/8yZx2e6cDsEEIpTcvwz6dpZs/e50CMcWv6cTtN5yRNws+dXCgDymKMv05vr6Ap9Nn73LoQ\n+E2M8cP0tv1vf18Afh9j3BFjrAN+CkyjE33mG/KO3GvASemr7/SgaXr9ZwnX1FX8DFiQfr4AWLnP\n+Pz0VaemAOXNyxx0ZNLryx8E3o4x3rnPS/Y+B0IIg0MIx6Sf96TpL6G3gReAS9K7fbr/zT+XS4D/\njDF26H9Z7KhijDfFGItijMU0fa7/Z4zxcux9uwsh9A4h9G1+DswE1uHnTruLMf4R+CCE8Ln00OeB\nDdj7XJvHn5Zqgv3PhT8AU0IIvdL/79P8u99pPvNDB6+vQwohfImmf+HNAx6KMd6WcEmdTgjhSWAG\nMAj4EPgm8H+Afwc+Q9N/nHNijLvS/3HeR9PVOKuBK2KMrydR99EuhHAW8Cvgv/jTeUk303Renr1v\nZyGEsTSd2J1H0z/C/XuM8dshhFE0zS4dC7wB/PcYY20IoRB4jKZzJ3cBl8UY30+m+s4jhDAD+HqM\n8c/tfftL9/jp9GZ34IkY420hhIH4udPuQgjjaLrYUA/gfeAK0p8/2Pt2F0LoRdO5XqNijOXpMX/3\ncyA03aZoLk1XFn8DuJKmc+86xWe+IU+SJEmSOhGXa0qSJElSJ2LIkyRJkqROxJAnSZIkSZ2IIU+S\nJEmSOhFDniRJkiR1IoY8SZIkSepEDHmSJEmS1In8f/NvVAJbXg3YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcc6853c128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for opt_mode in opt_modes:\n",
    "    plt.plot(range(1, num_epochs+1), -np.array(train_losses[opt_mode]))\n",
    "plt.grid(True)\n",
    "plt.legend(opt_modes)\n",
    "#plt.plot(test_losses, 'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final performance:\n",
      "rebar_0.1: -69.84\n",
      "reparam_0.1: -68.30\n",
      "no_baseline: -92.02\n"
     ]
    }
   ],
   "source": [
    "print('Final performance:')\n",
    "for opt_mode in opt_modes:\n",
    "    print('{}: {:.2f}'.format(opt_mode, -train_losses[opt_mode][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
